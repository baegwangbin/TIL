{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. HTTP(HyperText Transport Protocol)\n",
    "**1.1 프로토콜: 네트워크 통신 규약**\n",
    " - 인터넷 프로토콜: TCP 및 IP 프로토콜이 핵심, TCP/IP 프로토콜\n",
    " - 이더넷: 네트워크 모듈\n",
    " - IP 프로토콜: 컴퓨터 주소를 찾는 프로토콜\n",
    " - TCP 프로토콜: 컴퓨터간 신뢰성 있는 데이터 전송을 지원하는 프로토콜\n",
    " <img src=\"00_Images/protocol_stack.png\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**- 웹 전체 시나리오 **\n",
    "1. 사용자는 브라우저를 사용하여서 www.funcoding.xyz 같은 URL 입력을 통해서 웹페이지를 요청한다.\n",
    "2. 사용자의 요청은 **TCP 패킷**으로 만들어지게 된다.\n",
    "3. **TCP 패킷**은 **IP 패킷**으로 다시 만들어 지고\n",
    "   **IP 패킷**에는 자신의 IP 주소와, 도착해야될 상대방의 IP 주소 정보가 넣어진다.\n",
    "4. **IP 패킷**은 **이더넷 카드**로 보내어져서 Internet 으로 전송된다.\n",
    "5. **이더넷 패킷**은 도착지의 컴퓨터 **이더넷 카드**로 전달된다.\n",
    "<br><br>\n",
    "6. **이더넷 카드**는 해당 데이터를 **IP 프로토콜 계층**에 보낸다.\n",
    "7. **IP 프로토콜 계층**은 다시 **TCP 프로토콜 계층**으로 데이터를 보낸다.\n",
    "8. **TCP 프로토콜 계층**은 누락된 데이터가 없는지 확인하고, 수신받은 데이터를 재조합핸 후 이 데이터를 **Application Layer**에 보낸다.\n",
    "9. **Application Layer**에서 해당 데이터가 **HTTP 프로토콜**로 작성되어 있으면, **HTTP 프로토콜 규칙**에 준하여, 사용자가 요청한 웹페이지를 웹서버가 제공한다.\n",
    "10. 웹서버가 제공한 웹페이지는 다시 **TCP 프로토콜 계층**으로 전송되어, **TCP 패킷**으로 바뀌고, 결국 **IP 패킷**으로 만들어지고, **이더넷 카드**에 보내진다.\n",
    "<br><br>\n",
    "11. 웹페이지는 요청된 컴퓨터에 수신되고, **이더넷 카드, IP 패킷, TCP 패킷, HTTP 패킷**으로 분석되어, 웹브라우저에 웹페이지가 전달된다.\n",
    "12. 웹브라우저는 웹페이지 파일에 있는 HTML,CSS,javascript등을 **파싱(parsing)**하여, **렌더링** 작업을 거쳐 화면에 뿌려준다.\n",
    "\n",
    " <img src=\"00_Images/protocol_transferation.png\" />\n",
    "\n",
    "**참고1(TCP/IP 프로토콜): https://www.joinc.co.kr/w/Site/Network_Programing/Documents/IntroTCPIP**   \n",
    "**참고2(렌더링이란): http://wit.nts-corp.com/2014/03/18/1116**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**- HTTP 프로토콜: WWW(웹)상에서 문서 전송을 위한 프로토콜 **\n",
    " - request(요청) / response(응답) 으로 구성\n",
    "   - browser(클라이언트)가 요청하면 web server(서버)가 HTML 파일이나 다른 자원(이미지, 텍스트, 동영상 등)을 응답으로 전송\n",
    "   - request의 형태에는 대표적으로 GET / POST 가 있음\n",
    "   <br><br>\n",
    "     - <font color=\"blue\">GET 방식</font>  : 데이터 전달을 URL 내에서 함\n",
    "       - https://search.naver.com/search.naver?where=nexearch&sm=top_hty&fbm=1&ie=utf8&query=%EB%B9%85%EB%8D%B0%EC%9D%B4%ED%84%B0\n",
    "       - 네이버 검색, 구글 검색 등\n",
    "   <br><br>\n",
    "     - <font color=\"blue\">POST 방식</font> : 데이터 전송을 <form> 태그를 통해서 함(사용자에게 직접적으로 노출되지 않음)\n",
    "       - 예) ID, 비밀번호 전달의 경우\n",
    "       - [참고 - FORM을 통해 데이터를 전달하는 POST 방식 기본 설명](http://cloudstudying.kr/lectures/72)\n",
    "   <br><br>\n",
    " - browser는 응답을 렌더링하여 인간이 보기 쉬운 형태로 출력\n",
    " - [참고: HTTP 프로토콜 위키 페이지](https://en.wikipedia.org/wiki/Hypertext_Transfer_Protocol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Crawling 이란?\n",
    "  - Web상에 존재하는 Contents를 수집하는 작업 (프로그래밍으로 자동화 가능)\n",
    "      1. HTML 페이지를 **가져와서**, HTML/CSS등을 **파싱**하고, 필요한 데이터만 추출하는 기법\n",
    "      2. **Open API(Rest API)**를 제공하는 서비스에 Open API를 호출해서, 받은 데이터 중 필요한 데이터만 추출하는 기법\n",
    "      3. **Selenium**등 브라우저를 프로그래밍으로 조작해서, 필요한 데이터만 추출하는 기법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Crawling 예제\n",
    "\n",
    "**3.1. BeautifulSoup 라이브러리를 활용한 초간단 예제**\n",
    "  - HTML의 태그를 파싱해서 필요한 데이터만 추출하는 함수를 제공하는 라이브러리\n",
    "  - [BeautifulSoup 라이브러리 페이지](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)\n",
    "  - 설치 방법\n",
    "    - pip install bs4\n",
    "  - [참고: BeautifulSoup 4 API Guide](http://omz-software.com/pythonista/docs/ios/beautifulsoup_guide.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "잔금대출에도 DTI 규제 적용 검토 | Daum 뉴스\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# 1) reqeusts 라이브러리를 활용한 HTML 페이지 요청 \n",
    "# 1-1) res 객체에 HTML 데이터가 저장되고, res.content로 데이터를 추출할 수 있음\n",
    "res = requests.get('http://v.media.daum.net/v/20170615203441266')\n",
    "\n",
    "# print(res.content)\n",
    "# 2) HTML 페이지 파싱 BeautifulSoup(HTML데이터, 파싱방법)\n",
    "# 2-1) BeautifulSoup 파싱방법\n",
    "soup = BeautifulSoup(res.content, 'html.parser')\n",
    "\n",
    "# 3) 필요한 데이터 검색\n",
    "title = soup.find('title')\n",
    "\n",
    "# 4) 필요한 데이터 추출\n",
    "print(title.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.2. BeautifulSoup 라이브러리 활용 주요 예제**\n",
    "  - find() 와 find_all() 메서드 사용법 이해하기\n",
    "  - find() : 가장 먼저 검색되는 태그 반환\n",
    "  - find_all() : 전체 태그 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1 id=\"title\">[1]크롤링이란?</h1>\n",
      "[1]크롤링이란?\n",
      "[1]크롤링이란?\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = \"<html> \\\n",
    "            <body> \\\n",
    "                <h1 id='title'>[1]크롤링이란?</h1> \\\n",
    "                <p class='cssstyle'>웹페이지에서 필요한 데이터를 추출하는 것</p> \\\n",
    "                <p id='body' align='center'>파이썬을 중심으로 다양한 웹크롤링 기술 발달</p> \\\n",
    "            </body> \\\n",
    "        </html>\"\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "# 태그로 검색 방법\n",
    "title_data = soup.find('h1')\n",
    "\n",
    "print(title_data)\n",
    "print(title_data.string)\n",
    "print(title_data.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p class=\"cssstyle\">웹페이지에서 필요한 데이터를 추출하는 것</p>\n",
      "웹페이지에서 필요한 데이터를 추출하는 것\n",
      "웹페이지에서 필요한 데이터를 추출하는 것\n"
     ]
    }
   ],
   "source": [
    "# 가장 먼저 검색되는 태그를 반환\n",
    "paragraph_data = soup.find('p')\n",
    "\n",
    "print(paragraph_data)\n",
    "print(paragraph_data.string)\n",
    "print(paragraph_data.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1 id=\"title\">[1]크롤링이란?</h1>\n",
      "[1]크롤링이란?\n",
      "[1]크롤링이란?\n"
     ]
    }
   ],
   "source": [
    "# 태그에 있는 id로 검색 (javascript 예를 상기!)\n",
    "title_data = soup.find(id='title')\n",
    "\n",
    "print(title_data)\n",
    "print(title_data.string)\n",
    "print(title_data.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p class=\"cssstyle\">웹페이지에서 필요한 데이터를 추출하는 것</p>\n",
      "웹페이지에서 필요한 데이터를 추출하는 것\n",
      "웹페이지에서 필요한 데이터를 추출하는 것\n"
     ]
    }
   ],
   "source": [
    "# HTML 태그와 CSS class를 활용해서 필요한 데이터를 추출하는 방법1\n",
    "paragraph_data = soup.find('p', class_='cssstyle')\n",
    "\n",
    "print(paragraph_data)\n",
    "print(paragraph_data.string)\n",
    "print(paragraph_data.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p class=\"cssstyle\">웹페이지에서 필요한 데이터를 추출하는 것</p>\n",
      "웹페이지에서 필요한 데이터를 추출하는 것\n",
      "웹페이지에서 필요한 데이터를 추출하는 것\n"
     ]
    }
   ],
   "source": [
    "# HTML 태그와 CSS class를 활용해서 필요한 데이터를 추출하는 방법2\n",
    "paragraph_data = soup.find('p', 'cssstyle')\n",
    "\n",
    "print(paragraph_data)\n",
    "print(paragraph_data.string)\n",
    "print(paragraph_data.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p align=\"center\" id=\"body\">파이썬을 중심으로 다양한 웹크롤링 기술 발달</p>\n",
      "파이썬을 중심으로 다양한 웹크롤링 기술 발달\n",
      "파이썬을 중심으로 다양한 웹크롤링 기술 발달\n"
     ]
    }
   ],
   "source": [
    "# HTML 태그와 태그에 있는 속성:속성값을 활용해서 필요한 데이터를 추출하는 방법\n",
    "paragraph_data = soup.find('p', attrs = {'align': 'center'})\n",
    "print(paragraph_data)\n",
    "print(paragraph_data.string)\n",
    "print(paragraph_data.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<p>웹페이지에서 필요한 데이터를 추출하는 것</p>, <p id=\"body\">파이썬을 중심으로 다양한 웹크롤링 기술 발달</p>]\n",
      "웹페이지에서 필요한 데이터를 추출하는 것\n",
      "파이썬을 중심으로 다양한 웹크롤링 기술 발달\n"
     ]
    }
   ],
   "source": [
    "# find_all() 관련된 모든 데이터를 리스트 형태로 추출하는 함수\n",
    "paragraph_data = soup.find_all('p')\n",
    "\n",
    "print(paragraph_data)\n",
    "print(paragraph_data[0].get_text())\n",
    "print(paragraph_data[1].get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **string 검색**\n",
    " - 태그가 아닌 문자열 자체로 검색\n",
    " - 문자열, 정규표현식 등등으로 검색 가능\n",
    "   - 문자열 검색의 경우 한 태그내의 문자열과 exact matching인 것만 추출\n",
    "   - 이것이 의도한 경우가 아니라면 정규표현식 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['오대석']\n",
      "['[이주의해시태그-#네이버-클로바]쑥쑥 크는 네이버 AI', '오대석']\n",
      "[]\n",
      "[이주의해시태그-#네이버-클로바]쑥쑥 크는 네이버 AI | Daum 뉴스\n"
     ]
    }
   ],
   "source": [
    "res = requests.get('http://v.media.daum.net/v/20170518153405933')\n",
    "soup = BeautifulSoup(res.content, 'html5lib')\n",
    "\n",
    "print (soup.find_all(string='오대석'))\n",
    "print (soup.find_all(string=['[이주의해시태그-#네이버-클로바]쑥쑥 크는 네이버 AI', '오대석']))\n",
    "print (soup.find_all(string='AI'))\n",
    "print (soup.find_all(string=re.compile('AI'))[0])\n",
    "# print (soup.find_all(string=re.compile('AI')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "**<font color=\"blue\" size=\"4em\">연습문제1</font>**\n",
    " 1. 다음 사이트에서 링크가 되어 있는 모든 제목을 가져와서 출력합니다.\n",
    "    http://media.daum.net/digital/\n",
    " \n",
    "    X 참고코드: git 저장소에서 02_examples/crawling_seeko_title.py 를 참고 \n",
    "    - 프로그래밍은 스스로 작성을 해야 합니다. 정 이해하기 어려울 때만 참고코드를 보시면 좋을 것 같습니다.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-9-d1735dd44598>, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-9-d1735dd44598>\"\u001b[1;36m, line \u001b[1;32m9\u001b[0m\n\u001b[1;33m    [------------------------------------------------------]\u001b[0m\n\u001b[1;37m                                                           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "res = requests.get('http://media.daum.net/digital/')\n",
    "soup = BeautifulSoup(res.content, 'html.parser')\n",
    "\n",
    "# find_all() 메서드를 사용해서 태그와 클래스이름으로 링크가 걸려있는 기사 타이틀을 가져오기\n",
    "[------------------------------------------------------]\n",
    "\n",
    "for num in range(len(link_title)):\n",
    "    print(link_title[num].get_text().strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.2. Open API(Rest API)를 활용한 초간단 크롤링 실습**\n",
    "#### Open API(Rest API)란?\n",
    " - **API:** Application Programming Interface의 약자로, 특정 프로그램을 만들기 위해 제공되는 모듈(함수 등)을 의미\n",
    " - **Open API:** 공개 API라고도 불리우며, 누구나 사용할 수 있도록 공개된 API (주로 Rest API 기술을 많이 사용함)\n",
    " - **Rest API:** Representational State Transfer API의 약자로, HTTP프로토콜을 통해 서버 제공 기능을 사용할 수 있는 함수를 의미\n",
    "   - 일반적으로 XML, JSON의 형태로 응답을 전달(원하는 데이터 추출이 수월)\n",
    "   - [참고 - RestAPI란](http://hyunalee.tistory.com/1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**JSON 이란?**\n",
    " - JavaScript Object Notation 줄임말\n",
    " - 웹환경에서 서버와 클라이언트 사이에 데이터를 주고 받을때 많이 사용\n",
    "   - Rest API가 주요한 예제\n",
    " - JSON 포멧 예 <br>\n",
    " { \"id\":\"01\", \"language\": \"Java\", \"edition\": \"third\", \"author\": \"Herbert Schildt\" }\n",
    " <br>\n",
    " <br>\n",
    " \n",
    " - 참고 (https://books.google.co.kr/books?id=euSiAwAAQBAJ&pg=PT1755&lpg=PT1755&dq=json+%EC%9E%A5%EC%A0%90&source=bl&ots=VjTIoOjbTK&sig=3t7MXA7g2CvEi8SyD0-GQVywzw0&hl=ko&sa=X&ved=0ahUKEwiwo8OvxJfWAhXDsJQKHYaBDpI4ChDoAQhVMAg#v=onepage&q=json%20%EC%9E%A5%EC%A0%90&f=false)\n",
    "\n",
    " 출처: http://dpug.tistory.com/67#.WbycWshJaUk [퍼그의 전초기지]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.2.1. 네이버 검색 Open API를 이용한 크롤링 초간단 실습**\n",
    " - https://developers.naver.com/main/\n",
    " - [블로그 검색 가이드 문서](https://developers.naver.com/docs/search/blog/)\n",
    "   - 네이버 Open API 이용신청 [참고](http://hnark.tistory.com/135)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "   - postman 설치 \n",
    "     - (상세 가이드: http://www.a-mean-blog.com/ko/blog/Node-JS-API/_/API-%ED%85%8C%EC%8A%A4%ED%8A%B8-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%A8-Postman-%EC%84%A4%EC%B9%98%EB%B0%8F-%EA%B0%84%EB%8B%A8-%EC%82%AC%EC%9A%A9%EB%B2%95)\n",
    "   \n",
    "   1. Chrome -> Postman 실행 (https://chrome.google.com/webstore/detail/postman/fhbjgbiflinjbdggehcddcbncdddomop/related)\n",
    "   2. Sign Up in Postman\n",
    "   3. Insert https://openapi.naver.com/v1/search/news.json?query=스마트 into GET\n",
    "   4. Add X-Naver-Client-Id(key), <font color=\"blue\">CsODwdUTyG9vOI1uIeIf</font>(value) into Headers\n",
    "   5. Add X-Naver-Client-Secret(key), <font color=\"blue\">YmIx0GW8JG</font>(value) into Headers\n",
    "   6. Send\n",
    "   ![postman.png](attachment:postman.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.2.1.1. urllib 라이브러리를 활용한 크롤링 코드**\n",
    "\n",
    "- 인터넷에 다양한 예제들이 urllib 또는 urllib2를 사용한 예제들이 많으므로, 익혀둘 필요가 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "갤럭시노트8을 사고나서 제일 먼저 할일은?\n",
      "지문인식센서 제스쳐 기능이란 <b>스마트폰</b> 화면이 켜진 상태에서 지문인식센서에 손가락을 갖다대면 화면을 끈다거나 상단의 알림트레이를 손가락으로 스와이프 하는 동작을 대신할 수 있다. 특히 갤럭시노트8은 화면이... \n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import json\n",
    "\n",
    "client_key = 'CsODwdUTyG9vOI1uIeIf'\n",
    "client_secret = 'YmIx0GW8JG'\n",
    "\n",
    "# 한글등 non-ASCII text를 URL에 넣을 수 있도록 \"%\" followed by hexadecimal digits 로 변경\n",
    "# URL은 ASCII 인코딩셋만 지원하기 때문임\n",
    "encText = urllib.parse.quote_plus(\"스마트폰\")\n",
    "# print(encText)\n",
    "\n",
    "naver_url = 'https://openapi.naver.com/v1/search/news.json?query=' + encText\n",
    "\n",
    "# urllib.request.Request()는 HTTP Header 변경시에 사용함\n",
    "# 네이버에서도 다음 HTTP Header 키를 변경해야하기 때문에 사용함\n",
    "# HTTP Header 변경이 필요없다면, 바로 urllib.request.urlopen()함수만 사용해도 됩\n",
    "request = urllib.request.Request(naver_url)\n",
    "request.add_header(\"X-Naver-Client-Id\",client_key)\n",
    "request.add_header(\"X-Naver-Client-Secret\",client_secret)\n",
    "\n",
    "# urllib.request.urlopen 메세드로 크롤링할 웹페이지를 가져옴\n",
    "response = urllib.request.urlopen(request)\n",
    "\n",
    "\n",
    "# getcode() 메서드로 HTTP 응답 상태 코드를 가져올 수 있음\n",
    "rescode = response.getcode()\n",
    "\n",
    "# HTTP 요청 응답이 정상적일 경우, 해당 HTML 데이터를 수신되었기 때문에 필요한 데이터 추출이 가능함\n",
    "# HTTP 요청에 대한 정상응답일 경우, HTTP 응답 상태 코드 값이 200이 됩니다.\n",
    "if(rescode == 200):\n",
    "    # response.read() 메서드로 수신된 HTML 데이터를 가져올 수 있음\n",
    "    response_body = response.read()\n",
    "    # 네이버 Open API를 통해서 수신된 데이터가 JSON 포멧이기 때문에, \n",
    "    # JSON 포멧 데이터를 파싱해서 사전데이터로 만들어주는 json 라이브러라를 사용\n",
    "    data = json.loads(response_body)\n",
    "    # json.loads() 메서드를 사용해서 data 에 수신된 데이터를 사전 데이터로 분석해서 자동으로 만들어줌\n",
    "    print (data['items'][0]['title'])\n",
    "    print (data['items'][0]['description'])\n",
    "else:\n",
    "    print(\"Error Code:\" + rescode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [참고: 네이버 Open API HTTP 응답 상태 에러 코드 목록1](https://developers.naver.com/docs/common/openapiguide/#/errorcode.md)\n",
    "- [참고: 일반적인 HTTP 응답 상태 코드](http://ooz.co.kr/260) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.2.1.2. requests 라이브러리를 활용한 크롤링 코드 (간결함, 권장)**\n",
    "  - [참고: 기본적인 requests 라이브러리 활용 방법](http://dgkim5360.tistory.com/entry/python-requests)\n",
    "  \n",
    "  - reqeusts 라이브러리 개발자 Keneeth Reitz 의 커멘트\n",
    "  > 파이썬 표준 urllib2 모듈은 필요한 HTTP 기능을 거의 제공하지만, 이제 너무 뒤떨어져 있습니다. 이 API는 과거에, 과거의 웹을 위해 만들어졌습니다. urllib2를 사용하려면 정말 단순한 일 하나만 하려 해도 할 일이 너무 많고, 심지어 메서드 오버라이드까지 필요할 때도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "아이폰X는 전세계에 얼마나 팔릴까?\n",
      "출처=애플 애플이 하반기 프리미엄 <b>스마트폰</b> 아이폰X를 공개한 가운데, 판매 성적에도 비상한 관심이 쏠리고 있다. 일각에서는 연내 최대 5000만대가 팔려 4분기 기준으로 세계 <b>스마트폰</b> 판매량 1위에 오를 것이라는... \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "client_key = 'CsODwdUTyG9vOI1uIeIf'\n",
    "client_secret = 'YmIx0GW8JG'\n",
    "# 별도 quote_plus() 메서드등 처리할 필요 없음. requests 객체가 알아서 해줌\n",
    "naver_url = 'https://openapi.naver.com/v1/search/news.json?query=스마트폰'\n",
    "\n",
    "header_params = {\"X-Naver-Client-Id\":client_key, \"X-Naver-Client-Secret\":client_secret}\n",
    "# headers= header_params 는 header 변경시에만 필요하고, 그렇지 않으면, requests.get(원하는 URL) 만 해도 됨\n",
    "response = requests.get(naver_url, headers = header_params)\n",
    "# 별도 json.loads() 라이브러리 메서드 사용하지 않아도, reqeusts 라이브러리에 있는 json() 메서드로 간단히 처리 가능함\n",
    "# print(response.json())\n",
    "# print(response.text)\n",
    "\n",
    "# HTTP 응답 코드는 status_code 에 저장됨\n",
    "if(response.status_code == 200):\n",
    "    data = response.json()\n",
    "    print(data['items'][0]['title'])\n",
    "    print(data['items'][0]['description'])\n",
    "else:\n",
    "    print(\"Error Code:\" + response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "**<font color=\"blue\" size=\"4em\">연습문제2</font>**\n",
    " 1. 네이버 개발자 사이트 가입하고, X-Naver-Client-Id, X-Naver-Client-Secret 키 값을 할당받습니다.\n",
    " 2. 위 두 가지 키로 네이버 검색 Open API를 사용해서 부동산 키워드로 검색 결과 중 상위 10개의 타이틀을 출력합니다.\n",
    "    (참고코드는 3.2.1.1 절, 3.2.1.2 절을 보시면 되고, 해당 코드에서 일부만 수정하시면 됩니다.)\n",
    "    \n",
    "     - [네이버 개발자 사이트](https://developers.naver.com/main/)\n",
    "     - [블로그 검색 가이드 문서](https://developers.naver.com/docs/search/blog/)\n",
    "     - 네이버 Open API 이용신청 [참고](http://hnark.tistory.com/135)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **css select**\n",
    " - CSS 선택 문법을 이용하여 태그 검색\n",
    " - select 함수 사용\n",
    " - [CSS 선택 문법 참고](https://saucelabs.com/resources/articles/selenium-tips-css-selectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "res = requests.get('http://v.media.daum.net/v/20170615203441266')\n",
    "soup = BeautifulSoup(res.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>잔금대출에도 DTI 규제 적용 검토 | Daum 뉴스</title>\n",
      "잔금대출에도 DTI 규제 적용 검토 | Daum 뉴스\n"
     ]
    }
   ],
   "source": [
    "# 태그 검색\n",
    "soup.find('title')\n",
    "\n",
    "# select 함수는 리스트 형태로 전체 반환\n",
    "title = soup.select('title')[0]\n",
    "print (title)\n",
    "print (title.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "잔금대출에도 DTI 규제 적용 검토 | Daum 뉴스\n"
     ]
    }
   ],
   "source": [
    "# 띄어쓰기가 있다면 하위 태그를 검색\n",
    "title = soup.select('html head title')[0]\n",
    "print (title.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "잔금대출에도 DTI 규제 적용 검토 | Daum 뉴스\n"
     ]
    }
   ],
   "source": [
    "# 띄어쓰기가 있다면 하위 태그를 검색\n",
    "# 이때 바로 직계의 자식이 아니여도 관계없음\n",
    "title = soup.select('html title')[0]\n",
    "print (title.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-105-444e096a6cad>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# > 를 사용하는 경우 바로 아래의 자식만 검색\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# 바로 아래 자식이 아니기 때문에 에러 발생\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtitle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'html > title'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# > 를 사용하는 경우 바로 아래의 자식만 검색\n",
    "# 바로 아래 자식이 아니기 때문에 에러 발생\n",
    "title = soup.select('html > title')[0]\n",
    "print (title.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "잔금대출에도 DTI 규제 적용 검토 | Daum 뉴스\n"
     ]
    }
   ],
   "source": [
    "# 바로 아래 자식을 검색\n",
    "title = soup.select('head > title')[0]\n",
    "print (title.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bs4.element.Tag'> 3\n",
      "내주 부동산 종합대책 발표\n",
      "집값 상승 노린 투기 분양 차단\n",
      "LTVㆍDTI 규제 다시 강화할 듯\n",
      "저소득 실수요자 피해 우려도\n",
      "\n",
      "금융당국이 급증하는 가계부채 증가세를 막기 위해 아파트 잔금대출에도 소득을 따져 대출한도를 정하는 총부채상환비율(DTI)을 적용하는 방안을 유력하게 검토하고 있다. 지금은 집값을 기준으로 대출한도를 매기는 주택담보인정비율(LTV) 규제만 적용돼 소득이 없어도 집값의 70%를 빌려 잔금을 치르는 게 가능하다. 앞으로 잔금대출에 DTI가 적용되면 소득 없는 사람이 입주 뒤 집값 상승을 노리고 분양시장에 뛰어드는 게 사실상 불가능해진다. \n",
      "금융당국 고위관계자는 15일 “잔금대출에도 DTI를 적용하는 방안을 검토 중”이라며 “다만 아직 최종 결론이 난 건 아니다”고 말했다. 정부는 내주 이 같은 내용을 포함한 부동산 종합 대책을 발표할 예정이다. \n",
      "정부가 잔금대출 DTI 적용 카드를 꺼내는 건, 집단대출을 잡지 않고선 과열된 주택시장을 진정시키기 어렵다는 판단에서다. 실제 정부는 지난해 잔금대출도 대출 초기부터 원리금을 함께 갚도록 하는 여신심사 가이드라인을 도입했지만 이렇다 할 효과를 거두지 못했다. 오히려 정부 대책에도 불구, 집단대출 증가액은 매달 늘어나는 추세인데 지난달엔 2조원으로 올 들어 최고치를 기록했다. \n",
      "아파트 분양 집단대출은 중도금과 잔금대출로 구분된다. 계약금 10%를 내면 입주 전까지 집값의 60%를 중도금 대출로 받을 수 있다. 중도금 대출은 건설사 보증으로 이뤄져 소득심사를 안 거친다. 잔금대출은 건설사가 아닌 집을 담보로 이뤄지는 대출이다. LTV 규제만 적용돼 소득이 없어도 집값의 70%까지 대출이 가능하다. 때문에 지금은 잔금대출로 집값의 70%를 대출받아 기존 중도금 대출을 갚고 나머지 20%만 본인 돈으로 충당하면 집을 살 수 있다.\n",
      "앞으로 잔금대출에 DTI가 적용되면 소득이 없는 사람은 집값의 70% 대출 받는 게 어려워진다. 입주 뒤 집값 상승을 노리는 투기수요를 확실히 걸러낼 초강력 대책이 될 수 있다. 하지만 부작용도 우려된다. 소득이 낮은 사회초년생 등은 청약통장을 갖고도 분양시장에 진입하는 게 어려워지기 때문이다. \n",
      "이에 따라 잔금대출에 DTI를 적용하는 것 역시 지역 등에 따라 선별적으로 이뤄질 가능성이 높다. 현재 당국은 신규 분양 물량부터 규제를 적용할지 아니면 기존 분양 물량까지 규제 범위를 확대할지를 놓고 시뮬레이션을 하고 있다. \n",
      "아울러 당국은 지난 2년간 완화됐던 LTV와 DTI를 다시 강화할 것으로 보인다. 현재 LTV(은행 기준)는 기존 50~60%에서 70%, DTI는 50~60%에서 60%로 완화돼 있는 상태다. 당국은 일괄적인 조이기보다 지역ㆍ집값 수준별로 기준을 다르게 적용하는 방식을 모색할 것으로 보인다.\n",
      "김동욱 기자 kdw1280@hankookilbo.com\n"
     ]
    }
   ],
   "source": [
    "# .은 태그의 클래스를 검색\n",
    "# class가 article_view인 태그 탐색\n",
    "body = soup.select('.article_view')[0]\n",
    "print (type(body), len(body))\n",
    "for p in body.find_all('p'):\n",
    "    print (p.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bs4.element.Tag'> 3\n",
      "내주 부동산 종합대책 발표\n",
      "집값 상승 노린 투기 분양 차단\n",
      "LTVㆍDTI 규제 다시 강화할 듯\n",
      "저소득 실수요자 피해 우려도\n",
      "\n",
      "금융당국이 급증하는 가계부채 증가세를 막기 위해 아파트 잔금대출에도 소득을 따져 대출한도를 정하는 총부채상환비율(DTI)을 적용하는 방안을 유력하게 검토하고 있다. 지금은 집값을 기준으로 대출한도를 매기는 주택담보인정비율(LTV) 규제만 적용돼 소득이 없어도 집값의 70%를 빌려 잔금을 치르는 게 가능하다. 앞으로 잔금대출에 DTI가 적용되면 소득 없는 사람이 입주 뒤 집값 상승을 노리고 분양시장에 뛰어드는 게 사실상 불가능해진다. \n",
      "금융당국 고위관계자는 15일 “잔금대출에도 DTI를 적용하는 방안을 검토 중”이라며 “다만 아직 최종 결론이 난 건 아니다”고 말했다. 정부는 내주 이 같은 내용을 포함한 부동산 종합 대책을 발표할 예정이다. \n",
      "정부가 잔금대출 DTI 적용 카드를 꺼내는 건, 집단대출을 잡지 않고선 과열된 주택시장을 진정시키기 어렵다는 판단에서다. 실제 정부는 지난해 잔금대출도 대출 초기부터 원리금을 함께 갚도록 하는 여신심사 가이드라인을 도입했지만 이렇다 할 효과를 거두지 못했다. 오히려 정부 대책에도 불구, 집단대출 증가액은 매달 늘어나는 추세인데 지난달엔 2조원으로 올 들어 최고치를 기록했다. \n",
      "아파트 분양 집단대출은 중도금과 잔금대출로 구분된다. 계약금 10%를 내면 입주 전까지 집값의 60%를 중도금 대출로 받을 수 있다. 중도금 대출은 건설사 보증으로 이뤄져 소득심사를 안 거친다. 잔금대출은 건설사가 아닌 집을 담보로 이뤄지는 대출이다. LTV 규제만 적용돼 소득이 없어도 집값의 70%까지 대출이 가능하다. 때문에 지금은 잔금대출로 집값의 70%를 대출받아 기존 중도금 대출을 갚고 나머지 20%만 본인 돈으로 충당하면 집을 살 수 있다.\n",
      "앞으로 잔금대출에 DTI가 적용되면 소득이 없는 사람은 집값의 70% 대출 받는 게 어려워진다. 입주 뒤 집값 상승을 노리는 투기수요를 확실히 걸러낼 초강력 대책이 될 수 있다. 하지만 부작용도 우려된다. 소득이 낮은 사회초년생 등은 청약통장을 갖고도 분양시장에 진입하는 게 어려워지기 때문이다. \n",
      "이에 따라 잔금대출에 DTI를 적용하는 것 역시 지역 등에 따라 선별적으로 이뤄질 가능성이 높다. 현재 당국은 신규 분양 물량부터 규제를 적용할지 아니면 기존 분양 물량까지 규제 범위를 확대할지를 놓고 시뮬레이션을 하고 있다. \n",
      "아울러 당국은 지난 2년간 완화됐던 LTV와 DTI를 다시 강화할 것으로 보인다. 현재 LTV(은행 기준)는 기존 50~60%에서 70%, DTI는 50~60%에서 60%로 완화돼 있는 상태다. 당국은 일괄적인 조이기보다 지역ㆍ집값 수준별로 기준을 다르게 적용하는 방식을 모색할 것으로 보인다.\n",
      "김동욱 기자 kdw1280@hankookilbo.com\n"
     ]
    }
   ],
   "source": [
    "# div태그 중 class가 article_view인 태그 탐색\n",
    "body = soup.select('div.article_view')[0]\n",
    "print (type(body), len(body))\n",
    "for p in body.find_all('p'):\n",
    "    print (p.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<div class=\"article_view\" id=\"harmonyContainer\">\n",
      "<section dmcf-sid=\"LkDx6tL1qA\">\n",
      "<p dmcf-pid=\"L87lbwLTl1\" dmcf-ptype=\"general\">\"대화하겠지만 정부 지켜야 할 선 있어\"</p>\n",
      "<figure class=\"figure_frm origin_fig\" dmcf-pid=\"LebrjM7CEC\" dmcf-ptype=\"figure\">\n",
      "<p class=\"link_figure\"><img alt=\"【서울=뉴시스】고범준 기자 = 박춘란 교육부 차관이 16일 오후 서울 종로구 정부서울청사에서 한국유치원총연합회(한유총)의 불법 집단휴원과 관련해 브리핑을 하고 있다.한편 한국유치원총연합회(한유총)는 오는 18일 전국 사립유치원의 집단 휴업을 강행한다고 발표했다. 2017.09.16. bjko@newsis.com\" class=\"thumb_g\" dmcf-mid=\"L1aKI2hH9D\" dmcf-mtype=\"image\" height=\"254\" src=\"https://img2.daumcdn.net/thumb/R658x0.q70/?fname=https://t1.daumcdn.net/news/201709/16/newsis/20170916154441854drre.jpg\" width=\"499\"/></p>\n",
      "<figcaption class=\"txt_caption default_figure\">\n",
      "           【서울=뉴시스】고범준 기자 = 박춘란 교육부 차관이 16일 오후 서울 종로구 정부서울청사에서 한국유치원총연합회(한유총)의 불법 집단휴원과 관련해 브리핑을 하고 있다.한편 한국유치원총연합회(한유총)는 오는 18일 전국 사립유치원의 집단 휴업을 강행한다고 발표했다. 2017.09.16. bjko@newsis.com\n",
      "          </figcaption>\n",
      "</figure>\n",
      "<p dmcf-pid=\"LYsxfJn62U\" dmcf-ptype=\"general\">【서울=뉴시스】임재희 기자 = 정부가 집단 휴업 철회를 번복하고 18일 휴업을 강행하는 사립유치원에 대해 행·재정조치는 물론 강도 높은 감사를 추진해 책임을 묻기로 했다.</p>\n",
      "<p dmcf-pid=\"LtYJDwAiMt\" dmcf-ptype=\"general\">지난 15일 집단 휴업 철회 의사를 밝혔던 한국유치원총연합회(한유총)는 같은 날 자정께 \"한유총 전 회원들은 교육부가 합의를 파기한 것으로 판단하고 기존대로 1차 휴업을 강행하기로 했다\"고 발표했다.</p>\n",
      "<p dmcf-pid=\"LLtEfoAjp9\" dmcf-ptype=\"general\">이와 관련해 교육부는 16일 집단 휴업에 참여한 모든 사립유치원에 대해 ▲원장 등에게 직접 지원하는 재정지원금 환수 및 정원감축 ▲모집정지 ▲유치원 폐쇄 ▲기납부 원비 환불조치 등의 행·재정조치를 시·도 교육청과 함께 적극 추진한다. 아울러 운영 전반에 대해 우선적으로 강도 높은 감사를 추진한다.</p>\n",
      "<p dmcf-pid=\"L646PBRJ8y\" dmcf-ptype=\"general\">신익현 교육부 지방교육지원국장은 \"예외는 없다\"면서도 휴업을 주도한 사립유치원 등에 대해선 \"시도교육감들이 행정조치의 권한자이기 때문에 시도교육청과 내일 협의해서 바로 월요일 18일 휴업에 가담한 분들에 대한 적절한 조치가 바로 이뤄질 수 있도록 나갈 계획\"이라고 말했다.</p>\n",
      "<p dmcf-pid=\"L9wLjCbjBQ\" dmcf-ptype=\"general\">현재 한유총 측은 ▲국공립·사립 간 무상교육비 균등지원 보장 ▲바우처 방식 유아교육비 지원을 통한 학부모 선택권 보장 ▲설립자 기여금 보장 등 기존 합의안에 포함돼 있던 내용을 교육부가 '파기했다'고 주장하고 있다.</p>\n",
      "<p dmcf-pid=\"LBAiw97qbk\" dmcf-ptype=\"general\">이에대해 신 국장은 \"어제 모든 것을 열어놓고 한유총 등 사립유치원과 대화하고 모든 가능성을 열어놓고 시작을 하자는 의미였다\"며 기본 방향에 대해 합의를 하고 제가 그 문구를 말씀드린 것\"이라고 반박했다.</p>\n",
      "<p dmcf-pid=\"Ljza1kkHT4\" dmcf-ptype=\"general\">이 가운데 유아교육비 지원 방식을 바우처로 전환하는 방안에 대해 교육부는 기술적인 부분으로 판단하고 있다. 다만 설립자 기여금 인정 등의 문제를 한유총 측의 요구대로 시기와 방법에 대해 구체적으로 표기할 수 없다는 입장이다.</p>\n",
      "<p dmcf-pid=\"Lp7oTwJ9a6\" dmcf-ptype=\"general\">신 국장은 \"교육부는 사립유치원 경영자만을 대상으로 할 수 없다. 세금이 들어가고 막대한 예산이 들어가고 학습자인 아이가 있고 학부모가 있기 때문이다. 사립유치원 설립 경영자에게 직접적으로 지원이 갈 수 있게 제도 개선을 언제까지 해달라는 등의 부분은 저희가 수용하기 어려운 부분\"이라고 했다.</p>\n",
      "<p dmcf-pid=\"LWrATVAJnm\" dmcf-ptype=\"general\">앞으로의 대화 가능성을 묻는 말에 그는 \"사립유치원 분들도 교육자이기 때문에 극단적인 행동을 지속하지 않을 거란 믿음이 있어 계속 대화를 할 것\"이라면서도 \"저와 정부가 지켜야 하는 선이 분명히 있기 때문에 침해되는 부분은 법과 원칙에 따라 단호하게 집행해야 한다\"고 답했다.</p>\n",
      "<p dmcf-pid=\"Lq8XEh6QhX\" dmcf-ptype=\"general\">한편 교육부는 18일 집단 휴업에 대비해 각 시도교육청에 임시상황반을 구성하고 공립유치원, 초등돌봄교실 등을 활용한 '유아 임시 서비스'를 마련하고 있다. 아울러 보건복지부, 여성가족부, 시도 지방자치단체 등과 어린이집·아이돌봄서비스 등을 유아 돌봄에 투입할 계획이다.</p>\n",
      "<p dmcf-pid=\"LIg046uhpa\" dmcf-ptype=\"general\">교육부에 따르면 현재 전국 17개 시도 중 대전, 울산, 충남, 경북, 제주, 광주, 세종 등 7개 시도 사립유치원들은 집단 휴업 불참 의사를 밝혔다.</p>\n",
      "<p dmcf-pid=\"LfDhxnWvVw\" dmcf-ptype=\"general\">다음은 박춘란 교육부 차관, 신익현 지방교육지원국장과의 일문일답.</p>\n",
      "<p dmcf-pid=\"Ly0URmcnmY\" dmcf-ptype=\"general\">-제재 기준은 어떻게 되나? 휴업을 주도하는 곳엔 더 강한 조치가 이뤄지나?</p>\n",
      "<p dmcf-pid=\"Lq444a8c5K\" dmcf-ptype=\"general\">(박춘란 차관) \"참여하는 사립유치원 모두에게 제재 조치를 한다.\"</p>\n",
      "<p dmcf-pid=\"L5RFjLtd5k\" dmcf-ptype=\"general\">(신익현 국장) \"예외는 없다. 다만 1차와 2차 휴업이 예고돼 있는 상황에서 적극적으로 가담한 정도 이런 것들을 시도교육감들이 행정조치의 권한자이기 때문에 시도교육청과 내일 협의해서 바로 월요일 18일 휴업에 가담한 분들에 대한 적절한 조치가 바로 이뤄질 수 있도록 나갈 계획이다.\"</p>\n",
      "<p dmcf-pid=\"LQD0eeX9li\" dmcf-ptype=\"general\">-임시 돌봄서비스 이용률이 저조하다는 지적이 나온다.</p>\n",
      "<p dmcf-pid=\"LoT72iTpeN\" dmcf-ptype=\"general\">(박 차관) \"아직 신청이 부족한 것으로 알고 있다. 더욱 홍보해나갈 것이다. 이미 각 시도교육청에 임시상황반을 운영하고 있다. 돌봄서비스 제공을 안내해나가면서 그 부분 조치해 나가겠다.\"</p>\n",
      "<p dmcf-pid=\"LPb6JM4zx6\" dmcf-ptype=\"general\">(신 국장) \"돌봄 수요와 관련 17개 시도 중 7개 시도는 휴업에 참여하지 않겠다고 오전에 합의됐다. 대전, 울산, 충남, 경북, 제주, 광주, 세종 등이다. 나머지 10개 교육청이 있는데 참여하는 휴업에 하겠다고 얘기하는 사립유치원도 '최소한의 돌봄은 하겠다'고 이야기를 하고 있다. 그렇기 때문에 실질적으로 사립유치원 중 맞벌이 가정 등 (수요 파악을) 토대로 국공립유치원과 초등 병설유치원, 기타 교육청 모든 인프라를 총 동원해 돌봄서비스 받게 하고 있다. 그런데 인프라 수용 인원이 여유가 있을 정도로 수요가 아직 없지만 오늘, 내일 중 상황 변화가 있고 적극적으로 알려드리고 시도도 준비하게 되면 수요가 늘어나지 않을까 한다. 전제척인 상황은 그런 맥락에서 이뤄지고 있고 현재까지 준비에는 문제가 없다.\"</p>\n",
      "<p dmcf-pid=\"LQrEqDUscy\" dmcf-ptype=\"general\">-한유총에선 기존에 제시한 협상안엔 바우처, 설립자 재산권 보존 방안 등이 들어가 있었는데 교육부가 보낸 자료에는 없었다고 주장한다.</p>\n",
      "<p dmcf-pid=\"LTqiMR0Soo\" dmcf-ptype=\"general\">(신 국장) \"저희가 어제 이렇게 말씀드린 것은 모든 것을 열어놓고 한유총의 사립유치원과 대화하고 모든 가능성을 열어놓고 시작을 하자는 의미였다. 기본 방향에 대해서 합의를 하고 제가 그 문구를 말씀드린 것이다. 그 안에 방금 말씀하신 지급방식에 대한 부분 중 상대적으로 기술적인 부분에 해당할 수 있다. 기본 방향에 포함된다. 다만 한유총이 말하는 부분은 한유총 측에서 꼭 듣기를 원하는 답이 있다. 시기와 방법을 구체화해 달라는 것이다. 그러나 교육부는 사립유치원 경영자만을 대상으로 할 수 없다. 세금이 들어가고 막대한 예산이 들어가고 학습자인 아이가 있고 학부모가 있기 때문이다. 사립유치원 설립 경영자에게 직접적으로 지원이 갈 수 있게 제도 개선을 언제까지 해달라는 등의 부분은 저희가 수용하기 어려운 부분이다. 당장 수용하기 어려운 부분들을 토대로 '이런저런 이야기들이 파기다', '문구 조정' 이런 차원의 문제 아니다. 어제 방식은 모든 걸 열어 놨다. 한유총 수석부이사장님도 어제 교육부의 진정성 믿고 가본다고 했는데 그것이 그런 부분이다. 지금도 변함없다. 그러나 안 되는 건 안 되는 것이다. 그 부분까지 무리하게 강조하는 걸 토대로 이렇게 아이들에게 하는 부분까지는 공직자로서 납득하기 어려운 부분이 있다.\"</p>\n",
      "<p dmcf-pid=\"LH2bjnazVo\" dmcf-ptype=\"general\">-어제 긴급 간담회 이후 상황을 설명해 달라.</p>\n",
      "<p dmcf-pid=\"LjQcntTf12\" dmcf-ptype=\"general\">(신 국장) \"법과 원칙에서 지켜야 할 부분은 분명하게 지키고 한 치 양보도 없이 가야한다는 입장이다. 하지만 사립유치원에도 아이들이 있기 때문에 안고 가야한다는 입장이다. 그렇기 때문에 지금도 대화를 하고, 계속 혹시라도 저희가 도와드릴 부분 없는지 지금도 대화를 나누고 있다. 어제 저한테 연락이 당연히 왔었고 (합의안을) 토대로 제 생각을 말씀드리고 도와드리고 말씀드리고 했던 부분까지 교류했다. 저희쪽에는 통보 없었다. (휴업 철회 번복 사실도) 언론 보도를 통해 알았다.\"</p>\n",
      "<p dmcf-pid=\"LysM03upFx\" dmcf-ptype=\"general\">-교육부에선 이런 상황 예상 못햇나.</p>\n",
      "<p dmcf-pid=\"LFm1ch3h0O\" dmcf-ptype=\"general\">(신 국장) \"예상하고 싶지 않았다. 사실 저희는 18일 상황에 대비해 목요일까지 대체적인 준비체제는 마쳤다. 시도교육청에 임시돌봄 서비스도 14일까지 준비해놨다. 저희는 아이들의 안전과 학부모님들 불편이 최우선이기 때문이다. 다만 어제 큰 틀의 합의를 토대로 시간을 갖고 대화의 기회로 삼아서 하나씩 하나씩 해결을 하기 위한 좋은 기회라고 생각했다. 그런데 어떻게 보면 한유총 중요하지만 정부 측에선 받을 수가 없는 그런 국민 전체적으로 볼 때는 이해하기 어려운 부분들을 토대로 결과적으로 우려스러운 부분이 반복되는 것 같아 마음이 굉장히 무겁다.\"</p>\n",
      "<p dmcf-pid=\"LLeVOQCPzn\" dmcf-ptype=\"general\">-계속 대화해 나갈 용의 있나. 대화가 제대로 되지 않으면 징계 외에 다른 대책 강구할 건가.</p>\n",
      "<p dmcf-pid=\"LPu7FhDwez\" dmcf-ptype=\"general\">(신 국장) \"저는 사립유치원의분들도 교육자시기 때문에 극단적인 행동이나 지속적으로 하지 않으실 거란 믿음이 있다. 믿음은 어제도 오늘도 내일도 없다. 계속 대화를 할 것이다. 그러나 지킬 수 있는 선, 정부가 지켜야 하는 선은 분명히 있기 때문에 침해 되는 부분은 법과 원칙에 따라 단호하게 집행해야 한다.\"</p>\n",
      "<p dmcf-pid=\"LWmBWyGL5J\" dmcf-ptype=\"general\">limj@newsis.com</p>\n",
      "</section>\n",
      "</div>]\n"
     ]
    }
   ],
   "source": [
    "# div 태그 중 id가 harmonyContainer인 태그 탐색\n",
    "container = soup.select('#harmonyContainer')\n",
    "print (container)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "내주 부동산 종합대책 발표\n",
      "집값 상승 노린 투기 분양 차단\n",
      "LTVㆍDTI 규제 다시 강화할 듯\n",
      "저소득 실수요자 피해 우려도\n",
      "\n",
      "\n",
      "\n",
      "금융당국이 급증하는 가계부채 증가세를 막기 위해 아파트 잔금대출에도 소득을 따져 대출한도를 정하는 총부채상환비율(DTI)을 적용하는 방안을 유력하게 검토하고 있다. 지금은 집값을 기준으로 대출한도를 매기는 주택담보인정비율(LTV) 규제만 적용돼 소득이 없어도 집값의 70%를 빌려 잔금을 치르는 게 가능하다. 앞으로 잔금대출에 DTI가 적용되면 소득 없는 사람이 입주 뒤 집값 상승을 노리고 분양시장에 뛰어드는 게 사실상 불가능해진다. \n",
      "금융당국 고위관계자는 15일 “잔금대출에도 DTI를 적용하는 방안을 검토 중”이라며 “다만 아직 최종 결론이 난 건 아니다”고 말했다. 정부는 내주 이 같은 내용을 포함한 부동산 종합 대책을 발표할 예정이다. \n",
      "정부가 잔금대출 DTI 적용 카드를 꺼내는 건, 집단대출을 잡지 않고선 과열된 주택시장을 진정시키기 어렵다는 판단에서다. 실제 정부는 지난해 잔금대출도 대출 초기부터 원리금을 함께 갚도록 하는 여신심사 가이드라인을 도입했지만 이렇다 할 효과를 거두지 못했다. 오히려 정부 대책에도 불구, 집단대출 증가액은 매달 늘어나는 추세인데 지난달엔 2조원으로 올 들어 최고치를 기록했다. \n",
      "아파트 분양 집단대출은 중도금과 잔금대출로 구분된다. 계약금 10%를 내면 입주 전까지 집값의 60%를 중도금 대출로 받을 수 있다. 중도금 대출은 건설사 보증으로 이뤄져 소득심사를 안 거친다. 잔금대출은 건설사가 아닌 집을 담보로 이뤄지는 대출이다. LTV 규제만 적용돼 소득이 없어도 집값의 70%까지 대출이 가능하다. 때문에 지금은 잔금대출로 집값의 70%를 대출받아 기존 중도금 대출을 갚고 나머지 20%만 본인 돈으로 충당하면 집을 살 수 있다.\n",
      "앞으로 잔금대출에 DTI가 적용되면 소득이 없는 사람은 집값의 70% 대출 받는 게 어려워진다. 입주 뒤 집값 상승을 노리는 투기수요를 확실히 걸러낼 초강력 대책이 될 수 있다. 하지만 부작용도 우려된다. 소득이 낮은 사회초년생 등은 청약통장을 갖고도 분양시장에 진입하는 게 어려워지기 때문이다. \n",
      "이에 따라 잔금대출에 DTI를 적용하는 것 역시 지역 등에 따라 선별적으로 이뤄질 가능성이 높다. 현재 당국은 신규 분양 물량부터 규제를 적용할지 아니면 기존 분양 물량까지 규제 범위를 확대할지를 놓고 시뮬레이션을 하고 있다. \n",
      "아울러 당국은 지난 2년간 완화됐던 LTV와 DTI를 다시 강화할 것으로 보인다. 현재 LTV(은행 기준)는 기존 50~60%에서 70%, DTI는 50~60%에서 60%로 완화돼 있는 상태다. 당국은 일괄적인 조이기보다 지역ㆍ집값 수준별로 기준을 다르게 적용하는 방식을 모색할 것으로 보인다.\n",
      "김동욱 기자 kdw1280@hankookilbo.com\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# div태그 중 id가 mArticle 인 태그의 하위 태그 중 아이디가 article_title인 태그\n",
    "title = soup.select('div#mArticle  div#harmonyContainer')[0]\n",
    "print (title.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://sports.media.daum.net/sports\n",
      "http://search.daum.net/search?w=tot&DA=23W&rtmaxcoll=Z8T&q=서울특별시날씨\n",
      "http://search.daum.net/search?w=tot&DA=23W&rtmaxcoll=Z8T&q=수원시 권선구날씨\n",
      "http://search.daum.net/search?w=tot&DA=23W&rtmaxcoll=Z8T&q=인천광역시날씨\n",
      "http://search.daum.net/search?w=tot&DA=23W&rtmaxcoll=Z8T&q=대구광역시날씨\n",
      "http://search.daum.net/search?w=tot&DA=23W&rtmaxcoll=Z8T&q=대전광역시날씨\n",
      "http://search.daum.net/search?w=tot&DA=23W&rtmaxcoll=Z8T&q=광주광역시날씨\n",
      "http://search.daum.net/search?w=tot&DA=23W&rtmaxcoll=Z8T&q=부산광역시날씨\n",
      "http://search.daum.net/search?w=tot&DA=23W&rtmaxcoll=Z8T&q=울산광역시날씨\n",
      "http://search.daum.net/search?w=tot&DA=23W&rtmaxcoll=Z8T&q=울릉군날씨\n",
      "http://search.daum.net/search?w=tot&DA=23W&rtmaxcoll=Z8T&q=춘천시날씨\n",
      "http://search.daum.net/search?w=tot&DA=23W&rtmaxcoll=Z8T&q=강릉시날씨\n",
      "http://search.daum.net/search?w=tot&DA=23W&rtmaxcoll=Z8T&q=백령면날씨\n",
      "http://search.daum.net/search?w=tot&DA=23W&rtmaxcoll=Z8T&q=청주시 상당구날씨\n",
      "http://search.daum.net/search?w=tot&DA=23W&rtmaxcoll=Z8T&q=전주시 완산구날씨\n",
      "http://search.daum.net/search?w=tot&DA=23W&rtmaxcoll=Z8T&q=목포시날씨\n",
      "http://search.daum.net/search?w=tot&DA=23W&rtmaxcoll=Z8T&q=여수시날씨\n",
      "http://search.daum.net/search?w=tot&DA=23W&rtmaxcoll=Z8T&q=제주특별자치도날씨\n",
      "http://search.daum.net/search?w=tot&DA=23W&rtmaxcoll=Z8T&q=안동시날씨\n",
      "http://search.daum.net/search?w=tot&DA=23W&rtmaxcoll=Z8T&q=창원시 의창구날씨\n",
      "http://v.media.daum.net/v/20170916070410344\n",
      "http://v.media.daum.net/v/20170916070410344\n",
      "http://v.media.daum.net/v/20170915232122548\n",
      "http://v.media.daum.net/v/20170915103230504\n",
      "http://v.media.daum.net/v/20170915102957366\n",
      "http://v.media.daum.net/v/20170916044251311\n",
      "http://v.media.daum.net/v/20170916044251311\n",
      "http://v.media.daum.net/v/20170916030222904\n",
      "http://v.media.daum.net/v/20170916011537371\n",
      "http://v.media.daum.net/v/20170915185902464\n",
      "http://v.media.daum.net/v/20170916033622124\n",
      "http://v.media.daum.net/v/20170915150747489\n",
      "http://v.media.daum.net/v/20170915105603331\n",
      "http://v.media.daum.net/v/20170915084258568\n",
      "http://v.media.daum.net/v/20170916030119848\n",
      "http://v.media.daum.net/v/20170916030119848\n",
      "http://v.media.daum.net/v/20170915213506424\n",
      "http://v.media.daum.net/v/20170915170708806\n",
      "http://v.media.daum.net/v/20170915103504590\n",
      "http://v.media.daum.net/v/20170915211507104\n",
      "http://v.media.daum.net/v/20170915211507104\n",
      "http://v.media.daum.net/v/20170915180140367\n",
      "http://v.media.daum.net/v/20170915164703227\n",
      "http://v.media.daum.net/v/20170916140103841\n",
      "http://v.media.daum.net/v/20170916140103841\n",
      "http://v.media.daum.net/v/20170909140103098\n",
      "http://v.media.daum.net/v/20170902140104281\n",
      "http://v.media.daum.net/v/20170825194602752\n",
      "http://v.media.daum.net/v/20170916090013176\n",
      "http://v.media.daum.net/v/20170916090013176\n",
      "http://v.media.daum.net/v/20170909090016232\n",
      "http://v.media.daum.net/v/20170902090018632\n",
      "http://v.media.daum.net/v/20170826090025529\n",
      "http://v.media.daum.net/v/20170916145844498\n",
      "http://v.media.daum.net/v/20170916124836295\n",
      "http://v.media.daum.net/v/20170916124836295\n",
      "http://v.media.daum.net/v/20170916134540719\n",
      "http://v.media.daum.net/v/20170916050303400\n",
      "http://v.media.daum.net/v/20170916011416365\n",
      "http://v.media.daum.net/v/20170916124836295\n",
      "http://v.media.daum.net/v/20170915174005771\n",
      "http://v.media.daum.net/v/20170915174005771\n",
      "http://v.media.daum.net/v/20170915181329653\n",
      "http://v.media.daum.net/v/20170916070410344\n",
      "http://v.media.daum.net/v/20170916080026736\n",
      "http://v.media.daum.net/v/20170915185045320\n",
      "http://v.media.daum.net/v/20170916044251311\n",
      "http://v.media.daum.net/v/20170916134540719\n",
      "http://v.media.daum.net/v/20170916010116289\n",
      "http://v.media.daum.net/v/20170916050303400\n",
      "http://v.media.daum.net/v/20170916050303400\n",
      "http://v.media.daum.net/v/20170916152752789\n",
      "http://v.media.daum.net/v/20170916143005105\n",
      "http://v.media.daum.net/v/20170916140103841\n",
      "http://v.media.daum.net/v/20170916134540719\n",
      "http://v.media.daum.net/v/20170916130508423\n",
      "http://v.media.daum.net/v/20170916125401328\n",
      "http://v.media.daum.net/v/20170916124836295\n",
      "http://v.media.daum.net/v/20170916120108987\n",
      "http://v.media.daum.net/v/20170916110101442\n",
      "http://v.media.daum.net/v/20170916152253742\n",
      "http://v.media.daum.net/v/20170916152253742\n",
      "http://v.media.daum.net/v/20170916140103841\n",
      "http://v.media.daum.net/v/20170916140103841\n",
      "http://search.daum.net/search?w=tot&DA=23R&rtmaxcoll=HSU&q=코스피\n",
      "http://search.daum.net/search?w=tot&DA=23R&rtmaxcoll=HSU&q=코스피\n",
      "http://search.daum.net/search?w=tot&DA=23R&rtmaxcoll=HSU&q=코스피\n",
      "http://search.daum.net/search?w=tot&DA=23R&rtmaxcoll=HSU&q=코스피\n",
      "http://search.daum.net/search?w=tot&DA=23R&rtmaxcoll=HSU&q=코스닥\n",
      "http://search.daum.net/search?w=tot&DA=23R&rtmaxcoll=HSU&q=코스닥\n",
      "http://search.daum.net/search?w=tot&DA=23R&rtmaxcoll=HSU&q=코스닥\n",
      "http://search.daum.net/search?w=tot&DA=23R&rtmaxcoll=HSU&q=코스닥\n",
      "http://search.daum.net/search?w=tot&DA=23R&rtmaxcoll=HSU&q=다우\n",
      "http://search.daum.net/search?w=tot&DA=23R&rtmaxcoll=HSU&q=다우\n",
      "http://search.daum.net/search?w=tot&DA=23R&rtmaxcoll=HSU&q=다우\n",
      "http://search.daum.net/search?w=tot&DA=23R&rtmaxcoll=HSU&q=다우\n",
      "http://search.daum.net/search?w=tot&DA=23R&rtmaxcoll=HSU&q=나스닥\n",
      "http://search.daum.net/search?w=tot&DA=23R&rtmaxcoll=HSU&q=나스닥\n",
      "http://search.daum.net/search?w=tot&DA=23R&rtmaxcoll=HSU&q=나스닥\n",
      "http://search.daum.net/search?w=tot&DA=23R&rtmaxcoll=HSU&q=나스닥\n",
      "http://search.daum.net/search?w=tot&DA=23R&rtmaxcoll=Z6T&q=미국환율\n",
      "http://search.daum.net/search?w=tot&DA=23R&rtmaxcoll=Z6T&q=미국환율\n",
      "http://search.daum.net/search?w=tot&DA=23R&rtmaxcoll=Z6T&q=미국환율\n",
      "http://search.daum.net/search?w=tot&DA=23R&rtmaxcoll=Z6T&q=미국환율\n",
      "http://search.daum.net/search?w=tot&DA=23R&rtmaxcoll=Z6T&q=일본환율\n",
      "http://search.daum.net/search?w=tot&DA=23R&rtmaxcoll=Z6T&q=일본환율\n",
      "http://search.daum.net/search?w=tot&DA=23R&rtmaxcoll=Z6T&q=일본환율\n",
      "http://search.daum.net/search?w=tot&DA=23R&rtmaxcoll=Z6T&q=일본환율\n",
      "http://search.daum.net/search?w=tot&DA=23R&rtmaxcoll=Z6T&q=유로환율\n",
      "http://search.daum.net/search?w=tot&DA=23R&rtmaxcoll=Z6T&q=유로환율\n",
      "http://search.daum.net/search?w=tot&DA=23R&rtmaxcoll=Z6T&q=유로환율\n",
      "http://search.daum.net/search?w=tot&DA=23R&rtmaxcoll=Z6T&q=유로환율\n",
      "http://search.daum.net/search?w=tot&DA=23R&rtmaxcoll=Z6T&q=중국환율\n",
      "http://search.daum.net/search?w=tot&DA=23R&rtmaxcoll=Z6T&q=중국환율\n",
      "http://search.daum.net/search?w=tot&DA=23R&rtmaxcoll=Z6T&q=중국환율\n",
      "http://search.daum.net/search?w=tot&DA=23R&rtmaxcoll=Z6T&q=중국환율\n",
      "http://search.daum.net/search?w=tot&DA=23R&rtmaxcoll=BDS&q=아파트시세\n",
      "http://search.daum.net/search?w=tot&DA=23R&rtmaxcoll=BDS&q=아파트시세\n",
      "http://search.daum.net/search?w=tot&DA=23R&rtmaxcoll=BDS&q=아파트시세\n",
      "http://search.daum.net/search?w=tot&DA=23R&rtmaxcoll=BDS&q=아파트시세\n",
      "http://search.daum.net/search?w=tot&DA=23R&rtmaxcoll=BDS&q=아파트시세\n",
      "http://search.daum.net/search?w=tot&DA=23R&rtmaxcoll=BDS&q=아파트시세\n",
      "http://search.daum.net/search?w=tot&DA=23R&rtmaxcoll=BDS&q=아파트시세\n",
      "http://search.daum.net/search?w=tot&DA=23R&rtmaxcoll=BDS&q=아파트시세\n",
      "http://search.daum.net/search?w=tot&DA=23R&rtmaxcoll=BDS&q=아파트시세\n",
      "http://search.daum.net/search?w=tot&DA=23R&rtmaxcoll=BDS&q=아파트시세\n",
      "http://search.daum.net/search?w=tot&DA=23R&q=유가\n",
      "http://search.daum.net/search?w=tot&DA=23R&q=유가\n",
      "http://search.daum.net/search?w=tot&DA=23R&q=유가\n",
      "http://search.daum.net/search?w=tot&DA=23R&q=유가\n",
      "http://search.daum.net/search?w=tot&DA=23R&q=유가\n",
      "http://search.daum.net/search?w=tot&DA=23R&q=유가\n",
      "http://search.daum.net/search?w=tot&DA=23R&q=유가\n",
      "http://search.daum.net/search?w=tot&DA=23R&q=유가\n",
      "http://search.daum.net/search?w=tot&DA=23R&q=유가\n",
      "http://v.media.daum.net/v/20170916110251463\n",
      "http://v.media.daum.net/v/20170916125613346\n",
      "http://v.media.daum.net/v/20170916134540719\n",
      "http://v.media.daum.net/v/20170916130031377\n",
      "http://v.media.daum.net/v/20170916060308680\n",
      "http://v.media.daum.net/v/20170916135601809\n",
      "http://v.media.daum.net/v/20170916080014728\n",
      "http://v.media.daum.net/v/20170916063044959\n",
      "http://v.media.daum.net/v/20170916125043305\n",
      "http://v.media.daum.net/v/20170916133122618\n",
      "http://v.media.daum.net/v/20170916092937528\n",
      "http://v.media.daum.net/v/20170916081102838\n",
      "http://v.media.daum.net/v/20170916141742991\n",
      "http://v.media.daum.net/v/20170916130306404\n",
      "http://v.media.daum.net/v/20170916125436333\n",
      "http://v.media.daum.net/v/20170916100146842\n",
      "http://v.media.daum.net/v/20170916141441960\n",
      "http://v.media.daum.net/v/20170916095743775\n",
      "http://v.media.daum.net/v/20170916110354472\n",
      "http://v.media.daum.net/v/20170916141550973\n",
      "http://v.media.daum.net/v/20170916044249309\n",
      "http://v.media.daum.net/v/20170916050303400\n",
      "http://v.media.daum.net/v/20170916143016107\n",
      "http://v.media.daum.net/v/20170916090720345\n",
      "http://v.media.daum.net/v/20170916100018804\n",
      "http://v.media.daum.net/v/20170916070107259\n",
      "http://v.media.daum.net/v/20170916143610179\n",
      "http://v.media.daum.net/v/20170916065005098\n",
      "http://v.media.daum.net/v/20170916080104746\n",
      "http://v.media.daum.net/v/20170916124836295\n",
      "http://v.media.daum.net/v/20170916122435125?s=eRIGHT_MANY_TOT=R\n",
      "http://v.media.daum.net/v/20170916065304140?s=eRIGHT_MANY_TOT=R\n",
      "http://v.media.daum.net/v/20170916133900676?s=eRIGHT_MANY_TOT=R\n",
      "http://v.media.daum.net/v/20170916095028719?s=eRIGHT_MANY_TOT=R\n",
      "http://v.media.daum.net/v/20170916104403293?s=eRIGHT_MANY_TOT=R\n",
      "http://v.media.daum.net/v/20170916090403294?s=eRIGHT_MANY_TOT=R\n",
      "http://v.media.daum.net/v/20170916133515656?s=eRIGHT_MANY_TOT=R\n",
      "http://v.media.daum.net/v/20170916122203107?s=eRIGHT_MANY_TOT=R\n",
      "http://v.media.daum.net/v/20170916110007423?s=eRIGHT_MANY_TOT=R\n",
      "http://v.media.daum.net/v/20170915212320223?s=eRIGHT_MANY_TOT=R\n",
      "http://v.media.daum.net/v/20170916115841960?s=eRIGHT_MANY_TOT=R\n",
      "http://v.media.daum.net/v/20170916113240722?s=eRIGHT_MANY_TOT=R\n",
      "http://v.media.daum.net/v/20170916110003421?s=eRIGHT_MANY_TOT=R\n",
      "http://v.media.daum.net/v/20170916100339862?s=eRIGHT_MANY_TOT=R\n",
      "http://v.media.daum.net/v/20170916133934680?s=eRIGHT_MANY_TOT=R\n",
      "http://v.media.daum.net/v/20170916105018351?s=eRIGHT_MANY_TOT=R\n",
      "http://v.media.daum.net/v/20170916103736234?s=eRIGHT_MANY_TOT=R\n",
      "http://v.media.daum.net/v/20170916112616673?s=eRIGHT_MANY_TOT=R\n",
      "http://v.media.daum.net/v/20170916091147366?s=eRIGHT_MANY_TOT=R\n",
      "http://v.media.daum.net/v/20170916065026115?s=eRIGHT_MANY_TOT=R\n",
      "http://v.media.daum.net/v/20170916111924612?s=eRIGHT_MANY_TOT=R\n",
      "http://v.media.daum.net/v/20170916144603328?s=eRIGHT_MANY_TOT=R\n",
      "http://v.media.daum.net/v/20170916124604282?s=eRIGHT_MANY_TOT=R\n",
      "http://v.media.daum.net/v/20170916141002925?s=eRIGHT_MANY_TOT=R\n",
      "http://v.media.daum.net/v/20170916081215847?s=eRIGHT_MANY_TOT=R\n",
      "http://v.media.daum.net/v/20170916130016374?s=eRIGHT_MANY_TOT=R\n",
      "http://v.media.daum.net/v/20170916083853023?s=eRIGHT_MANY_TOT=R\n",
      "http://v.media.daum.net/v/20170916140603885?s=eRIGHT_MANY_TOT=R\n",
      "http://v.media.daum.net/v/20170916075210658?s=eRIGHT_MANY_TOT=R\n",
      "http://v.media.daum.net/v/20170916114935865?s=eRIGHT_MANY_TOT=R\n",
      "http://v.media.daum.net/v/20170916125705350\n",
      "http://v.media.daum.net/v/20170916131509483\n",
      "http://v.media.daum.net/v/20170916121503072\n",
      "http://v.media.daum.net/v/20170916070504355\n",
      "http://v.media.daum.net/v/20170916130333408\n",
      "http://v.media.daum.net/v/20170916113217718\n",
      "http://v.media.daum.net/v/20170916111843606\n",
      "http://v.media.daum.net/v/20170916145155400\n",
      "http://v.media.daum.net/v/20170915200317816\n",
      "http://v.media.daum.net/v/20170916141717987\n",
      "http://v.media.daum.net/v/20170916142954100\n",
      "http://v.media.daum.net/v/20170916050217394\n",
      "http://v.media.daum.net/v/20170916090004157\n",
      "http://v.media.daum.net/v/20170916092127455\n",
      "http://v.media.daum.net/v/20170916101436000\n",
      "http://v.media.daum.net/v/20170916094619687\n",
      "http://v.media.daum.net/v/20170916112159635\n",
      "http://v.media.daum.net/v/20170916090543324\n",
      "http://v.media.daum.net/v/20170916102100079\n",
      "http://v.media.daum.net/v/20170916142942099\n",
      "http://v.media.daum.net/v/20170916053014480\n",
      "http://v.media.daum.net/v/20170916111519579\n",
      "http://v.media.daum.net/v/20170916060018623\n",
      "http://v.media.daum.net/v/20170916125246319\n",
      "http://v.media.daum.net/v/20170916085540130\n",
      "http://v.media.daum.net/v/20170916122402117\n",
      "http://v.media.daum.net/v/20170916120329009\n",
      "http://v.media.daum.net/v/20170916080315780\n",
      "http://v.media.daum.net/v/20170916130003367\n",
      "http://v.media.daum.net/v/20170916120259004\n",
      "http://policy.daum.net/info/info\n",
      "http://biz.daum.net/\n",
      "http://cs.daum.net/faq/63.html\n",
      "http://www.kakaocorp.com/\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "res = requests.get('http://media.daum.net/economic/')\n",
    "\n",
    "soup = BeautifulSoup(res.content, 'html.parser')\n",
    "\n",
    "# a태그이면서 href 속성을 갖는 경우 탐색, 리스트 타입으로 links 변수에 저장됨\n",
    "links = soup.select('a[href]')\n",
    "   \n",
    "for link in links:\n",
    "    # print (link) # <a class=\"link_services link_services2\" href=\"http://sports.media.daum.net/sports\">스포츠</a>\n",
    "    # print (link['href']) # http://sports.media.daum.net/sports\n",
    "    if re.search('http://\\w+', link['href']):  # http:// 문자열 이후에 숫자 또는 문자[a-zA-Z0-9_]가 한 개 이상 있는 데이터와 매치됨 \n",
    "        print (link['href'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - [참고: 정규표현식 재확인](http://devanix.tistory.com/296)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "**<font color=\"blue\" size=\"4em\">연습문제3</font>**\n",
    " 1. 다음 뉴스 경제란 뉴스 타이틀 추출하기\n",
    "    - http://media.daum.net/economic/ 로 크롤링된 데이터 중 http:// 로 시작하는 링크를 다시 들어가서, title 태그 정보만 출력해보기\n",
    "    \n",
    "    X 참고코드: git 저장소에서 02_examples/crawling_daum_news_title.py 를 참고 \n",
    "    - 프로그래밍은 스스로 작성을 해야 합니다. 정 이해하기 어려울 때만 참고코드를 보시면 좋을 것 같습니다.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://v.media.daum.net/v/20170916130602430 北 축전에 조롱거리 된 싱가포르 첫 여성대통령 | Daum 뉴스\n",
      "http://v.media.daum.net/v/20170916143016107 교육부 \"집단 휴업 사립유치원, 감사 등 책임 묻겠다\" | Daum 뉴스\n",
      "http://v.media.daum.net/v/20170916011416365 G70 고급 세단 시장 도전장 .. 벤츠·BMW와 럭셔리 대결 | Daum 뉴스\n",
      "http://v.media.daum.net/v/20170916080026736 [WEEKLY BIZ] 파산 직전의 철강회사는 어떻게 1년 만에 2조 흑자를 냈나 | Daum 뉴스\n",
      "http://v.media.daum.net/v/20170916143005105 \"일본 공짜 커피를 보고 발상을 전환하라\" | Daum 뉴스\n",
      "http://v.media.daum.net/v/20170916063044959 [토요정담]6년째 '으르렁' 대는 文·安의 악연..'되게 하는 힘'과 '안 되게 하는 힘' | Daum 뉴스\n",
      "http://v.media.daum.net/v/20170909140103098 [장은석 기자의 호갱 탈출] 물 차고 시간 안 맞는 고급 손목시계, 환불·보상받을 수 있는 방법 있나요 | Daum 뉴스\n",
      "http://v.media.daum.net/v/20170916140103841 [장은석 기자의 호갱 탈출] 게임 아이템 날아갔는데 환불되나요 | Daum 뉴스\n",
      "http://v.media.daum.net/v/20170916134540719 [사진현장] 초조함, 기다림, 부르튼 발. 취업문 앞 청년들 | Daum 뉴스\n",
      "http://v.media.daum.net/v/20170916033622124 사라지는 '뉴스테이'.. 힘 받는 '행복주택' | Daum 뉴스\n",
      "http://v.media.daum.net/v/20170915185902464 연임 앞둔 윤종규 KB금융 회장 \"행장 분리, 이사회와 논의\" | Daum 뉴스\n",
      "http://v.media.daum.net/v/20170825194602752 [장은석 기자의 호갱 탈출] 90% 할인 판매? 쇼핑몰 '실수'면 거래 취소된다 | Daum 뉴스\n",
      "http://v.media.daum.net/v/20170916130113385 \"우리 개는 안 물어요\"..목줄 푸는 주인들의 착각 | Daum 뉴스\n",
      "http://v.media.daum.net/v/20170909090016232 [오은석의부동산재테크]과도한 수요 억제는 집값폭등을 부른다 | Daum 뉴스\n",
      "http://v.media.daum.net/v/20170916060104650 결손 처분한 체납건보료 6년간 4천여억원 | Daum 뉴스\n",
      "http://v.media.daum.net/v/20170915134002434 코스피, 北 미사일 도발에도 보합권..코스닥은 '상승' | Daum 뉴스\n",
      "http://v.media.daum.net/v/20170916090013176 [오은석의부동산재테크]불확실한 시장에서 우량 물건을 잡는 방법 | Daum 뉴스\n",
      "http://v.media.daum.net/v/20170916110251463 [박수찬의 軍] \"한국, 대륙서 돈만 벌고 사드 외면\" 중국의 직격탄 | Daum 뉴스\n",
      "http://v.media.daum.net/v/20170916134517716 토성탐사선 카시니의 '유작'(遺作) | Daum 뉴스\n",
      "http://v.media.daum.net/v/20170916100018804 安 '선명 야당'으로 국민의당, 몸값 높아졌는데..부메랑은 | Daum 뉴스\n",
      "http://v.media.daum.net/v/20170916141922005 김이수 귀국 후 \"표결 수용..맡은 바 소임 최선 다할 것\"(종합) | Daum 뉴스\n",
      "http://v.media.daum.net/v/20170916070107259 러, 파괴력 최대 '모든 폭탄 아버지' 사용 여부 진실공방 | Daum 뉴스\n",
      "http://v.media.daum.net/v/20170916050303400 장제원 의원님! '스펙'이 그렇게 중요합니까? | Daum 뉴스\n",
      "http://v.media.daum.net/v/20170916145844498 \"소비 점진적 회복세..북핵·주택시장 규제는 걸림돌\" | Daum 뉴스\n",
      "http://v.media.daum.net/v/20170916141550973 \"애플, '아이폰X' 한 대 팔 때 83만원 남겨..이익률 64%\" | Daum 뉴스\n",
      "http://v.media.daum.net/v/20170916152253742 [한국사의 안뜰] 양반·평민 함께한 마을계.. '나눔의 정' 300년을 이었다 | Daum 뉴스\n",
      "http://v.media.daum.net/v/20170915105603331 '뉴스테이' 명칭 없애고 공공성 대폭 늘린다 | Daum 뉴스\n",
      "http://v.media.daum.net/v/20170916153904951 대한항공, 美 휴스턴 노선 중단 검토 | Daum 뉴스\n",
      "http://v.media.daum.net/v/20170916090013176 [오은석의부동산재테크]불확실한 시장에서 우량 물건을 잡는 방법 | Daum 뉴스\n",
      "http://v.media.daum.net/v/20170916060308680 문 대통령, 北에 '재기불능'과 '대화복귀' 선택지 던졌다 | Daum 뉴스\n",
      "http://v.media.daum.net/v/20170916044249309 선정적 코피노 캐릭터, 해도 너무한 게임 | Daum 뉴스\n",
      "http://v.media.daum.net/v/20170916092937528 [단독]세월호 위성항법장치 GPS플로터, 사고 40분전 꺼졌다 | Daum 뉴스\n",
      "http://v.media.daum.net/v/20170916050110377 \"김명수까지 퇴짜 놓다간   호남서 민심역풍 불수도.. \" | Daum 뉴스\n",
      "http://v.media.daum.net/v/20170916154442038 [일문일답]교육부 \"휴업 참여 사립유치원 징계 예외는 없다\" | Daum 뉴스\n",
      "http://v.media.daum.net/v/20170916070410344 비트코인 거품 논란 점입가경..튤립 파동과 다른 점은? | Daum 뉴스\n",
      "http://v.media.daum.net/v/20170915185045320 끝내 中롯데마트 철수 결정한 롯데..8조원 투자한 中사업 '흔들'(종합) | Daum 뉴스\n",
      "http://v.media.daum.net/v/20170916130031377 [양낙규의 Defence Club]EMP 서울상공서 터지면 어떻게 되나 | Daum 뉴스\n",
      "http://v.media.daum.net/v/20170916134540719 [사진현장] 초조함, 기다림, 부르튼 발. 취업문 앞 청년들 | Daum 뉴스\n",
      "http://v.media.daum.net/v/20170916143337144 [단독] '무도' 김태호PD \"노조탈퇴 제안 받았지만 거절했다\" | Daum 뉴스\n",
      "http://v.media.daum.net/v/20170915174005771 제네시스 G70 \"BMW 3보다 크고, 벤츠 C보다 세다\" | Daum 뉴스\n",
      "http://v.media.daum.net/v/20170916030222904 '윤종규 2기' KB금융, 신한과 금융 지존 가린다 | Daum 뉴스\n",
      "http://v.media.daum.net/v/20170916070410344 비트코인 거품 논란 점입가경..튤립 파동과 다른 점은? | Daum 뉴스\n",
      "http://v.media.daum.net/v/20170916110101442 \"소비 점진적 회복세..북핵·주택시장 규제로 위축 우려\" | Daum 뉴스\n",
      "http://v.media.daum.net/v/20170916011537371 KB금융 회장 첫 연임 .. 윤종규, 노조와 갈등 풀어낼까 | Daum 뉴스\n",
      "http://v.media.daum.net/v/20170915084258568 [단독]박근혜의 '뉴스테이' 국토부서 '아웃' | Daum 뉴스\n",
      "http://v.media.daum.net/v/20170916150148531 교육부 \"휴업 유치원, 지원금 회수·원비 환불·폐쇄 등 조치\"(종합) | Daum 뉴스\n",
      "http://v.media.daum.net/v/20170916010116289 [현장 속으로] 앞 거의 못 보는 소녀 VR기기 쓰자 \"단발머리 .. 어, 우리 엄마?\" | Daum 뉴스\n",
      "http://v.media.daum.net/v/20170916143610179 [이슈플러스] '주인'은 없고 '깃발'만 나부끼는 보수의 몰락 | Daum 뉴스\n",
      "http://v.media.daum.net/v/20170915161046048 코스피, 北도발에도 '굳건'..한달여만에 2,380선 재탈환(종합) | Daum 뉴스\n",
      "http://v.media.daum.net/v/20170916124836295 \"SK하이닉스, 도시바 의결권 15%..거부권은 없어\" | Daum 뉴스\n",
      "http://v.media.daum.net/v/20170916125043305 고립 속 '나홀로 육아'..비극 빚는 '주부 우울증' | Daum 뉴스\n",
      "http://v.media.daum.net/v/20170915102957366 비트코인 '폭삭'.. 中거래소 중단에 투자자 이탈 | Daum 뉴스\n",
      "http://v.media.daum.net/v/20170915232122548 中 비트코인 거래소 오케이코인·후오비 10월31일 폐쇄 | Daum 뉴스\n",
      "http://v.media.daum.net/v/20170915171609085 [마감시황][종합]코스피, 北 미사일 도발에도 2380선 상승 마감 | Daum 뉴스\n",
      "http://v.media.daum.net/v/20170916124836295 \"SK하이닉스, 도시바 의결권 15%..거부권은 없어\" | Daum 뉴스\n",
      "http://v.media.daum.net/v/20170916050205389 [기획] '맷집' 생긴 증시.. 北 연이은 도발에도 '덤덤' | Daum 뉴스\n",
      "http://v.media.daum.net/v/20170916050303400 장제원 의원님! '스펙'이 그렇게 중요합니까? | Daum 뉴스\n",
      "http://v.media.daum.net/v/20170916044251311 '외풍' 막아낸 KB금융 이사진의 힘 | Daum 뉴스\n",
      "http://v.media.daum.net/v/20170902140104281 [장은석 기자의 호갱 탈출] 숙박 앱 비회원도 예약 7일 이내엔 위약금 안 뗍니다 | Daum 뉴스\n",
      "http://v.media.daum.net/v/20170916124836295 \"SK하이닉스, 도시바 의결권 15%..거부권은 없어\" | Daum 뉴스\n",
      "http://v.media.daum.net/v/20170916044251311 '외풍' 막아낸 KB금융 이사진의 힘 | Daum 뉴스\n",
      "http://v.media.daum.net/v/20170916125613346 사흘 만에 처음 입 연 '240번 버스 기사' | Daum 뉴스\n",
      "http://v.media.daum.net/v/20170916144646338 與 \"김문수, '文대통령은 김정은 기쁨조' 막말 사과해야\" | Daum 뉴스\n",
      "http://v.media.daum.net/v/20170916134540719 [사진현장] 초조함, 기다림, 부르튼 발. 취업문 앞 청년들 | Daum 뉴스\n",
      "http://v.media.daum.net/v/20170826090025529 [오은석의 부동산 재테크]8.2 대책, 3~4년 뒤 집값은 폭등한다. | Daum 뉴스\n",
      "http://v.media.daum.net/v/20170915174005771 제네시스 G70 \"BMW 3보다 크고, 벤츠 C보다 세다\" | Daum 뉴스\n",
      "http://v.media.daum.net/v/20170916153558897 코스닥, 외국인 2116억원 순매수..671.30 마감 | Daum 뉴스\n",
      "http://v.media.daum.net/v/20170916140103841 [장은석 기자의 호갱 탈출] 게임 아이템 날아갔는데 환불되나요 | Daum 뉴스\n",
      "http://v.media.daum.net/v/20170916140103841 [장은석 기자의 호갱 탈출] 게임 아이템 날아갔는데 환불되나요 | Daum 뉴스\n",
      "http://v.media.daum.net/v/20170916130508423 \"늦은 추석 과일 맛도 최고\"..기상여건 양호 덕분 | Daum 뉴스\n",
      "http://v.media.daum.net/v/20170916125436333 갤노트8 첫날 20만대 개통..'떴다방식' 불법 보조금 등장 | Daum 뉴스\n",
      "http://v.media.daum.net/v/20170916080104746 홧김에 창문 밖으로 후배 밀친 20대, 유족 합의 후 선처 | Daum 뉴스\n",
      "http://v.media.daum.net/v/20170916110125448 [뉴스탐색] '240번 버스기사' 사건 최초유포자 사과 진정성 있나? | Daum 뉴스\n",
      "http://v.media.daum.net/v/20170916140103841 [장은석 기자의 호갱 탈출] 게임 아이템 날아갔는데 환불되나요 | Daum 뉴스\n",
      "http://v.media.daum.net/v/20170916141742991 박근혜 전 대통령 무죄 석방 서명운동 | Daum 뉴스\n",
      "http://v.media.daum.net/v/20170916080014728 \"같은 역에서 내리자\" 지하철서 여고생 추행 60대 징역형 | Daum 뉴스\n",
      "http://v.media.daum.net/v/20170916125401328 공무원 정년 연장하는 일본, 다른 나라들은 어떨까 | Daum 뉴스\n",
      "http://v.media.daum.net/v/20170902090018632 [오은석의 부동산 재테크]전세 대란의 징조 | Daum 뉴스\n",
      "http://v.media.daum.net/v/20170916124836295 \"SK하이닉스, 도시바 의결권 15%..거부권은 없어\" | Daum 뉴스\n",
      "http://v.media.daum.net/v/20170916152253742 [한국사의 안뜰] 양반·평민 함께한 마을계.. '나눔의 정' 300년을 이었다 | Daum 뉴스\n",
      "http://v.media.daum.net/v/20170916111912610 세월호 내부 영상 공개.. 침몰원인 밝혀질까 | Daum 뉴스\n",
      "http://v.media.daum.net/v/20170915103230504 중국 최대 가상화폐거래소 업무 중단..비트코인 28% 급락 | Daum 뉴스\n",
      "http://v.media.daum.net/v/20170915181329653 [현장+]제네시스 G70 출시 이례적 '금요일' 택한 속내 | Daum 뉴스\n",
      "http://v.media.daum.net/v/20170915150747489 박근혜표 임대주택 '뉴스테이' 명칭 사라진다 | Daum 뉴스\n",
      "http://v.media.daum.net/v/20170916152752789 신고리5·6호기 시민참여단 478명, 첫 오리엔테이션 참석(종합) | Daum 뉴스\n",
      "http://v.media.daum.net/v/20170916135601809 \"무책임한 잠적 황당\"..'알바추노'에 속끓는 자영업자들 | Daum 뉴스\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "res = requests.get('http://media.daum.net/economic/')\n",
    "[-------------------------------------------------]\n",
    "\n",
    "# a태그이면서 href 속성을 갖는 경우 탐색, 리스트 타입으로 links 변수에 저장됨\n",
    "links = soup.select('a[href]')\n",
    "for link in links:\n",
    "    if re.search('http://\\w+', link['href']):  # 이 부분도 개선의 여지가 있어보입니다만...(고급)\n",
    "    [-------------------------------------------------]\n",
    "    [-------------------------------------------------]\n",
    "    [-------------------------------------------------]    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **CSS Selector 를 활용하는 팁**\n",
    " 2. 네이버 부동산 매매 아파트 이름과 가격만 찾아보기\n",
    "    - CSS Selector 를 활용하는 팁: Chrome F12(WINDOW) or Alt + Command + i(MAC) --> Copy Selector 참고\n",
    "    - Copy Selector 시 일부 태그에 붙는 :nth-child(#) 은 동일한 태그로 리스트가 있을 경우, 리스트 중 특정한 값만 가리킴\n",
    "      . 전체 리스트를 가져오는 경우에는 :nth-child(#) 은 삭제할 필요가 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "청담자이 190,000\n",
      "청담린든그로브 176,000\n",
      "청담자이 190,000\n",
      "청담자이 190,000\n",
      "개포우성2차 180,000\n",
      "청담자이 240,000\n",
      "청담자이 188,000\n",
      "청담자이 190,000\n",
      "선경1,2차 225,000\n",
      "삼성힐스테이트1단지 80,000\n",
      "청담자이 170,000\n",
      "대치SK뷰 183,000\n",
      "아이파크삼성 340,000\n",
      "대치SK뷰 183,000\n",
      "논현동양파라곤 250,000\n",
      "청담자이 121,000\n",
      "대치SK뷰 165,000\n",
      "청담자이 120,000\n",
      "역삼자이(개나리6차재건축) 170,000\n",
      "개포주공7단지 130,000\n",
      "역삼래미안 130,000\n",
      "청담래미안로이뷰 175,000\n",
      "래미안대치팰리스1단지 180,000\n",
      "청담자이 170,000\n",
      "논현동양파라곤 250,000\n",
      "은마 120,000\n",
      "청담자이 239,000\n",
      "청담자이 190,000\n",
      "청담자이 163,000\n",
      "삼성힐스테이트2단지 128,000\n",
      "은마 125,000\n",
      "래미안강남힐즈 115,000\n",
      "래미안그레이튼(진달래3차) 175,000\n",
      "도곡렉슬 190,000\n",
      "청담자이 125,000\n",
      "은마 190,000\n",
      "청담자이 127,000\n",
      "청담자이 120,000\n",
      "청담자이 120,000\n",
      "청담자이 125,000\n",
      "아카데미스위트 195,000\n",
      "신현대(현대9,11,12차) 127,000\n",
      "청담자이 127,000\n",
      "청담자이 190,000\n",
      "청담자이 51,000\n",
      "청담휴먼스타빌 110,000\n",
      "역삼래미안 108,000\n",
      "래미안강남힐즈 128,000\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "res = requests.get('http://land.naver.com/article/divisionInfo.nhn?rletTypeCd=A01&tradeTypeCd=A1&hscpTypeCd=A01%3AA03%3AA04&cortarNo=1168000000&articleOrderCode=&cpId=&minPrc=&maxPrc=&minWrrnt=&maxWrrnt=&minLease=&maxLease=&minSpc=&maxSpc=&subDist=&mviDate=&hsehCnt=&rltrId=&mnex=&siteOrderCode=&cmplYn=')\n",
    "\n",
    "soup = BeautifulSoup(res.content, 'html.parser')\n",
    "\n",
    "# a 태그이면서 href 속성 값이 특정한 값을 갖는 경우 탐색\n",
    "link_title = soup.select(\"#depth4Tab0Content > div > table > tbody > tr > td.align_l.name > div > a.sale_title\")\n",
    "link_price = soup.select(\"#depth4Tab0Content > div > table > tbody > tr > td.num.align_r > div > strong\")\n",
    "\n",
    "for num in range(len(link_price)):\n",
    "    print(link_title[num].get_text(), link_price[num].get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "**<font color=\"blue\" size=\"4em\">연습문제4</font>**\n",
    " 1. 네이버 실시간검색어 20개 추출하기\n",
    "    - Chrome 의 Copy Selector를 활용\n",
    "    \n",
    "    X 참고코드: git 저장소에서 02_examples/crawling_naver_realtime_keyword.py 를 참고 \n",
    "    - 프로그래밍은 스스로 작성을 해야 합니다. 정 이해하기 어려울 때만 참고코드를 보시면 좋을 것 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 서현진\n",
      "2 이건희\n",
      "3 무한도전\n",
      "4 태풍 독수리\n",
      "5 황금빛내인생\n",
      "6 청년경찰\n",
      "7 보그맘\n",
      "8 그것이 알고싶다\n",
      "9 아는형님\n",
      "10 소사이어티 게임 2\n",
      "11 롤챔스 승강전\n",
      "12 롯데시네마\n",
      "13 메가박스\n",
      "14 편성표\n",
      "15 프로야구중계\n",
      "16 태풍경로\n",
      "17 스팀\n",
      "18 테일즈런너\n",
      "19 cj채용\n",
      "20 아프리카티비\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "res = requests.get('https://www.naver.com/')\n",
    "soup = BeautifulSoup(res.content, 'html.parser')\n",
    "\n",
    "# a 태그이면서 href 속성 값이 특정한 값을 갖는 경우 탐색\n",
    "link_title = soup.select([------------------------------------------])\n",
    "for num in range(len(link_title)):\n",
    "    [------------------------------------------]\n",
    "    [------------------------------------------]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "**<font color=\"blue\" size=\"4em\">흥미로운 예제</font>**\n",
    " 1. slack 메세지로 만들어보는 부동산 뉴스 (과제로 해당 코드를 설명해서 공유드리겠습니다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import datetime\n",
    "import json\n",
    "\n",
    "random_url = 'https://hooks.slack.com/services/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'\n",
    "res = requests.get('http://www.drapt.com/e_sale/index.htm?page_name=esale_news&menu_key=34')\n",
    "soup = BeautifulSoup(res.content, 'html.parser')\n",
    "\n",
    "link_titles = soup.find_all('a', class_='c0000000')\n",
    "link_dates = soup.find_all('span', class_='ffth fs11 c807f7f')\n",
    "today_date = datetime.date.today()\n",
    "today_message = '오늘의 부동산 뉴스 [%s]' % str(today_date)\n",
    "payload = {'text': today_message}\n",
    "estate_info_message = json.dumps(payload)\n",
    "requests.post(random_url, data=estate_info_message)\n",
    "\n",
    "for num, link_title in enumerate(link_titles):\n",
    "    if str(today_date) == link_dates[num].get_text():\n",
    "        # estate_info = '<a herf=\\\"http://www.drapt.com/e_sale/%s\\\">%s</a>' % (link_title['href'], link_title.get_text())\n",
    "        # Reference for creating a link: https://api.slack.com/incoming-webhooks\n",
    "        estate_info = '%d] <http://www.drapt.com/e_sale/%s|%s>' % (num + 1, link_title['href'], link_title.get_text())\n",
    "        payload = {'text': estate_info}\n",
    "        estate_info_message = json.dumps(payload)\n",
    "        requests.post(random_url, data=estate_info_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crawling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습목표\n",
    " 1. 쿠키(Cookie)와 세션(Session) 이해\n",
    " 2. 로그인이 필요한 웹페이지 크롤링 이해 및 실습\n",
    " 3. Selenium 과 PhantomJS를 활용한 크롤링 이해 및 실습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 쿠키(Cookie)와 세션(Session)\n",
    " - HTTP Request 를 전송하면, 서버는 HTML 파일을 전달하고, 해당 요청은 완료된다.\n",
    " - HTTP 프로토콜은 연결을 유지하기 어려운 구조로 되어 있음<br>\n",
    "   . 요청-응답 후 연결이 끊기는 구조(사용자 입력 정보등 상태 정보 활용이 어려운 구조임)\n",
    " - 상태 관리 정보를 저장하는 방식으로 쿠키(cookie)와 세션(session) 기법이 나옴\n",
    " \n",
    "#### 1.1 쿠키(cookie): 상태 정보를 클라이언트에 저장하는 방식\n",
    " 1. HTML 페이지를 웹 서버에 요청\n",
    " 2. 웹 서버에서 쿠키(cookie) 생성\n",
    " 3. 웹 서버 응답(HTML 페이지를 돌려줄 때) HTTP 헤더에 쿠키를 포함해서 전송 \n",
    "``` \n",
    "Set−Cookie: id=korea123\n",
    "``` \n",
    " 4. 전달받은 쿠키는 웹브라우저에서 관리하고 있다가, 다음 요청 때 쿠키를 함께 전송\n",
    "```\n",
    "Cookie: id=korea123\n",
    "```\n",
    " 5. 서버에서는 쿠키 정보를 읽어 이전 상태 정보를 확인\n",
    " 6. 필요시 서버가 쿠키 정보를 변경해서 응답시 변경된 쿠키와 함께 응답\n",
    "\n",
    " <img src=\"00_Images/cookie.png\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 세션(session): 상태 정보를 웹 서버에 저장하는 방식\n",
    "1. 웹브라우저가 웹 서버에 요청하게 되면, 웹 서버가 해당 웹브라우저(클라이언트)에 유일한 ID(세션 ID)를 부여함\n",
    "2. 해당 세션 ID는 응답(HTML 페이지를 돌려줄 때) HTTP 헤더에 넣어져 전달된다.\n",
    "``` \n",
    "Set−Cookie: PHPSESSID=pi0fo9v2kdi5nuha3bcgiu8fq2\n",
    "``` \n",
    "3. 웹브라우저는 이후 웹브라우저를 닫기 까지 해당 웹 서버 요청할 때 부여된 세션 ID를 HTTP 헤더에 넣어서 전달한다.\n",
    "``` \n",
    "Cookie: PHPSESSID=pi0fo9v2kdi5nuha3bcgiu8fq2\n",
    "``` \n",
    "4. 웹 서버는 세션 ID를 확인하고, 해당 세션에 관련된 정보를 확인한 후, HTML 페이지를 돌려준다.\n",
    "\n",
    " <img src=\"00_Images/session.png\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "**<font color=\"blue\" size=\"4em\">실습 (세션에 대한 기본 이해)</font>**\n",
    " 1. [한빛미디어 회원가입](http://www.hanbit.co.kr/member/member_agree.html)\n",
    " 2. 크롬(Chrome) 브라우저로 www.hanbit.co.kr 페이지 오픈 후\n",
    "    - alt + command + i (맥북), F12 (윈도우) 누르고 Application -> Cookies -> http://www.hanbit.co.kr 이동\n",
    "    - PHPSESSID 확인\n",
    " 3. 한빛미디어 로그인 후\n",
    "    - PHPSESSID 값을 임의 값으로 수정\n",
    " 4. 마이한빛 메뉴 클릭 \n",
    " \n",
    " X PHPSESSID 값을 임의 값으로 수정했기 때문에, 로그인 정보가 필요한 마이한빛 페이지 오픈시, 서버측에서 해당 로그인 정보가 없으므로\n",
    " 로그인을 하라는 페이지로 이동함\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 로그인이 필요한 웹페이지 크롤링 이해 및 실습\n",
    " - 로그인이 필요한 웹페이지는 쿠키 또는 세션을 사용하는 경우가 일반적입니다.\n",
    "\n",
    "#### 2.1 한빛미디어 홈페이지(http://www.hanbit.co.kr) 마일리지 크롤링 \n",
    "   - 마일리지를 확인하기 위해 로그인 정보가 필요함\n",
    "   - 세션으로 관리되고 있음을 코드를 통해 확인\n",
    "   - 세션 정보를 획득하고, 이를 사용해서 마일리지 페이지에 접근하여 마일리지 점수 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 2.1.1 로그인 페이지 분석\n",
    " - http://www.hanbit.co.kr/member/login.html\n",
    " - form 태그를 이해할 필요가 있음 (http://pythonscraping.com/pages/files/form.html)\n",
    " - form 태그를 통해 ID/PW가 전달되는 것이 일반적이므로 해당 코드 확인 (웹브라우저에서 해당 웹페이지 소스보기로 확인)\n",
    " - 다음 두 태그가 코드를 이해하는데 핵심\n",
    "``` \n",
    "<form name=\"frm\"  id=\"frm\"  action=\"#\" method=\"post\">\n",
    "<input  type=\"button\" name=\"login_btn\"  id=\"login_btn\" value=\"로그인\" class=\"btn_login\" >\t\t\t\t\t\n",
    "``` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - javascript를 간결하게 만들기 위한 라이브러리인 jQuery 코드를 확인할 필요가 있음"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<SCRIPT language=\"javascript\">\n",
    "\t$(document).ready(function() { \n",
    "\t\t$('#login_btn').click(function(){ login_proc(); });\t\t\t\t\t\t\t\t\t\t\n",
    "\t});\n",
    "\t\n",
    "\n",
    "\tfunction login_proc(){\t\t\t\t\t\n",
    "\t\tvar chk_rule =  \"m_id:isEmpty:아이디를 입력\"\t\t\t\t\n",
    "\t\t\t\t\t\t\t+\"@m_passwd:isEmpty:비밀번호를 입력\"\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "\t\t\t\t\t\t\t;\t\t\t\t\t\t\t\t\t\t\t \n",
    "\t\tif(validateForm(chk_rule)){\t\n",
    "\t\t\t$(\"#frm\").attr(\"action\",\"login_proc.php\");\n",
    "\t\t\t$(\"#frm\").submit();\t\t\n",
    "\t\t\t//console.log(\"validate success!!\");\n",
    "\t\t}\n",
    "\t}\t\n",
    "</SCRIPT>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - id가 login_btn 인 태그(input type=\"button\")가 click 되었을 때 login_proc() 함수를 호출하게 되어 있음"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "    $('#login_btn').click(function(){ login_proc(); });\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - id가 frm 인 태그(form 태그)에 action 속성을 login_proc.php 로 바꿔주고, 전송하게 되어 있음"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\t\t\t$(\"#frm\").attr(\"action\",\"login_proc.php\");\n",
    "\t\t\t$(\"#frm\").submit();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - 즉, 버튼을 누르면 login_proc.php 웹페이지에 m_id 값과 m_passwd 값을 넣어 전송해줌\n",
    " - 마일리지는 http://www.hanbit.co.kr/myhanbit/myhanbit.html 페이지에서 CSS Selector로 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 유추하는데 도움이 되는 툴 \n",
    "  - Chrome 개발자 도구 -> Network -> Check 'Preserver log' and Select 'Doc'\n",
    "    1. Go www.hanbit.co.kr/index.html\n",
    "    2. Add ID/PW and click 로그인\n",
    "  - login.html -> login_proc.php -> index.html 로 호출됨을 확인할 수 있음\n",
    "  - login_proc.php Request Method가 POST 이고, FORM 데이터에서 m_id, m_passwd 를 확인할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mileage is 5,650\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "login_url = 'http://www.hanbit.co.kr/member/login_proc.php'\n",
    "\n",
    "user = 'tenial'\n",
    "password = ''\n",
    "\n",
    "# requests.session 메서드는 해당 reqeusts를 사용하는 동안 cookie를 header에 유지하도록 하여\n",
    "# 세션이 필요한 HTTP 요청에 사용됩니다.\n",
    "session = requests.session()\n",
    "\n",
    "params = dict()\n",
    "params['m_id'] = user\n",
    "params['m_passwd'] = password\n",
    "\n",
    "# javascrit(jQuery) 코드를 분석해보니, 결국 login_proc.php 를 m_id 와 m_passwd 값과 함께\n",
    "# POST로 호출하기 때문에 다음과 같이 requests.session.post() 메서드를 활용하였습니다.\n",
    "# 실제코드: <form name=\"frm\"  id=\"frm\"  action=\"#\" method=\"post\">\n",
    "res = session.post(login_url, data = params) \n",
    "\n",
    "# 응답코드가 200 즉, OK가 아닌 경우 에러를 발생시키는 메서드입니다.\n",
    "res.raise_for_status() \n",
    "\n",
    "# 'Set-Cookie'로 PHPSESSID 라는 세션 ID 값이 넘어옴을 알 수 있다.\n",
    "# print(res.headers)\n",
    "\n",
    "# cookie로 세션을 로그인 상태를 관리하는 상태를 확인해보기 위한 코드입니다.\n",
    "# print(session.cookies.get_dict()) \n",
    "\n",
    "# 여기서부터는 로그인이 된 세션이 유지됩니다. session 에 header에는 Cookie에 PHPSESSID가 들어갑니다.\n",
    "mypage_url = 'http://www.hanbit.co.kr/myhanbit/myhanbit.html'\n",
    "res = session.get(mypage_url)\n",
    "\n",
    "# 응답코드가 200 즉, OK가 아닌 경우 에러를 발생시키는 메서드입니다.\n",
    "res.raise_for_status() \n",
    "\n",
    "soup = BeautifulSoup(res.text, 'html.parser')\n",
    "\n",
    "# Chrome 개발자 도구에서 CSS SELECTOR를 통해 간단히 가져온 CSS SELECTOR 표현식을 사용\n",
    "he_coin = soup.select_one('#container > div > div.sm_mymileage > dl.mileage_section2 > dd > span')\n",
    "\n",
    "# 다음과 같이 class를 .mileage_section2 로 그리고 그 하부 태그중에 span이 있다는 식으로 표현도 가능함\n",
    "# he_coin = soup.select_one('.mileage_section2 span')\n",
    "\n",
    "print ('mileage is', he_coin.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "**<font color=\"blue\" size=\"4em\">연습문제1</font>**\n",
    " 1. 한빛미디어 마이한빛에서 회원등급 가져와서 출력하기 (기본)\n",
    " 2. 한빛미디어 이름, 회원등급, 마일리지 가져와서 출력하기 (중급)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 3. Selenium 과 PhantomJS를 활용한 크롤링 이해 및 실습\n",
    " - 브라우저를 제어해서 크롤링을 하는 방법\n",
    "\n",
    "#### 2.1 Selenium & PhantomJS\n",
    "\n",
    "##### 2.1.1 Selenium \n",
    "   - Selenium: 웹을 테스트하기 위한 프레임워크\n",
    "   - 공식 홈페이지(http://www.seleniumhq.org/)\n",
    "   - Selenium with Python : http://selenium-python.readthedocs.io/index.html\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "**<font color=\"blue\" size=\"4em\">사전준비 (Selenium 설치)</font>**\n",
    " 1. Selenium 인스톨: pip install selenium\n",
    " 2. 웹드라이버 인스톨: 웹 테스트 자동화를 위해 제공되는 툴(각 browser및 os 별로 존재)\n",
    " - selenium - 테스트 코드를 사용하여 브라우져에서의 액션을 테스트할 수 있게 해주는 툴\n",
    " - Firefox, chromedriver 등 각 브라우져마다 웹드라이버 다운로드 가능\n",
    "     + https://sites.google.com/a/chromium.org/chromedriver/  (Chrome 브라우저용)\n",
    "     + https://github.com/mozilla/geckodriver/releases  (Firefox 브라우저용)\n",
    "     \n",
    " X 설치 디렉토리를 알아두어야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "\n",
    "# 드라이버 생성\n",
    "# chromedriver 설치된 경로를 정확히 기재해야 함\n",
    "# chromedriver = 'C:/dev_python/Webdriver/chromedriver.exe' # 윈도우 \n",
    "chromedriver = '/usr/local/Cellar/chromedriver/chromedriver' # 맥\n",
    "driver = webdriver.Chrome(chromedriver)\n",
    "\n",
    "# 크롤링할 사이트 호출\n",
    "driver.get(\"http://www.python.org\")\n",
    "\n",
    "# Selenium은 웹테스트를 위한 프레임워크로 다음과 같은 방식으로 웹테스트를 자동으로 진행함 (참고)\n",
    "assert \"Python\" in driver.title\n",
    "\n",
    "# <input id=\"id-search-field\" name=\"q\" 검색창 name으로 검색하기\n",
    "# 태그 name으로 특정한 태그를 찾을 수 있음\n",
    "elem = driver.find_element_by_name(\"q\")\n",
    "\n",
    "# input 텍스트 초기화 \n",
    "# elem.clear()\n",
    "\n",
    "# 키 이벤트 전송가능함\n",
    "# 태그가 input 태그이므로 입력창에 키이벤트가 전달되면, 입력값이 자동으로 작성됨\n",
    "elem.send_keys(\"pycon\")\n",
    "\n",
    "# 태그가 input 태그이므로 엔터 입력시 form action이 진행됨\n",
    "elem.send_keys(Keys.RETURN)\n",
    "\n",
    "# Selenium은 웹테스트를 위한 프레임워크로 다음과 같은 방식으로 웹테스트를 자동으로 진행함 (참고)\n",
    "assert \"No results found.\" not in driver.page_source\n",
    "\n",
    "# 명시적으로 일정시간을 기다릴 수 있음 (10초 기다림)\n",
    "time.sleep(10)\n",
    "\n",
    "# 크롬 브라우저 닫기 가능함\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.1.2 PhantomJS\n",
    " - WebTesting을 위해 나온 화면이 존재하지 않는 브라우저\n",
    " - 터미널환경에서 동작하는 크롤러의 경우 PhantomJS 브라우저 사용 권장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "**<font color=\"blue\" size=\"4em\">사전준비 (PhantomJS 설치)</font>**\n",
    " 1. 윈도우: PhantomJS 다운로드 후 절적한 디렉토리에 압축을 품 (http://phantomjs.org/download.html)\n",
    " 2. 맥: brew install phantomjs 또는 윈도우에서 사용한 웹사이트를 활용\n",
    " 3. 리눅스: suto apt-get install phantomjs (한글폰트가 없다면, 추가로 sudo apt-get install -y fonts-nanum* )\n",
    " \n",
    " X 설치 디렉토리를 알아둬야 함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **<font color=\"blue\" size=\"4em\">확인 사항</font>**\n",
    " <br><br>\n",
    " \n",
    " <font color=\"red\">\n",
    " 다음 코드부터는 Selenium을 사용할지, PhantomJS를 사용할지를 정해서<br>\n",
    " 드라이버를 생성하는 코드를 자신의 로컬 환경에 맞게 넣어주신 후에<br>\n",
    " 실행을 하셔야 합니다.\n",
    " </font>\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.python.org/\n",
      "Welcome to Python.org\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "# 드라이버 생성 방법1 (selenium)\n",
    "# chromedriver = 'C:/dev_python/Webdriver/chromedriver.exe' # 윈도우 \n",
    "# chromedriver = '/usr/local/Cellar/chromedriver/chromedriver' # 맥\n",
    "# driver = webdriver.Chrome(chromedriver)\n",
    "\n",
    "# 드라이버 생성 방법2 (phantomJS)\n",
    "# driver = webdriver.PhantomJS('C:/dev_python/phantomjs-2.1.1-windows/bin/phantomjs.exe') # 윈도우\n",
    "driver = webdriver.PhantomJS('/usr/local/Cellar/phantomjs/2.1.1/bin/phantomjs') # 맥\n",
    "\n",
    "driver.get(\"http://www.python.org\")\n",
    "\n",
    "print (driver.current_url)\n",
    "print (driver.title)\n",
    "\n",
    "elem = driver.find_element_by_name(\"q\")\n",
    "\n",
    "# input 텍스트 초기화 \n",
    "elem.clear()\n",
    "\n",
    "# 키 이벤트 전송\n",
    "elem.send_keys(\"python\")\n",
    "\n",
    "# 엔터 입력\n",
    "elem.send_keys(Keys.RETURN)\n",
    "\n",
    "# 스크린샷도 찍을 수 있습니다.\n",
    "driver.set_window_size(1400, 1000)\n",
    "elem.screenshot(\"pycon_event.png\")\n",
    "assert \"No results found.\" not in driver.page_source\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Selenium & PhantomJS 태그 검색 주요 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 주요 함수 - find_element_by_tag_name(), find_elements_by_tag_name()\n",
    "  - find_element_by_tag_name(): 최초 발견한 태그만 가져오기\n",
    "  - find_elements_by_tag_name(): 모든 태그 리스트로 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'포켓몬고' 상륙 1주일.. 대한민국 곳곳이 들썩\n",
      "'포켓몬고' 상륙 1주일.. 대한민국 곳곳이 들썩\n",
      "많이본 뉴스\n",
      "포토&TV\n",
      "실시간 이슈\n",
      "이 시각 추천뉴스\n",
      "실시간 주요이슈\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "\n",
    "# driver = webdriver.PhantomJS('C:/dev_python/phantomjs-2.1.1-windows/bin/phantomjs.exe') # 윈도우\n",
    "driver = webdriver.PhantomJS('/usr/local/Cellar/phantomjs/2.1.1/bin/phantomjs') # 맥\n",
    "driver.get('http://v.media.daum.net/v/20170202185812986')\n",
    "\n",
    "# 최초 발견한 태그만 검색\n",
    "title = driver.find_element_by_tag_name('h3')\n",
    "print (title.text)\n",
    "\n",
    "# 모든 태그 검색\n",
    "h3s = driver.find_elements_by_tag_name('h3')\n",
    "\n",
    "for h3 in h3s:\n",
    "    print (h3.text)\n",
    "    \n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **<font color=\"blue\" size=\"4em\">실습 (함께 작성해보는 코드)</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 주요 함수 - find_element_by_id(), find_elements_by_id()\n",
    "  - find_element_by_id(): 최초 발견한 아이디를 가진 태그만 가져오기\n",
    "  - find_elements_by_id(): 아이디를 가진 모든 태그 리스트로 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "지난달 24일 출시된 모바일게임 '포켓몬고'가 출시 1주일여만에 우리나라 거리 풍경을 크게 바꿔놨다. 번화가나 공원 등 거리 곳곳에서 손에 스마트폰을 들고 '포켓몬'을 사냥하는 모습을 손쉽게 찾아볼 수 있게 된 것이다.다른 국가에 비해 반년 가량 늦게 출시됐음에도 불구, 이용자 수가 700만명에 육박한 것으로 알려졌다. 우리나라 국민 10명 중 1명은 지난 1주일 사이에 한번은 포켓몬고 게임을 해봤다는 얘기다.\n",
      "\n",
      "지역경제 활성화에도 도움이 되고 있다. 포켓몬이 자주 출몰하는 지역으로 입소문을 탄 지역 편의점 매출이 급증하는 현상도 나타났다. 지난해 여름, 강원도 속초가 '포켓몬고' 특수를 톡톡히 누린 것과 비슷한 현상이 전국 곳곳에서 나타나고 있는 것이다.\n",
      "\n",
      "■우리 국민 10명 중 1명은 '포켓몬고' 게이머\n",
      "\n",
      "애플리케이션(앱) 분석업체 와이즈앱은 2일 전국 2만3000명의 안드로이드 스마트폰 사용자 표본조사를 바탕으로 추정한 지난 1주일간 '포켓몬고' 이용자는 698만명이라고 발표했다. 특히 10대와 20대 이용자들이 '포켓몬고'에 열광하고 있는 것으로 나타났다. 전체 이용자의 65% 이상이 10대와 20대다.\n",
      "\n",
      "이 게임 개발사인 나이언틱랩스가 설 연휴 직전에 출시한 전략도 제대로 맞아 떨어졌다. 지난 설 연휴, 고향에서 가족과 친지들이 모여 '포켓몬고'를 즐기는 모습이 곳곳에서 눈에 띄였다. 고속도로 휴게소 등에서도 포켓몬고 이용자들도 많았다.\n",
      "\n",
      "전국 번화가와 공원 등 게임 내 주요 장소인 '포켓스톱'으로 지정된 곳이 많은 지역은 '포켓몬고' 게이머들로 붐볐다. 서울 노원역, 이수역, 강남역, 잠실역 등 번화가와 부산 시민공원, 대전 오월드, 제천 의림지 등 전국 주요 장소로 '포켓몬'을 찾는 이들이 몰려들었다.\n",
      "\n",
      "지역 명소를 찾는 이들도 부쩍 늘었다. 주로 교회나 절, 조형물 등이 '포켓스톱'으로 지정돼 있기 때문에 평소에는 그냥 지나쳤던 명소를 다시 한번 돌아보게 되는 계기가 됐다는 게이머들도 많다.\n",
      "\n",
      "업계 관계자는 \"포켓스톱은 포켓몬고를 즐기기 위해 반드시 지나쳐야 하는 곳이기 때문에 평소엔 그냥 지나쳤더라도 요즘엔 멈춰서서 다시 한번 보는 경우가 많다\"며 \"겨울철이라 집안에만 있기 쉽지만 포켓몬고를 하기 위해 밖으로 걸어다니기 때문에 건강에도 긍정적\"이라고 언급했다.\n",
      "\n",
      "■'포켓몬고' 인기에 지역 상권도 '후광효과'\n",
      "\n",
      "포켓몬고는 지역 상권에도 영향을 주고 있다. '포켓몬'이 자주 출몰하는 이른바 '포세권'의 편의점은 후광효과를 톡톡히 보고 있다. 포켓몬을 쫓아온 게이머들이 대거 몰리면서 휴대폰 충전기와 핫팩은 물론 음료,간식 등의 매출이 쑥쑥 오르는 상황이다.\n",
      "\n",
      "세븐일레븐의 경우 포켓몬고 게임이 출시된 지난달 24일 이후 지난 1일까지 9일간 매출이 게임 출시 직전 9일에 비해 휴대폰 관련 용품 매출이 61.3%, 핫팩은 66.2%증가했다. 탄산음료와 컵라면,스낵과자도 같은 기간 매출이 33.5%,22%,16.3% 올랐다.\n",
      "\n",
      "'포세권'으로 입소문을 탄 부산시민공원점도 휴대용용품과 핫팩 매출이 각각 54%, 60.5% 늘었고 간식류 매출도 10~20% 증가했다. GS25의 대전오월드점은 같은 기간 커피와 차는 매출이 420%, 휴대폰 용품과 핫팩은 각각 271%, 268% 급증했다. 라면(46%)을 비롯한 간식류 매출도 크게 늘었다.\n",
      "\n",
      "세븐일레븐 관계자는 \"포켓몬고 이용자들이 많이 몰리는 지역 점포들의 관련 상품 매출이 크게 오르고 있다\"면서 \"수요가 높은 상품군 위주로 재고를 늘리고 진열도 확대하는 등 포켓몬고 특수에 대응하고 있다\"고 말했다.\n",
      "\n",
      "■일부 부작용도 있어 '주의'\n",
      "\n",
      "게임이 인기를 끌면서 일부 부작용도 나타나고 있어 이용자들의 주의가 요구된다. 출입이 금지된 구역에 등장하는 '포켓몬'을 획득하기 위해 금지구역을 넘어서거나 운전하면서 포켓몬고를 즐기는 사례가 잇따라 보고되고 있다. 해외에서도 '포켓몬고' 출시 당시 이런 부작용이 속출했는데 우리나라도 비슷한 현상을 겪고 있는 것이다.\n",
      "\n",
      "나이언틱랩스는 특정 속도 이상 빠르게 움직이면 '포켓몬'을 사냥할 수 없도록 하고 게임 도중 출입금지 구역에 가지 말라고 여러차례 공지하고 있다.\n",
      "\n",
      "jjoony@fnnews.com 허준 이환주 기자\n",
      "※ 저작권자 ⓒ . 무단 전재-재배포 금지\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "\n",
    "# driver = webdriver.PhantomJS('C:/dev_python/phantomjs-2.1.1-windows/bin/phantomjs.exe') # 윈도우\n",
    "driver = webdriver.PhantomJS('/usr/local/Cellar/phantomjs/2.1.1/bin/phantomjs') # 맥\n",
    "driver.get('http://v.media.daum.net/v/20170202185812986')\n",
    "\n",
    "body = driver.find_element_by_id('harmonyContainer')\n",
    "print (body.text)\n",
    "    \n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 주요 함수 - find_element_by_name(), find_elements_by_name()\n",
    "  - find_element_by_name(): 최초 발견한 태그 안에 name 값이 같은 태그 가져오기\n",
    "  - find_elements_by_name(): 태그 안에 name 값이 같은 태그 모두 리스트로 가져오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 CSS selector 이용하기 (BeautifulSoup 과 동일)\n",
    "\n",
    " - docs : http://saucelabs.com/resources/articles/selenium-tips-css-selectors\n",
    " - 아이디의 경우 앞에 #\n",
    " - 클래스의 경우 앞에 .\n",
    " - 하위 태그는 >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 클래스로 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "포커 정복한 AI, 어디까지 진화할까\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "\n",
    "# driver = webdriver.PhantomJS('C:/dev_python/phantomjs-2.1.1-windows/bin/phantomjs.exe') # 윈도우\n",
    "driver = webdriver.PhantomJS('/usr/local/Cellar/phantomjs/2.1.1/bin/phantomjs') # 맥\n",
    "driver.get('http://v.media.daum.net/v/20170202180355822')\n",
    "\n",
    "# 클래스가 tit_view인 h3태그\n",
    "title = driver.find_element_by_css_selector(\"h3.tit_view\")\n",
    "print (title.text)\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "* 아이디로 찾기\n",
    "  **<font color=\"blue\" size=\"4em\">연습문제2 (다음 코드 문제점 확인하고 수정하기)</font>**\n",
    "  \n",
    "  - 팁: 이전 시간에 설명한 CSS Selector 내용 상기\n",
    "  1. 에러 메세지를 읽고, 어떤 라인에서 문제가 있는지를 확인한 후\n",
    "  2. 해당 라인의 코드에 어떤 문제가 있는지를 CSS Selector 문법과 해당 웹페이지 소스를 비교해가며 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "포커 정복한 AI, 어디까지 진화할까 | Daum 뉴스\n"
     ]
    },
    {
     "ename": "NoSuchElementException",
     "evalue": "Message: {\"errorMessage\":\"Unable to find element with css selector 'html > title'\",\"request\":{\"headers\":{\"Accept\":\"application/json\",\"Accept-Encoding\":\"identity\",\"Connection\":\"close\",\"Content-Length\":\"103\",\"Content-Type\":\"application/json;charset=UTF-8\",\"Host\":\"127.0.0.1:4589\",\"User-Agent\":\"Python http auth\"},\"httpVersion\":\"1.1\",\"method\":\"POST\",\"post\":\"{\\\"using\\\": \\\"css selector\\\", \\\"value\\\": \\\"html > title\\\", \\\"sessionId\\\": \\\"7a719140-a4d2-11e7-85f1-2d818984f2a9\\\"}\",\"url\":\"/element\",\"urlParsed\":{\"anchor\":\"\",\"query\":\"\",\"file\":\"element\",\"directory\":\"/\",\"path\":\"/element\",\"relative\":\"/element\",\"port\":\"\",\"host\":\"\",\"password\":\"\",\"user\":\"\",\"userInfo\":\"\",\"authority\":\"\",\"protocol\":\"\",\"source\":\"/element\",\"queryKey\":{},\"chunks\":[\"element\"]},\"urlOriginal\":\"/session/7a719140-a4d2-11e7-85f1-2d818984f2a9/element\"}}\nScreenshot: available via screen\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-4ef08a550db1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtitle_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_attribute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mtitle_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element_by_css_selector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'html > title'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;31m# title 정보는 get_attribute('text') 메서드로 추출할 수 있습니다.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtitle_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_attribute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\dev_python\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mfind_element_by_css_selector\u001b[1;34m(self, css_selector)\u001b[0m\n\u001b[0;32m    496\u001b[0m             \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element_by_css_selector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'#foo'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    497\u001b[0m         \"\"\"\n\u001b[1;32m--> 498\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCSS_SELECTOR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcss_selector\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    499\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    500\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfind_elements_by_css_selector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcss_selector\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\dev_python\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mfind_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    830\u001b[0m         return self.execute(Command.FIND_ELEMENT, {\n\u001b[0;32m    831\u001b[0m             \u001b[1;34m'using'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 832\u001b[1;33m             'value': value})['value']\n\u001b[0m\u001b[0;32m    833\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    834\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfind_elements\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mID\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\dev_python\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    295\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 297\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    298\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[0;32m    299\u001b[0m                 response.get('value', None))\n",
      "\u001b[1;32mC:\\dev_python\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    192\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mexception_class\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mUnexpectedAlertPresentException\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m'alert'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'alert'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 194\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNoSuchElementException\u001b[0m: Message: {\"errorMessage\":\"Unable to find element with css selector 'html > title'\",\"request\":{\"headers\":{\"Accept\":\"application/json\",\"Accept-Encoding\":\"identity\",\"Connection\":\"close\",\"Content-Length\":\"103\",\"Content-Type\":\"application/json;charset=UTF-8\",\"Host\":\"127.0.0.1:4589\",\"User-Agent\":\"Python http auth\"},\"httpVersion\":\"1.1\",\"method\":\"POST\",\"post\":\"{\\\"using\\\": \\\"css selector\\\", \\\"value\\\": \\\"html > title\\\", \\\"sessionId\\\": \\\"7a719140-a4d2-11e7-85f1-2d818984f2a9\\\"}\",\"url\":\"/element\",\"urlParsed\":{\"anchor\":\"\",\"query\":\"\",\"file\":\"element\",\"directory\":\"/\",\"path\":\"/element\",\"relative\":\"/element\",\"port\":\"\",\"host\":\"\",\"password\":\"\",\"user\":\"\",\"userInfo\":\"\",\"authority\":\"\",\"protocol\":\"\",\"source\":\"/element\",\"queryKey\":{},\"chunks\":[\"element\"]},\"urlOriginal\":\"/session/7a719140-a4d2-11e7-85f1-2d818984f2a9/element\"}}\nScreenshot: available via screen\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "\n",
    "driver = webdriver.PhantomJS('C:/dev_python/phantomjs-2.1.1-windows/bin/phantomjs.exe') # 윈도우\n",
    "# driver = webdriver.PhantomJS('/usr/local/Cellar/phantomjs/2.1.1/bin/phantomjs') # 맥\n",
    "driver.get('http://v.media.daum.net/v/20170202180355822')\n",
    "\n",
    "title_data = driver.find_element_by_css_selector('html head title')\n",
    "print(title_data.get_attribute('text'))\n",
    "\n",
    "title_data = driver.find_element_by_css_selector('html > title')\n",
    "# head 태그 안에 있는 title 정보는 get_attribute('text') 메서드로 추출할 수 있습니다. \n",
    "print(title_data.get_attribute('text'))\n",
    "\n",
    "contents = driver.find_element_by_css_selector(\"div#harmonyContainer\")\n",
    "# body 안에 있는 태그 요소는 .text 로 추출할 수 있습니다. (출력이 잘 안되면, 둘다 써보셔도 좋습니다.)\n",
    "print(contents.text)\n",
    "\n",
    "for p in contents.find_elements_by_tag_name('p'):\n",
    "    print (p.text)\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 속성으로 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "홈\n",
      "사회\n",
      "정치\n",
      "경제\n",
      "국제\n",
      "문화\n",
      "IT\n",
      "랭킹\n",
      "연재\n",
      "포토\n",
      "TV\n",
      "1boon\n",
      "스토리펀딩\n",
      "서울\n",
      "서울 23 ℃\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "\n",
    "# driver = webdriver.PhantomJS('C:/dev_python/phantomjs-2.1.1-windows/bin/phantomjs.exe') # 윈도우\n",
    "driver = webdriver.PhantomJS('/usr/local/Cellar/phantomjs/2.1.1/bin/phantomjs') # 맥\n",
    "driver.get('http://v.media.daum.net/v/20170202180355822')\n",
    "\n",
    "# role attribute가 navigation인 div태그\n",
    "nav = driver.find_element_by_css_selector(\"div[role='navigation']\")\n",
    "print(nav.text)\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4 XPATH를 이용하여 가져오기\n",
    " - 마크업에서 요소를 정의하기 위해 path 경로를 사용하는 방법\n",
    " - find_element_by_xpath(), find_elements_by_xpath() 메서드로 검색 가능\n",
    " - [XPATH 문법 상세 참고](https://wkdtjsgur100.github.io/selenium-xpath/)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "   - / : 절대경로를 나타냄\n",
    "   - // : 문서내에서 검색\n",
    "   - //@href : href 속성이 있는 모든 태그 선택\n",
    "   - //a[@href='http://google.com'] : a 태그의 href 속성에 http://google.com 속성값을 가진 모든 태그 선택 \n",
    "   - (//a)[3] : 문서의 세 번째 링크 선택\n",
    "   - (//table)[last()] : 문서의 마지막 테이블 선택\n",
    "   - (//a)[position() < 3] : 문서의 처음 두 링크 선택\n",
    "   - //table/tr/* 모든 테이블에서 모든 자식 tr 태그 선택\n",
    "   - //div[@*] 속성이 하나라도 있는 div 태그 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "아이폰8 출시..예전같은 열기는 없었다 | Daum 뉴스\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "\n",
    "# driver = webdriver.PhantomJS('C:/dev_python/phantomjs-2.1.1-windows/bin/phantomjs.exe') # 윈도우\n",
    "driver = webdriver.PhantomJS('/usr/local/Cellar/phantomjs/2.1.1/bin/phantomjs') # 맥\n",
    "driver.get('http://v.media.daum.net/v/20170922175202762')\n",
    "\n",
    "title = driver.find_element_by_xpath(\"//title\") # 문서내의 어떤 태그든지 가능\n",
    "\n",
    "# head 태그 안에 있는 title 정보는 get_attribute('text') 메서드로 추출할 수 있습니다.\n",
    "print (title.get_attribute('text'))\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **<font color=\"blue\" size=\"4em\">실습 (함께 작성해보는 코드)</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'포켓몬고' 상륙 1주일.. 대한민국 곳곳이 들썩 | Daum 뉴스\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "\n",
    "# driver = webdriver.PhantomJS('C:/dev_python/phantomjs-2.1.1-windows/bin/phantomjs.exe') # 윈도우\n",
    "driver = webdriver.PhantomJS('/usr/local/Cellar/phantomjs/2.1.1/bin/phantomjs') # 맥\n",
    "driver.get('http://v.media.daum.net/v/20170922182449443')\n",
    "\n",
    "title = driver.find_element_by_xpath(\"/html/head/title\") # 절대경로\n",
    "\n",
    "# head 태그 안에 있는 title 정보는 get_attribute('text') 메서드로 추출할 수 있습니다.\n",
    "print (title.get_attribute('text'))\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'포켓몬고' 상륙 1주일.. 대한민국 곳곳이 들썩 | Daum 뉴스\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "\n",
    "# driver = webdriver.PhantomJS('C:/dev_python/phantomjs-2.1.1-windows/bin/phantomjs.exe') # 윈도우\n",
    "driver = webdriver.PhantomJS('/usr/local/Cellar/phantomjs/2.1.1/bin/phantomjs') # 맥\n",
    "driver.get('http://v.media.daum.net/v/20170202185812986')\n",
    "\n",
    "title = driver.find_element_by_xpath(\"/html//title\") # html 태그 내에서 다시 검색\n",
    "\n",
    "# head 태그 안에 있는 title 정보는 get_attribute('text') 메서드로 추출할 수 있습니다.\n",
    "print (title.get_attribute('text'))\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 속성으로 검색하는 XPATH 문법: 태그[@속성=속성값] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'포켓몬고' 상륙 1주일.. 대한민국 곳곳이 들썩\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "\n",
    "# driver = webdriver.PhantomJS('C:/dev_python/phantomjs-2.1.1-windows/bin/phantomjs.exe') # 윈도우\n",
    "driver = webdriver.PhantomJS('/usr/local/Cellar/phantomjs/2.1.1/bin/phantomjs') # 맥\n",
    "driver.get('http://v.media.daum.net/v/20170202185812986')\n",
    "\n",
    "#soup.find('h3', attrs = {'class' : 'tit_s'})\n",
    "title_content = driver.find_element_by_xpath(\"//h3[@class='tit_view']\")\n",
    "\n",
    "# body 안에 있는 태그 요소는 .text 로 추출할 수 있습니다. (출력이 잘 안되면, 둘다 써보셔도 좋습니다.)\n",
    "print (title_content.text)\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(지디넷코리아=김익현 기자)한 때 ‘마이너리티 리포트’란 영화가 인기를 끈 적 있다. 최첨단 치안시스템을 통해 범죄를 미리 예측한 뒤 특수 경찰을 보내 미래의 범죄자들을 체포하는 얘기다.\n",
      "하지만 그 영화를 보면서 “그럴듯하다”고 생각했던 사람은 거의 없었다. ‘무서운 미래’이긴 했지만 ‘있음직한 미래상’은 아니었단 얘기다.\n",
      "최근 인공지능(AI)이 포커 시합에서 최고수 프로 선수를 꺾었단 소식을 접하면서 ‘마이너리티 리포트’가 황당한 얘기만은 아닐 수도 있다는 생각을 하게 됐다.\n",
      "\n",
      "일단 팩트부터 챙겨보자.\n",
      "프로 포커 선수 네 명을 꺾은 화제의 주인공은 리브라투스(Libratus)란 AI 프로그램이다. 미국 카네기멜론대학 연구팀이 개발한 이 프로그램은 지난 달 11일부터 30일까지 20일 동안 계속된 포커 대결에서 승리했다.\n",
      "자세한 얘기는 생략한다. 궁금한 분은 지디넷코리아에 게재된 기사를 확인해보시라.\n",
      "[관련기사1] AI는 어떻게 심리싸움 '뻥카'까지 알았을까\n",
      "[관련기사2] 카네기멜론대학의 공식 자료\n",
      "■ 바둑과는 또 다른 포커 정복\n",
      "이번 결과에 대해 카네기멜론대학 뿐 아니라 세계 주요 외신들도 흥분을 감추지 못하고 있다.\n",
      "당연히 궁금증이 제기되지 않을 수 없다. 이미 AI는 퀴즈쇼, 체스에 이어 난공불락의 영역이라 일컬어지던 바둑까지 정복했기 때문이다.\n",
      "세계 최강 이세돌 9단에 이어 중국의 커제 9단까지 알파고에 완패한 마당에 포커 시합에서 진 게 뭐 그리 대단한 일이냐고 생각할 수도 있다.\n",
      "하지만 포커와 바둑은 조금 다르다.\n",
      "물론 바둑 경기에서 고려해야 할 수는 무한 대에 가깝다. 한 수를 둘 때 가능한 수가 250개 정도에 이른다.한 경기에 150수 이상 둔다고 가정하면 '250의 150승’이란 경우의 수가 만들어진다. 이게 유기적으로 연결돼야 한다. 중간에 수 하나만 삐끗해도 시합을 망치게 된다.\n",
      "\n",
      "그 동안 ‘바둑은 인간의 영역’이라고 했던 건 인공지능은 직관적으로 문제를 해결하긴 쉽지 않을 것으로 생각했기 때문이다.\n",
      "이처럼 방대하긴 하지만 바둑 경기는 ‘모든 정보’를 갖고 임할 수 있다. 대국을 하는 두 선수는 전체 바둑판을 보면서 추론을 할 수 있다.\n",
      "그런데 포커는 다르다. 바둑과 달리 ‘제한된 정보’만 갖고 경기에 임해야 한다. 일단 상대방의 패를 볼 수가 없다.\n",
      "‘좋은 수’를 갖고 있다고 해서 꼭 이긴다는 보장도 없다. ‘뻥카’로 불리는 고도의 심리전이 중요한 전략적 무기중 하나다.\n",
      "이 차이는 인공지능 개발 과정에서도 중요한 의미를 갖는다. 바둑 대국을 한 알파고는 무수히 많은 상대의 수를 분석해서 내게 맞는 최적의 수를 찾아내면 됐다.\n",
      "하지만 포커 전문 AI는 반대 추론도 할 줄 알아야 한다. 무슨 얘기일까? 상대방이 내 약점을 어떻게 찌르고 들어오는지 추론한 뒤 방어 대책을 세워야 한다는 것이다. 그렇기 때문에 한 단계 더 진전된 능력으로 무장해야만 한다.\n",
      "그러다보니 이번 대결이 시작되기 전 국내 도박사이트들은 4대 1 정도로 인간 포커 기사들이 우세할 것으로 전망했다.\n",
      "리브라투스가 프로 포커 기사와 대결에서 승리한 게 의미 있는 건 이런 부분 때문이다.\n",
      "■ 외신들 \"불완전한 정보로 완벽한 추론\" 흥분\n",
      "이번 승리는 포커 AI가 ’불완전한 정보’를 토대로 상대방의 심리를 추론할 능력까지 갖췄다는 의미다. 주어진 수를 잘 읽는 AI보다 한 단계 더 높은 능력을 보여줬단 얘기다.\n",
      "실제로 이번 대결에서 승리한 카네기멜론대학 측은 “앞으로 비즈니스 협상 뿐 아니라 군사전략, 사이버 보안, 의료분야까지 활용 가능할 것”이라고 호언 장담했다.\n",
      "알파고와 달리 리브라투스 얘긴 아직 공식 논문으로 발표되진 않았다. 그런만큼 ‘어떻게 이겼는지’에 대한 자세한 얘긴 아직 공개되지 않았다.\n",
      "다만 카네기멜론대학 팀은 하루 11시간씩 계속된 포커 경기가 끝날 때마다 분석 작업을 했다고 밝히고 있다. 처음엔 포커를 둘 줄도 몰랐던 리브라투스는 경기가 거듭되면서 상대방의 수 뿐 아니라 ‘나의 약점’을 상대방이 어떻게 파고 드는지까지 분석해냈다고 한다.\n",
      "\n",
      "이쯤 되면 살짝 두렵다는 생각까지 든다. 게다가 리브라투스는 포커에만 특화된 프로그램이 아니라고 한다. 다른 영역에도 확장 가능하단 얘기다.\n",
      "루이빌대학 컴퓨터공학과의 로만 얌폴스키 교수는 라디언과 인터뷰에서 “비즈니스나 군사 작전에서 당신을 엿 먹일 수 있는 기계를 갖게 됐다”고 경고했다.\n",
      "무한대에 가깝던 바둑의 수를 읽어내던 AI가 이젠 상대방의 패를 보지도 못한 상태에서 ‘뻥카’까지 성공적으로 치는 수준으로 발전했다.\n",
      "이런 속도라면 어디까지 진화할 수 있을까?\n",
      "■ 알파고보다 더 무서운 포커 AI, 어디까지 진화할까\n",
      "자율주행차에 탑재한 인공지능이 운전자의 심리나 건강 상태를 본 뒤 ‘운전 금지’라면 시동 걸리길 거부할 수도 있지 않을까? ‘마이너리티 리포트’ 같은 범죄 예방 시스템이 등장하지 않을까? 그러다가 결국은 정치와 비즈니스 협상까지 인공지능에 맡겨야 할 시대가 오는 건 아닐까?\n",
      "포커 고수까지 인공지능에게 무릎 꿇었다는 소식을 접하면서 이런 생각들을 해봤다.\n",
      "아직까지 카네기멜론대학은 리브라투스 관련 논문을 공식 발표하진 않았다. 2월 중 학회에서 발표할 예정이라고 하니 논문이 나오길 손꼽아 기다려본다. 카네기멜론대학 측이 논문을 공식 발표하면 이 코너를 통해 상세하게 요약해드리겠단 ‘공약’을 해본다.\n",
      "[관련기사3] 구글 알파고는 어떻게 바둑경기 이겼나\n",
      "(덧글)\n",
      "이번 대결 방식이 인간들에게 다소 불리했단 얘기도 있다. 이번 대회 기간 동안 매일 밤 10시까지 경기를 했다고 한다. 하루 11시간의 강행군이 끝나면 리브라투스와 인간 모두 ‘분석 작업’을 했다. 그래서 인간 선수들은 새벽 두 시에나 잠자리에 들 수 있었다고 한다.\n",
      "잠을 잘 필요도, 식사나 화장실을 갈 필요도 없는 인공지능과 달리, 인간들에겐 참 힘든 여정이었겠단 생각을 해봤다.\n",
      "김익현 기자(sini@zdnet.co.kr)\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "\n",
    "# driver = webdriver.PhantomJS('C:/dev_python/phantomjs-2.1.1-windows/bin/phantomjs.exe') # 윈도우\n",
    "driver = webdriver.PhantomJS('/usr/local/Cellar/phantomjs/2.1.1/bin/phantomjs') # 맥\n",
    "driver.get('http://v.media.daum.net/v/20170202180355822')\n",
    "\n",
    "body = driver.find_element_by_xpath(\"//div[@id='harmonyContainer']\")\n",
    "for p in body.find_elements_by_tag_name('p'):\n",
    "    print (p.text)\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "**<font color=\"blue\" size=\"4em\">연습문제3</font>**\n",
    "\n",
    "  http://v.media.daum.net/v/20170202180355822 페이지에서<br>\n",
    "  <br>\n",
    "  [김익현의 미디어 읽기] '마이너리티 리포트'와 AI\n",
    "  <br><br>\n",
    "  를 XPATH로 크롤링해서 출력하세요<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 2.5 페이지 로딩 시간을 기다린 후, 검색하는 방법\n",
    " - 몇몇 페이지의 경우, 페이지 로딩 지연이 발생하여(여러 요청이 병합하여 페이지 결과를 생성) tag를 못읽어오는 경우가 발생할 수 있음\n",
    " - 이때, 아래의 코드를 이용하여 해결 가능\n",
    " - e.g) 10초내에 해당 tag를 찾으면 반환, 그렇지 않으면 timeout 발생!\n",
    " - http://selenium-python.readthedocs.io/waits.html\n",
    "\n",
    "\n",
    "* WebDriverWait() 메서드\n",
    " - 명시적인 페이지 로드 대기에 사용됨\n",
    " - 주로 다음 코드와 같이 사용됨\n",
    " \n",
    "```\n",
    "try:\n",
    "    element = WebDriverWait(driver, 몇초).until(\n",
    "        # By.ID 는 ID로 검색, By.CSS_SELECTOR 는 CSS Selector 로 검색\n",
    "        EC.presence_of_element_located((By.ID, \"cMain\"))\n",
    "    )\n",
    "except TimeoutException:\n",
    "    print(\"타임아웃\")\n",
    "finally:\n",
    "    driver.quit()\n",
    "```\n",
    "\n",
    "* from selenium.webdriver.common.by import By 검색 지원 방법\n",
    "``` \n",
    " By.ID - 태그에 있는 ID 로 검색\n",
    " By.CSS_SELECTOR - CSS Selector 로 검색\n",
    " By.NAME - 태그에 있는 name 으로 검색\n",
    " By.TAG_NAME - 태그 이름으로 검색\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[김익현의 미디어 읽기] '마이너리티 리포트'와 AI\n",
      "(지디넷코리아=김익현 기자)한 때 ‘마이너리티 리포트’란 영화가 인기를 끈 적 있다. 최첨단 치안시스템을 통해 범죄를 미리 예측한 뒤 특수 경찰을 보내 미래의 범죄자들을 체포하는 얘기다.\n",
      "하지만 그 영화를 보면서 “그럴듯하다”고 생각했던 사람은 거의 없었다. ‘무서운 미래’이긴 했지만 ‘있음직한 미래상’은 아니었단 얘기다.\n",
      "최근 인공지능(AI)이 포커 시합에서 최고수 프로 선수를 꺾었단 소식을 접하면서 ‘마이너리티 리포트’가 황당한 얘기만은 아닐 수도 있다는 생각을 하게 됐다.\n",
      "영화 '마이너리티 리포트'는 범죄자를 사전에 알아내는 지나치게 똑똑한 인조인간 얘기로 많은 충격을 안겨줬다.\n",
      "일단 팩트부터 챙겨보자.\n",
      "프로 포커 선수 네 명을 꺾은 화제의 주인공은 리브라투스(Libratus)란 AI 프로그램이다. 미국 카네기멜론대학 연구팀이 개발한 이 프로그램은 지난 달 11일부터 30일까지 20일 동안 계속된 포커 대결에서 승리했다.\n",
      "자세한 얘기는 생략한다. 궁금한 분은 지디넷코리아에 게재된 기사를 확인해보시라.\n",
      "[관련기사1] AI는 어떻게 심리싸움 '뻥카'까지 알았을까\n",
      "[관련기사2] 카네기멜론대학의 공식 자료\n",
      "■ 바둑과는 또 다른 포커 정복\n",
      "이번 결과에 대해 카네기멜론대학 뿐 아니라 세계 주요 외신들도 흥분을 감추지 못하고 있다.\n",
      "당연히 궁금증이 제기되지 않을 수 없다. 이미 AI는 퀴즈쇼, 체스에 이어 난공불락의 영역이라 일컬어지던 바둑까지 정복했기 때문이다.\n",
      "세계 최강 이세돌 9단에 이어 중국의 커제 9단까지 알파고에 완패한 마당에 포커 시합에서 진 게 뭐 그리 대단한 일이냐고 생각할 수도 있다.\n",
      "하지만 포커와 바둑은 조금 다르다.\n",
      "물론 바둑 경기에서 고려해야 할 수는 무한 대에 가깝다. 한 수를 둘 때 가능한 수가 250개 정도에 이른다.한 경기에 150수 이상 둔다고 가정하면 '250의 150승’이란 경우의 수가 만들어진다. 이게 유기적으로 연결돼야 한다. 중간에 수 하나만 삐끗해도 시합을 망치게 된다.\n",
      "인공지능 프로그램 리브라투스와 프로 포커 선수들의 시합 장면. (사진=카네기멜론대학)\n",
      "그 동안 ‘바둑은 인간의 영역’이라고 했던 건 인공지능은 직관적으로 문제를 해결하긴 쉽지 않을 것으로 생각했기 때문이다.\n",
      "이처럼 방대하긴 하지만 바둑 경기는 ‘모든 정보’를 갖고 임할 수 있다. 대국을 하는 두 선수는 전체 바둑판을 보면서 추론을 할 수 있다.\n",
      "그런데 포커는 다르다. 바둑과 달리 ‘제한된 정보’만 갖고 경기에 임해야 한다. 일단 상대방의 패를 볼 수가 없다.\n",
      "‘좋은 수’를 갖고 있다고 해서 꼭 이긴다는 보장도 없다. ‘뻥카’로 불리는 고도의 심리전이 중요한 전략적 무기중 하나다.\n",
      "이 차이는 인공지능 개발 과정에서도 중요한 의미를 갖는다. 바둑 대국을 한 알파고는 무수히 많은 상대의 수를 분석해서 내게 맞는 최적의 수를 찾아내면 됐다.\n",
      "하지만 포커 전문 AI는 반대 추론도 할 줄 알아야 한다. 무슨 얘기일까? 상대방이 내 약점을 어떻게 찌르고 들어오는지 추론한 뒤 방어 대책을 세워야 한다는 것이다. 그렇기 때문에 한 단계 더 진전된 능력으로 무장해야만 한다.\n",
      "그러다보니 이번 대결이 시작되기 전 국내 도박사이트들은 4대 1 정도로 인간 포커 기사들이 우세할 것으로 전망했다.\n",
      "리브라투스가 프로 포커 기사와 대결에서 승리한 게 의미 있는 건 이런 부분 때문이다.\n",
      "■ 외신들 \"불완전한 정보로 완벽한 추론\" 흥분\n",
      "이번 승리는 포커 AI가 ’불완전한 정보’를 토대로 상대방의 심리를 추론할 능력까지 갖췄다는 의미다. 주어진 수를 잘 읽는 AI보다 한 단계 더 높은 능력을 보여줬단 얘기다.\n",
      "실제로 이번 대결에서 승리한 카네기멜론대학 측은 “앞으로 비즈니스 협상 뿐 아니라 군사전략, 사이버 보안, 의료분야까지 활용 가능할 것”이라고 호언 장담했다.\n",
      "알파고와 달리 리브라투스 얘긴 아직 공식 논문으로 발표되진 않았다. 그런만큼 ‘어떻게 이겼는지’에 대한 자세한 얘긴 아직 공개되지 않았다.\n",
      "다만 카네기멜론대학 팀은 하루 11시간씩 계속된 포커 경기가 끝날 때마다 분석 작업을 했다고 밝히고 있다. 처음엔 포커를 둘 줄도 몰랐던 리브라투스는 경기가 거듭되면서 상대방의 수 뿐 아니라 ‘나의 약점’을 상대방이 어떻게 파고 드는지까지 분석해냈다고 한다.\n",
      "리브라투스를 공동 개발한 토머스 샌드홀름 교수. (사진=카네기멜론대학)\n",
      "이쯤 되면 살짝 두렵다는 생각까지 든다. 게다가 리브라투스는 포커에만 특화된 프로그램이 아니라고 한다. 다른 영역에도 확장 가능하단 얘기다.\n",
      "루이빌대학 컴퓨터공학과의 로만 얌폴스키 교수는 라디언과 인터뷰에서 “비즈니스나 군사 작전에서 당신을 엿 먹일 수 있는 기계를 갖게 됐다”고 경고했다.\n",
      "무한대에 가깝던 바둑의 수를 읽어내던 AI가 이젠 상대방의 패를 보지도 못한 상태에서 ‘뻥카’까지 성공적으로 치는 수준으로 발전했다.\n",
      "이런 속도라면 어디까지 진화할 수 있을까?\n",
      "■ 알파고보다 더 무서운 포커 AI, 어디까지 진화할까\n",
      "자율주행차에 탑재한 인공지능이 운전자의 심리나 건강 상태를 본 뒤 ‘운전 금지’라면 시동 걸리길 거부할 수도 있지 않을까? ‘마이너리티 리포트’ 같은 범죄 예방 시스템이 등장하지 않을까? 그러다가 결국은 정치와 비즈니스 협상까지 인공지능에 맡겨야 할 시대가 오는 건 아닐까?\n",
      "포커 고수까지 인공지능에게 무릎 꿇었다는 소식을 접하면서 이런 생각들을 해봤다.\n",
      "아직까지 카네기멜론대학은 리브라투스 관련 논문을 공식 발표하진 않았다. 2월 중 학회에서 발표할 예정이라고 하니 논문이 나오길 손꼽아 기다려본다. 카네기멜론대학 측이 논문을 공식 발표하면 이 코너를 통해 상세하게 요약해드리겠단 ‘공약’을 해본다.\n",
      "[관련기사3] 구글 알파고는 어떻게 바둑경기 이겼나\n",
      "(덧글)\n",
      "이번 대결 방식이 인간들에게 다소 불리했단 얘기도 있다. 이번 대회 기간 동안 매일 밤 10시까지 경기를 했다고 한다. 하루 11시간의 강행군이 끝나면 리브라투스와 인간 모두 ‘분석 작업’을 했다. 그래서 인간 선수들은 새벽 두 시에나 잠자리에 들 수 있었다고 한다.\n",
      "잠을 잘 필요도, 식사나 화장실을 갈 필요도 없는 인공지능과 달리, 인간들에겐 참 힘든 여정이었겠단 생각을 해봤다.\n",
      "김익현 기자(sini@zdnet.co.kr)\n",
      "#인공지능\n",
      "#대결\n",
      "#범죄예방\n",
      "연재김익현의 미디어 읽기\n",
      "뉴스 무한복제시대..NYT의 해법은\n",
      "포커 정복한 AI, 어디까지 진화할까\n",
      "미래 IT세계 보여준 슈퍼볼 드론쇼\n",
      "더보기\n",
      "[Copyrightⓒ메가뉴스 & ZDNet & CNET. 무단전재 및 재배포 금지]\n",
      "16\n",
      "지디넷코리아 주요 뉴스해당 언론사로 연결됩니다.\n",
      "AI는 어떻게 심리싸움 '뻥카'까지 알았을까\n",
      "美 AI강자 비브는 왜 삼성을 택했을까\n",
      "구글 CEO는 왜 'AI 퍼스트' 선언했나\n",
      "AI·로봇에 대체될 가능성이 낮은 직업은?\n",
      "구글 알파고와 튜링테스트의 기억\n",
      "구글 알파고는 어떻게 바둑경기 이겼나\n",
      "카페24의 '디지털 실크로드' 세계로 뻗다\n",
      "구글-애플 신패권 전쟁…\"적 장점 흡수하라\"\n",
      "HTML5 게임, 새 바람 일으키나\n",
      "아이폰8 출시…예전같은 열기는 없었다\n",
      "댓글 25\n",
      "내 댓글\n",
      "로그인 해주세요.\n",
      "추천순\n",
      "최신순\n",
      "과거순\n",
      "시사비평가\n",
      "2017.02.02 19:32\n",
      "이 기사가 터무니없는 이유....뻥카로 이긴 횟수가 표시되지 않았기에 과연 정말 그런 추론을 했는지가 증명이 되지않았다\n",
      "만약 포커를 모두 외울정도의 기억력이 존재한다면 확률상 대부분 승리할 것이다\n",
      "그러니 그 승리가 뻥카까지 섭렵한 승리인지 판단이 불가능하다는 것이다\n",
      "답글 2\n",
      "댓글 찬성하기\n",
      "15\n",
      "댓글 비추천하기\n",
      "3\n",
      "조명주\n",
      "2017.02.02 23:04\n",
      "Al 기술력이 진화해서\n",
      "여러가지 영역에서 인간의 두뇌와 시합하는\n",
      "모험은 좋지만..\n",
      " 인간은 두뇌를\n",
      "선하게 잘 쓸수 있는 마음의 지능이 있지만\n",
      "기계는 입력된 프로그램을 이용해서\n",
      "최적의 답안을 내는  숙련된 기계 지능일뿐인~\n",
      "인간을 위한 선한 도구가 될지\n",
      "위험 인자를 가지고\n",
      "인간들을 해할 것인지를\n",
      "깊이 고뇌하고\n",
      "지식이\n",
      "인간에게 주는 효율적인 편리함과\n",
      "인간 사회를 이롭게 하는데에\n",
      "인공지능이 할일에\n",
      "대해서..\n",
      "바른 가치관의 정립도\n",
      "뿌리를 내리는..\n",
      "답글쓰기\n",
      "댓글 찬성하기\n",
      "9\n",
      "댓글 비추천하기\n",
      "2\n",
      "rjwltakf\n",
      "2017.02.09 23:03\n",
      "인공지능을 우습게 알지 마라 앞으로 양자컴퓨터와 인공지능이 결합하면 지금과는 진짜로 다른세상이 전개된다\n",
      "답글쓰기\n",
      "댓글 찬성하기\n",
      "1\n",
      "댓글 비추천하기\n",
      "0\n",
      "더보기\n",
      "새로고침\n",
      "많이본 뉴스\n",
      "뉴스\n",
      "정진석 \"盧전대통령, 부부싸움 끝 자살\" 발언 파문 확산(종합)\n",
      "'韓 여성 성폭행' 日 민박집 주인 \"술에 수면제 탔었다\"\n",
      "여교사 과녁에 세우고 '체험용 활' 쏜 갑질 교감\n",
      "임은정 \"괴물 잡겠다고 검사 됐는데 우리가 괴물이더라\"\n",
      "쩍쩍 갈라지고 내려앉고..부산 신축 오피스텔 '기우뚱'\n",
      "\"점주·본사 6백만원 냈는데 제빵사는 2백만원만 받아\"\n",
      "정청래 \"아들이 여학생 성추행..아버지로서 죄송\"\n",
      "'박근혜 재판' 증인들 \"조윤선도 블랙리스트 관여했다\"\n",
      "'제2의 파리바게뜨 될라'..납작 엎드린 프랜차이즈 업계\n",
      "\"1천600억 한꺼번에\"..정부 제동 비웃듯 재건축 '돈잔치'\n",
      "이전\n",
      "다음\n",
      "전체랭킹\n",
      "연예\n",
      "스포츠\n",
      "포토&TV\n",
      "포토\n",
      "[포토뉴스]한복 나들이 신나요\n",
      "영상\n",
      "[날씨] 미세먼지·일교차 주의..새벽 중부 일부 빗방...\n",
      "실시간 이슈\n",
      "전체\n",
      "뉴스\n",
      "1위\n",
      "이재명 청년통장\n",
      "2위\n",
      "공항철도\n",
      "3위\n",
      "임은정 검사\n",
      "4위\n",
      "시베리안 허스키\n",
      "5위\n",
      "노무현\n",
      "6위\n",
      "애견카페\n",
      "7위\n",
      "검암역\n",
      "8위\n",
      "인천교감 화살\n",
      "9위\n",
      "김정은\n",
      "10위\n",
      "괴산군수\n",
      "연예\n",
      "스포츠\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "\n",
    "driver = webdriver.PhantomJS('C:/dev_python/phantomjs-2.1.1-windows/bin/phantomjs.exe')\n",
    "# driver = webdriver.PhantomJS('/usr/local/Cellar/phantomjs/2.1.1/bin/phantomjs')\n",
    "driver.get('http://v.media.daum.net/v/20170202180355822')\n",
    "try:\n",
    "    # id가 cMain인 tag를 10초 내에 검색, 그렇지 않으면 timeoutexception 발생\n",
    "    element = WebDriverWait(driver, 10).until(\n",
    "        # By.ID 는 ID로 검색, By.CSS_SELECTOR 는 CSS Selector 로 검색\n",
    "        EC.presence_of_element_located((By.ID, \"cMain\"))\n",
    "    )\n",
    "    print(element.text)\n",
    "\n",
    "except TimeoutException:\n",
    "    print(\"해당 페이지에 cMain 을 ID 로 가진 태그가 존재하지 않거나, 해당 페이지가 10초 안에 열리지 않았습니다.\")\n",
    "    \n",
    "finally:\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.6 웹사이트 자동 조작하는 방법\n",
    "\n",
    "  - element 클릭: element.click()\n",
    "  - element 더블 클릭: element.double_click()\n",
    "  - element 키보드 입력 전송: element.send_keys()\n",
    "  - element 로 마우스 이동: element.move_to_element()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello there, Doky Kim!\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.remote.webelement import WebElement\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver import ActionChains\n",
    "\n",
    "driver = webdriver.PhantomJS('C:/dev_python/phantomjs-2.1.1-windows/bin/phantomjs.exe')\n",
    "# driver = webdriver.PhantomJS('/usr/local/Cellar/phantomjs/2.1.1/bin/phantomjs')\n",
    "driver.get(\"http://pythonscraping.com/pages/files/form.html\")\n",
    "\n",
    "firstnameField = driver.find_element_by_name(\"firstname\")\n",
    "lastnameField = driver.find_element_by_name(\"lastname\")\n",
    "submitButton = driver.find_element_by_id(\"submit\")\n",
    "\n",
    "firstnameField.send_keys(\"Doky\")\n",
    "lastnameField.send_keys(\"Kim\")\n",
    "submitButton.click()\n",
    "\n",
    "print(driver.find_element_by_tag_name(\"body\").text)\n",
    "\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ActionChains(): 행동 여러 개를 체인 으로 묶어서 저장하고 원하는 만큼 실행\n",
    "- perform() 메서드 실행시 전체 행동을 실행함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello there, Doky Kim!\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.remote.webelement import WebElement\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver import ActionChains\n",
    "\n",
    "driver = webdriver.PhantomJS('C:/dev_python/phantomjs-2.1.1-windows/bin/phantomjs.exe')\n",
    "# driver = webdriver.PhantomJS('/usr/local/Cellar/phantomjs/2.1.1/bin/phantomjs')\n",
    "driver.get(\"http://pythonscraping.com/pages/files/form.html\")\n",
    "\n",
    "firstnameField = driver.find_element_by_name(\"firstname\")\n",
    "lastnameField = driver.find_element_by_name(\"lastname\")\n",
    "submitButton = driver.find_element_by_id(\"submit\")\n",
    "\n",
    "actions = ActionChains(driver).click(firstnameField).send_keys(\"Doky\").click(lastnameField).send_keys(\"Kim\").send_keys(Keys.RETURN)\n",
    "actions.perform()\n",
    "\n",
    "print(driver.find_element_by_tag_name(\"body\").text)\n",
    "\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **<font color=\"blue\" size=\"4em\">실습 (함께 작성해보는 코드)</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "**<font color=\"blue\" size=\"4em\">연습문제4</font>** \n",
    " - 다음 코드를 기반으로, 코드를 추가하여 해당 다음 뉴스 댓글을 모두 출력하는 프로그램 작성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-12-ae5687809e4e>, line 25)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-12-ae5687809e4e>\"\u001b[0;36m, line \u001b[0;32m25\u001b[0m\n\u001b[0;31m    [------------------------------------]\u001b[0m\n\u001b[0m                                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "\n",
    "# 드라이버 생성\n",
    "# 1. PhantomJS 웹브라우저 설치 및 파이썬 사용법\n",
    "# - Installation of PhantomJS: MAC - pip install phantomjs, Window - http://phantomjs.org\n",
    "# - Add the location of phantomjs to webdriver.PhantomJS('this')\n",
    "chromedriver = 'C:/dev_python/Webdriver/chromedriver.exe'\n",
    "driver = webdriver.Chrome(chromedriver)\n",
    "driver.get(\"http://v.media.daum.net/v/20170922175202762\")\n",
    "\n",
    "print(driver.current_url)\n",
    "try:\n",
    "    element = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.ID, \"alex-area\"))\n",
    "    )\n",
    "finally:\n",
    "    loop = True\n",
    "    while loop:\n",
    "        try:\n",
    "            element = WebDriverWait(driver, 3).until(\n",
    "                [------------------------------------]\n",
    "            )\n",
    "            [------------------------------------]\n",
    "            webdriver.ActionChains(driver).move_to_element(more_button).click(more_button).perform()\n",
    "        except:\n",
    "            loop = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 3 저장하기 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " + csv 모듈을 활용한 CSV 파일 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "csv_file = open(\"test.csv\", \"w+\")\n",
    "try:\n",
    "    writer = csv.writer(csv_file)\n",
    "    writer.writerow(('number', 'number plus 2', 'number times 2'))\n",
    "    for num in range(10):\n",
    "        writer.writerow((num, num+2, num*2))\n",
    "finally:\n",
    "    csv_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " + xlsxwriter 모듈을 활용한 엑셀 파일 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xlsxwriter\n",
    "\n",
    "title_list = [\"웹기술\", \"빅데이터기술\", \"IoT\", \"DataScience\", \"adfdf\", \"dfadfadf\", \"ddd\"]\n",
    "hit_count_list = [2000, 10000, 2000, 2000, 4000, 5000, 6000, 4040]\n",
    "\n",
    "report_excel = xlsxwriter.Workbook('report.xlsx')\n",
    "report_sheet1 = report_excel.add_worksheet('report1')\n",
    "report_sheet2 = report_excel.add_worksheet('report2')\n",
    "\n",
    "report_sheet1.set_column(0, 0, 5)\n",
    "report_sheet1.set_column(1, 1, 80)\n",
    "\n",
    "report_sheet2.set_column(0, 0, 5)\n",
    "report_sheet2.set_column(1, 1, 80)\n",
    "\n",
    "cell_format = report_excel.add_format({'bold': True, 'align': 'center', 'fg_color': '#FFC107', 'color': 'blue', 'border': 10})\n",
    "report_sheet1.write(1, 1, '타이틀', cell_format)\n",
    "report_sheet1.write(1, 2, '클릭수', cell_format)\n",
    "\n",
    "report_sheet2.write(1, 1, '타이틀', cell_format)\n",
    "report_sheet2.write(1, 2, '클릭수', cell_format)\n",
    "\n",
    "cell_format_gray = report_excel.add_format({'fg_color': '#ECEFF1', 'border': 1})\n",
    "cell_format_white = report_excel.add_format({'fg_color': 'white', 'border': 1})\n",
    "\n",
    "for num in range(len(title_list)):\n",
    "    report_sheet1.write(num + 2, 1, title_list[num], cell_format_gray)\n",
    "    report_sheet1.write(num + 2, 2, hit_count_list[num], cell_format_white)\n",
    "\n",
    "for num in range(len(title_list)):\n",
    "    report_sheet2.write(num + 2, 1, title_list[num], cell_format_gray)\n",
    "    report_sheet2.write(num + 2, 2, hit_count_list[num], cell_format_white)\n",
    "    \n",
    "report_excel.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
