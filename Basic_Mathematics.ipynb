{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSS - Mathematics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # 1. 벡터와 행렬"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Types\n",
    "* **scalar** - 하나의 숫자만으로 이루어진 데이터\n",
    "  * *알파벳 소문자*로 표현\n",
    "* **vector** - 여러 개의 숫자가 특정한 순서대로 모여 있는 것 / 하나의 열의 형태로 표현 / 벡터를 이루는 데이터의 개수를 차원이라고 한다\n",
    "  * feature vector - 예측 문제에 사용되는 데이터 벡터\n",
    "  * column vector - 벡터를 $N \\times 1$의 행렬로 인식\n",
    "  * **알파벳 소문자**로 표현\n",
    "* **matrix** - 복수의 차원을 가지는 데이터 레코드가 여러 개 있는 경우 데이터를 합쳐서 표기한 것\n",
    "  * feature matrix - 예측 문제에 사용되는 데이터 행렬\n",
    "  * **알파벳 대문자**로 표현\n",
    "----\n",
    "* **하나의 데이터 레코드를 단독으로 벡터로 나타낼 때는 하나의 열(column)로 표기**\n",
    "* ** 복수의 데이터 레코드 집합을 행렬로 나타낼 때는 하나의 데이터 레코드가 하나의 행(row)으로 표기**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Types - Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scalar1 = 1.0\n",
    "vector1 = np.array([[1.0], [2.0], [3.0], [4.0]])  #Scikit-Learn 패키지 사용시 반드시 이 형태 NX1 형태 사용\n",
    "vector2 = np.array([1.0, 2.0, 3.0, 4.0])\n",
    "matrix1 = np.array([[1,2,3],[4,5,6]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 행렬의 행 표기법과 열 표기법\n",
    "* NumPy에서는 ndarray 객체의 T라는 속성을 이용하여 전치 행렬을 구한다\n",
    "* 이 때 T는 메서드(method)가 아닌 속성(attribute)이므로 ()를 붙여서 호출하면 안된다.\n",
    "\n",
    "$$ X = \\begin{bmatrix} c_1 & c_2 & \\cdots & c_M \\\\ \\end{bmatrix} = \\begin{bmatrix} r_1^T \\\\ r_2^T \\\\ \\vdots \\\\ r_N^T \\\\  \\end{bmatrix}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 특수한 벡터와 행렬\n",
    "* 영 벡터 - 모든 원소가 0 / 문맥에 의해 크기를 알 수 있을 때에는 아래첨자 N 생략 가능\n",
    "* 일 벡터 - 모든 원소가 1 / 문맥에 의해 크기를 알 수 있을 때에는 아래첨자 N 생략 가능\n",
    "----\n",
    "* 정방행렬(square matrix) - 행과 열의 크기가 같음\n",
    "* 대각행렬(diagonal matrix) - off-diagonal 요소가 0인 정방행렬\n",
    "* 단위행렬(identity matrix) - 모든 diagonal 요소가 1인 대각행렬\n",
    "* 대칭행렬(symmetric matrix) - 전치 행렬과 원래 행렬이 같은 행렬"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 대각행렬 / 단위행렬 - numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.diag([1,2,3]) #대각행렬\n",
    "np.identity(3) #단위행렬\n",
    "np.eye(3) #단위행렬"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 벡터와 행렬의 덧셈과 뺄셈 (element-wise operation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.array([1, 1, 1, 1, 1])\n",
    "y = np.array([2, 2, 2, 2, 2])\n",
    "print(x + y, x-y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 벡터의 내적 (inner product *or* dot product)\n",
    "* 두 벡터의 길이가 같고 / 앞의 벡터가 행 벡터이고 뒤의 벡터가 열 벡터일 때만 가능\n",
    "$$ x^T y = \\begin{bmatrix}x_{1} & x_{2} & \\cdots & x_{N} \\end{bmatrix}\\begin{bmatrix}y_{1} \\\\y_{2} \\\\\\vdots \\\\y_{N} \\\\\\end{bmatrix} = x_1y_1 + \\cdots + x_N y_N = \\sum_{i=1}^N x_i y_i$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 벡터의 내적 - numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2차원 배열을 곱하는 경우 전치연산 필요\n",
    "# 결과는 1X1 행렬이다\n",
    "x = np.array([[1], [2], [3]])\n",
    "y = np.array([[4], [5], [6]])\n",
    "np.dot(x.T, y)[0, 0] \n",
    "\n",
    "# 1차원 배열을 곱하는 경우 전치연산 불필요\n",
    "# 결과는 스칼라이다\n",
    "x = np.array([1, 2, 3])\n",
    "y = np.array([4, 5, 6])\n",
    "np.dot(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 가중합 (weighted sum)\n",
    "* 복수의 데이터에 가중치 값을 곱한 후 다시 합한 것 / 선형 조합(linear combination)이라고도 함\n",
    "$$ w_1 x_1 + \\cdots + w_N x_N = \\sum_{i=1}^N w_i x_i   $$ \n",
    "$$= w^Tx$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 평균 (average)\n",
    "* 벡터로 표현된 $N$개의 데이터의 단순 평균은 가중치값이 모두  $\\dfrac{1}{N}$인 가중합과 같다.\n",
    "$$\n",
    "\\bar{x} = \\dfrac{1}{N}\\sum_{i=1}^N x_i = \\dfrac{1}{N} \\mathbf{1}_N^T x\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 평균 - numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.arange(10)\n",
    "x.mean() \n",
    "\n",
    "# 또는\n",
    "\n",
    "N = len(x)\n",
    "np.dot(np.ones(N), x) / N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 제곱합 (sum of squares)\n",
    "$$\n",
    "x^T x = \n",
    "\\begin{bmatrix}\n",
    "x_{1} & x_{2} & \\cdots & x_{N} \n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "x_{1} \\\\\n",
    "x_{2} \\\\\n",
    "\\vdots \\\\\n",
    "x_{N} \\\\\n",
    "\\end{bmatrix} = \\sum_{i=1}^{N} x_i^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 선형 회귀 모형 (linear regression model)\n",
    "* 독립 변수 $x$에서 종속 변수 $y$를 예측하기 위한 방법의 하나\n",
    "* 독립 변수 벡터 $x$ 와 가중치 벡터 $w$와의 가중합으로 ${y}$와 가장 비슷한 값 $\\hat{y}$를 계산하는 수식을 말함\n",
    "\n",
    "$$ \\hat{y} = w_1 x_1 + \\cdots + w_N x_N$$\n",
    "\n",
    "* 이 수식은 벡터의 곱으로 표현 할 수 있다.\n",
    "\n",
    "$$ \\hat{y} = w^Tx$$\n",
    "\n",
    "* 여기에서 가장 비슷한 값이라고 한 이유는 우리가 원하는 $y$와 정확히 똑같은 값을 만들어주는 가중치 벡터 $w$를 찾을 수 없는 경우가 많기 때문이다. 이 경우에는 원래의 $y$와 가장 비슷한 $\\hat{y}$ 값이라도 계산해 주는 가중치 벡터 $w$로 만족해야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 행렬의 곱셈(내적)\n",
    "$$ C = AB \\; \\rightarrow \\; c_{ij} = a_i^T b_j $$\n",
    "$$ A \\in \\mathbf{R}^{N \\times L} , \\; B \\in \\mathbf{R}^{L \\times M} \\;  \\rightarrow \\; AB \\in \\mathbf{R}^{N \\times M} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 행렬의 곱셉 - numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "B = np.array([[1, 2], [3, 4], [5, 6]])\n",
    "C = np.dot(A, B)\n",
    "C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 교환 법칙과 분배 법칙\n",
    "$$ AB \\neq BA $$\n",
    "\n",
    "$$ A(B + C) = AB + AC $$\n",
    "\n",
    "$$ (A + B)C = AC + BC $$\n",
    "\n",
    "$$ (A + B)^T = A^T + B^T $$\n",
    "\n",
    "$$ (AB)^T = B^T A^T $$\n",
    "\n",
    "$$ (ABC)^T = C^T B^T A^T $$\n",
    "\n",
    "$$ ABC = (AB)C = A(BC) $$\n",
    "\n",
    "$$ ABCD = ((AB)C)D = (AB)(CD) = A(BCD) = A(BC)D $$\n",
    "\n",
    "$$ AI = IA = A $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 여러 개의 벡터에 대한 가중합\n",
    "$$ \\hat{y} = Xw $$\n",
    "\n",
    "$$ \\begin{eqnarray} \\hat{y} = \\begin{bmatrix} \\hat{y}_1 \\\\ \\hat{y}_2 \\\\ \\vdots \\\\ \\hat{y}_M \\\\ \\end{bmatrix}=\\begin{bmatrix} w_1 x_{1,1} + w_2 x_{1,2} + \\cdots + w_N x_{1,N} \\\\ w_1 x_{2,1} + w_2 x_{2,2} + \\cdots + w_N x_{2,N} \\\\ \\vdots  \\\\ w_1 x_{M,1} + w_2 x_{M,2} + \\cdots + w_N x_{M,N} \\\\ \\end{bmatrix} =\\begin{bmatrix} x_{1,1} & x_{1,2} & \\cdots & x_{1,N} \\\\ x_{2,1} & x_{2,2} & \\cdots & x_{2,N} \\\\ \\vdots & \\vdots & \\vdots & \\vdots \\\\ x_{M,1} & x_{M,2} & \\cdots & x_{M,N} \\\\ \\end{bmatrix} \\begin{bmatrix} w_1 \\\\ w_2 \\\\ \\vdots \\\\ w_N \\end{bmatrix}  = \\begin{bmatrix} x_1^T \\\\ x_2^T \\\\ \\vdots \\\\ x_M^T \\\\ \\end{bmatrix} \\begin{bmatrix} w_1 \\\\ w_2 \\\\ \\vdots \\\\ w_N \\end{bmatrix} = X w  \\end{eqnarray} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 잔차(Residual)와 제곱합(RSS, Residual Sum of Squares)\n",
    "\n",
    "$$ e = y - Xw $$ \n",
    "\n",
    "$$ \\begin{eqnarray}e &=&\\begin{bmatrix}e_{1} \\\\e_{2} \\\\\\vdots \\\\e_{M} \\\\\\end{bmatrix}=\\begin{bmatrix}y_{1} \\\\y_{2} \\\\\\vdots \\\\y_{M} \\\\\\end{bmatrix}-\\begin{bmatrix}x^T_{1}w \\\\x^T_{2}w \\\\\\vdots \\\\x^T_{M}w \\\\\\end{bmatrix}=y - Xw\\end{eqnarray}$$\n",
    "\n",
    "$$ \\sum_{i=1}^{N} e_i^2 = \\sum_{i=1}^{N} (y_i - w^Tx_i)^2 = e^Te =  (y - Xw)^T (y - Xw) = y^Ty - w^TX^Ty - y^TXw + w^TX^TXw $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이차 형식 (Quadratic Form) - 행벡터 X 정방 행렬 X 열벡터\n",
    "* 행렬의 부호: 영 벡터가 아닌 모든 벡터 x에 대해\n",
    "  * **양-한정**(positive definite): $ x^T A x > 0$\n",
    "  * **양-반한정**(positive semi-definite): $ x^T A x \\geq 0$ \n",
    "\n",
    "$$ \\begin{eqnarray} x^T A x &=& \\begin{bmatrix}x_{1} & x_{2} & \\cdots & x_{N} \\end{bmatrix}\\begin{bmatrix}a_{1,1} & a_{1,2} & \\cdots &a_{1,N} \\\\a_{2,1} & a_{2,2} & \\cdots & a_{2,N} \\\\\\vdots & \\vdots & \\ddots & \\vdots \\\\a_{N,1} & a_{N,2} & \\cdots & a_{N,N} \\\\\\end{bmatrix}\\begin{bmatrix}x_{1} \\\\x_{2} \\\\\\vdots \\\\x_{N} \\\\\\end{bmatrix} \\end{eqnarray}$$ \n",
    "$$\\begin{eqnarray} &=& \\sum_{i=1}^{N}\\sum_{j=1}^{N} a_{i,j} x_i x_j \\end{eqnarray}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 행렬의 크기 - Norm, Trace, Determinant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Norm\n",
    "* **프로베니우스 놈**(Frobenius norm): L = 2\n",
    "* 벡터의 놈의 제곱은 그 벡터의 제곱합과 같다\n",
    "$$ \\Vert A \\Vert_L = \\left( \\sum_{i=1}^M \\sum_{j=1}^N |a_{ij}|^L \\right)^{1/L} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Norm - numpy (Frobenius norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A = np.arange(9).reshape(3, 3)\n",
    "np.linalg.norm(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trace\n",
    "* 정방 행렬에 대해서만 정의된다\n",
    "\n",
    "$$ \\operatorname{tr}(A) = a_{11} + a_{22} + \\dots + a_{NN}=\\sum_{i=1}^{N} a_{ii} $$\n",
    "\n",
    "$$ \\text{tr} (cA) = c\\;\\text{tr} (A) $$\n",
    "\n",
    "$$ \\text{tr} (A^T) = \\text{tr} (A) $$\n",
    "\n",
    "$$ \\text{tr} (A + B) = \\text{tr} (A) + \\text{tr} (B)$$\n",
    "\n",
    "$$ \\text{tr} (AB) = \\text{tr} (BA) $$\n",
    "\n",
    "$$ \\text{tr} (ABC) = \\text{tr} (BCA) = \\text{tr} (CAB) $$\n",
    "\n",
    "* **Trace trick** - Quadratic form의 미분을 구하는 데 사용\n",
    "$$ x^TAx = \\text{tr}(x^TAx) = \\text{tr}(Axx^T)  = \\text{tr}(xx^TA) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trace - numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.trace(np.eye(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determinant\n",
    "* **Cofactor expansion**이라고 불리는 재귀적인 방법으로 정의\n",
    "* 임의의 행이나 열을 선택한 후 다음의 식을 적용\n",
    "$$ \\det(A) = \\sum_{i=1}^N \\left\\{ (-1)^{i+j_0}M_{i,j_0} \\right\\} a_{i,j_0} = \\sum_{j=1}^N \\left\\{ (-1)^{i_0+j} M_{i_0,j} \\right\\} a_{i_0,j} =  \\sum_{j=1}^N C_{i_0,j} a_{i_0,j} $$\n",
    "\n",
    "$$ \\det(A^{T}) = \\det(A) $$\n",
    "\n",
    "$$ \\det(I) = 1 $$\n",
    "\n",
    "$$ \\det(AB) = \\det(A)\\det(B) $$\n",
    "\n",
    "$$ \\det(A^{-1}) = \\dfrac{1}{\\det(A)} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determinant - numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A = np.array([[1, 2], [3, 4]])\n",
    "np.linalg.det(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 역행렬\n",
    "$$ A^{-1} A = A A^{-1} = I $$\n",
    "\n",
    "$$ (A^{T})^{-1} = (A^{-1})^{T} $$\n",
    "\n",
    "$$ (AB)^{-1} = B^{-1} A^{-1} $$\n",
    "\n",
    "$$ (ABC)^{-1} = C^{-1} B^{-1} A^{-1} $$\n",
    "\n",
    "* 역행렬은 코팩터 행렬(cofactor matrix)과 다음의 관계를 가진다\n",
    "* 코팩터 행렬의 전치 행렬을 adjugate matrix 또는 adjoint matrix라고 하며 $ \\text{adj}(A) $로 표기한다\n",
    "* 행렬식의 값이 0이 아니면 역행렬이 존재한다. 반대로 역행렬이 존재하면 행렬식의 값은 0이 아니다.\n",
    "\n",
    "$$ A^{-1} = \\dfrac{1}{\\det A} C^T = \\dfrac{1}{\\det A} \n",
    "\\begin{bmatrix}\n",
    "C_{1,1} &\\cdots& C_{N, 1}\\\\\n",
    "\\vdots &\\ddots &\\vdots\\\\\n",
    "C_{1,N} &\\cdots &C_{N,N}\\\\\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 연립방정식과 역행렬\n",
    "$$\n",
    "\\begin{matrix}\n",
    "a_{11} x_1 & + \\;& a_{12} x_2   &\\; + \\cdots + \\;& a_{1M} x_M &\\; = \\;& b_1 \\\\\n",
    "a_{21} x_1 & + \\;& a_{22} x_2   &\\; + \\cdots + \\;& a_{2M} x_M &\\; = \\;& b_2 \\\\\n",
    "\\vdots\\;\\;\\; &   & \\vdots\\;\\;\\; &                & \\vdots\\;\\;\\; &     & \\;\\vdots \\\\\n",
    "a_{N1} x_1 & + \\;& a_{N2} x_2   &\\; + \\cdots + \\;& a_{NM} x_M &\\; = \\;& b_N \\\\\n",
    "\\end{matrix}\n",
    "$$\n",
    "\n",
    "$$ Ax = b $$\n",
    "$$ x = A^{-1}b$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 역행렬 - numpy (inv, lstsq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A = np.array([[1, 3, -2], [3, 5, 6], [2, 4, 3]])\n",
    "b = np.array([[5], [7], [8]])\n",
    "Ainv = np.linalg.inv(A)\n",
    "x = np.dot(Ainv, b)\n",
    "#또는\n",
    "x, resid, rank, s = np.linalg.lstsq(A, b)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 최소 자승 문제 - 방정식의 수가 미지수의 수보다 많은 경우\n",
    "$$ Ax \\approx b $$\n",
    "\n",
    "$$ e = Ax-b $$\n",
    "\n",
    "$$ e^Te = \\Vert e \\Vert^2 = (Ax-b)^T(Ax-b) $$\n",
    "\n",
    "$$ x = \\text{arg} \\min_x e^Te = \\text{arg} \\min_x  \\; (Ax-b)^T(Ax-b) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 의사 역행렬(pseudo inverse)\n",
    "$$ A^TAx = A^Tb $$\n",
    "\n",
    "\n",
    "$$ (A^TA)x = A^Tb $$\n",
    "\n",
    "$$ x = (A^TA)^{-1}A^T b = A^+ b $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # 2. 선형대수와 해석기하"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 벡터의 기하학적 의미\n",
    "* 벡터의 의미: **그 값으로 표시되는 점** 또는 **원점과 그 점을 연결한 화살표**\n",
    "* 벡터의 길이: Frobenius norm으로 계산 가능 (각 성분을 제곱하여 더한 후 그 합의 제곱근)\n",
    "* 벡터와 실수의 곱: 방향은 변하지 않고 길이만 실수배만큼 커진다 (음수를 곱하는 경우 방향이 반대가 된다)\n",
    "* 단위 벡터: 길이가 1인 벡터\n",
    "* 벡터의 합과 차: 각 성분을 서로 더하거나 빼서 구한다 or 평행사변형법 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 벡터의 내적\n",
    "$$ a^Tb = \\|a\\|\\|b\\| \\cos\\theta $$\n",
    "\n",
    "따라서,\n",
    "\n",
    "$$ a^T b = b^T a = 0   \\;\\;\\;\\; \\leftrightarrow \\;\\;\\;\\; a \\perp b $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 벡터의 분해(decomposition)와 성분\n",
    "* 벡터 a와 b가 있을 때, a를 b에 직교하는 성분($ a_1 $)과 평행하는 성분($ a_2 $)으로 분해할 수 있다\n",
    "* 이 때 $ a_2 $를 $a$의 $b$에 대한 투영(projection)이라고 하며 다음과 같이 구할 수 있다\n",
    "\n",
    "$$ \\| a_2 \\| = \\|a\\|\\cos\\theta = \\dfrac{\\|a\\|\\|b\\|\\cos\\theta}{\\|b\\|}  = \\dfrac{a^Tb}{\\|b\\|} = \\dfrac{b^Ta}{\\|b\\|} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 직선의 방정식\n",
    "* 원점으로부터 직선까지 이어지는 수직선을 $w$라고 할 때, 임의의 점 $x$와 직선의 거리는 다음과 같다\n",
    "$$$$\n",
    "$$ \\left| \\dfrac{w^Tx}{\\|w\\|} - \\|w\\| \\right| = \\dfrac{\\left|w^Tx - \\|w\\|^2 \\right|}{\\|w\\|}= \\dfrac{\\left|w^Tx - w_0 \\right|}{\\|w\\|} $$\n",
    "$$$$\n",
    "* 따라서 직선 상의 점의 방정식은 다음과 같다\n",
    "$$$$\n",
    "$$\n",
    "w^Tx - w_0 = 0\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 벡터의 선형 종속과 선형 독립\n",
    "* 선형 종속(linearly dependent): 벡터들의 선형 조합이 0이 되는 모두 0이 아닌 스칼라값들이 존재\n",
    "* 선형 독립(linearly independent): 존재 X\n",
    "* 열 랭크(column rank) or 랭크(rank): 행렬의 열 벡터 중 서로 독립인 열 벡터의 최대 갯수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 열 랭크 - numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.linalg.matrix_rank(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 벡터 공간과 기저 벡터\n",
    "* **벡터 공간**(vector space): K차원의 벡터 K개가 서로 선형 독립인 경우, 이 벡터들을 선형 조합해 만들어지는 모든 벡터의 집합\n",
    "* **기저 벡터**(basis vector): 그러한 K개의 벡터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 좌표와 좌표변환\n",
    "* **좌표**(coordinate): 표준 기저 벡터를 선형조합하여 해당 벡터를 나타내었을 때의 선형 조합 가중치\n",
    "$$$$\n",
    "$$ a = a_1 \\cdot e_1 + a_2 \\cdot e_2 $$\n",
    "$$$$\n",
    "* **변환행렬**(transformation matrix): 새로운 기저 벡터들의 좌표를 행렬 형태로 나타낸 것\n",
    "* **좌표변환**(coordinate transformation): 새로운 기저 벡터에 대해 좌표값을 계산하는 것\n",
    "* 특정 벡터의 구좌표가 $a$, 신좌표가 $a'$ 일 때,\n",
    "$$$$\n",
    "$$ a  = a_1 \\cdot e_1 + a_2 \\cdot e_2 = {a'}_1 \\cdot g_1 + {a'}_2 \\cdot g_2 =\n",
    "\\begin{bmatrix} g_1 & g_2 \\end{bmatrix} \n",
    "\\begin{bmatrix} {a'}_1 \\\\ {a'}_2 \\end{bmatrix}\n",
    "= \\begin{bmatrix} g_1 & g_2 \\end{bmatrix} a' $$ \n",
    "$$ a' = A^{-1}a $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # 3. 특이값 분해"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 고유분해(eigen-decomposition)\n",
    "* 고유분해(eigen-decomposition): 정방행렬 $A$의 고유값(eigenvalue)과 고유벡터(eigenvector)를 찾는 작업\n",
    "* 고유값과 고유벡터: 정방행렬 $A$에 대해 다음 식을 만족하는 실수 $\\lambda$와 벡터 $v$\n",
    "\n",
    "$$ Av = \\lambda v $$\n",
    "\n",
    "* $ A \\in \\mathbf{R}^{M \\times M} $ 에 대해 최대 $M$개의 고유값-고유벡터 쌍이 존재할 수 있다. \n",
    "* 고유벡터와 방향이 같은 벡터는 모두 고유벡터가 되므로 크기가 1이 되도록 정규화(normalization)한다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 고유벡터 행렬과 고유값 행렬\n",
    "$$ \n",
    "A \\left[ v_1 \\cdots v_M \\right] =\n",
    "\\left[ \\lambda_1 v_1 \\cdots \\lambda_M v_M \\right] =\n",
    "\\left[ v_1 \\cdots v_M \\right] \n",
    "\\begin{bmatrix}\n",
    "\\lambda_{1} & 0 & \\cdots & 0 \\\\\n",
    "0 & \\lambda_{2} & \\cdots & 0 \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "0 & 0 & \\cdots & \\lambda_{M} \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$ AV = V\\Lambda $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 고유값과 고유벡터 - numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w, V = np.linalg.eig(np.array([[1, -2], [2, -3]]))\n",
    "w #벡터 형태의 고유값\n",
    "V #행렬 형태의 고유벡터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 대칭행렬의 고유분해\n",
    "* 대칭행렬의 고유벡터는 서로 수직(orthogonal)이므로 다음이 성립한다 (고유벡터가 정규화된 상태일 경우)\n",
    "\n",
    "$$ V^T V = V V^T = I$$\n",
    "\n",
    "* 따라서 다음이 성립한다\n",
    "\n",
    "\n",
    "$$ A = V\\Lambda V^T = \\sum_{i=1}^{M} {\\lambda_i} v_i v_i^T$$\n",
    "\n",
    "$$ A^{-1} = V \\Lambda^{-1} V^T = \\sum_{i=1}^{M} \\dfrac{1}{\\lambda_i} v_i v_i^T$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 확률 변수의 좌표 변환\n",
    "확률 변수의 공분산 행렬 $\\Sigma$ 은 대칭 행렬이므로 위의 관계식이 성립한다. \n",
    "\n",
    "따라서 다변수 가우시안 정규 분포의 확률 밀도 함수는 다음과 같이 표시할 수 있다.\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "\\mathcal{N}(x \\mid \\mu, \\Sigma) \n",
    "&=& \\dfrac{1}{(2\\pi)^{D/2} |\\Sigma|^{1/2}} \\exp \\left( -\\dfrac{1}{2} (x-\\mu)^T \\Sigma^{-1} (x-\\mu) \\right) \\\\\n",
    "&=& \\dfrac{1}{(2\\pi)^{D/2} |\\Sigma|^{1/2}} \\exp \\left( -\\dfrac{1}{2} (x-\\mu)^T V \\Lambda^{-1} V^T (x-\\mu) \\right) \\\\\n",
    "&=& \\dfrac{1}{(2\\pi)^{D/2} |\\Sigma|^{1/2}} \\exp \\left( -\\dfrac{1}{2} (V^T(x-\\mu))^T  \\Lambda^{-1} (V^T (x-\\mu)) \\right) \\\\\n",
    "\\end{eqnarray}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 정방행렬이 아닌 행렬에 대한 특이값 분해\n",
    "\n",
    "정방 행렬이 아닌 행렬 $M$에 대해서도 고유 분해와 유사한 분해가 가능하다. 이를 특이값 분해(singular value decomposition)이라고 한다.\n",
    "\n",
    "\n",
    "* $M \\in \\mathbf{R}^{m \\times n}$ \n",
    "\n",
    "$$M = U \\Sigma V^T$$ \n",
    "\n",
    "여기에서 \n",
    "* $U \\in \\mathbf{R}^{m \\times m}$ \n",
    "* $\\Sigma  \\in \\mathbf{R}^{m \\times n}$  \n",
    "* $V \\in \\mathbf{R}^{n \\times n}$ \n",
    "\n",
    "이고 행렬 $U$와 $V$는 다음 관계를 만족한다.\n",
    "\n",
    "$$ U^T U = UU^T = I $$\n",
    "$$ V^T V = VV^T = I $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # 4. 함수\n",
    "* **함수**: 수식 등을 사용하여 입력받은 변수를 출력 변수로 바꾸어 출력하는 관계 혹은 구조 $ y = f(x) $\n",
    "* **역함수**: 어느 함수의 입력과 출력 관계와 정반대의 입출력 관계를 가지는 함수 $ x = f^{-1}(y) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### matplotlib으로 그래프 그리기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ f(x) = x^3 - 3x^2 + x $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return x**3 - 3*x**2 + x\n",
    "\n",
    "x = np.linspace(-1, 3, 400)\n",
    "y = f(x)\n",
    "\n",
    "plt.plot(x, y)\n",
    "\n",
    "plt.xlim(-2, 4)\n",
    "plt.xticks(np.arange(-1, 4))\n",
    "plt.yticks(np.arange(-5, 4))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 분석에서 많이 사용되는 함수들\n",
    "* **다항식 함수**(polynomial function)\n",
    ">* $ f(x) = c_0 + c_1 x + c_2 x^2 + \\cdots + c_n x^n $\n",
    "\n",
    "* **지수 함수**(exponential function)\n",
    ">* $ y = e^x $\n",
    ">* 파이썬에서 자연 상수값은 np.e로 구할 수 있다\n",
    ">* 밑이 $e$가 아닌 경우, $ y = a^x = (e^{\\log a})^x = e^{x \\log a} $\n",
    ">* $ e^{x_1} e^{x_2} = e^{x_1 + x_2}$\n",
    "\n",
    "* **로그 함수**(logarithmic function)\n",
    ">* $ y = \\log x $\n",
    ">* $x$값, 즉 입력변수값이 양수이어야 한다. 0이거나 음수이면 정의되지 않는다.\n",
    ">* $x > 1$ 이면 양수 / $x=1$일 때 $y=0$ / $x < 1$ 이면 음수\n",
    ">* 로그 함수의 성질1: 로그 함수는 곱셈을 덧셈으로 변환한다\n",
    ">  * $ \\log{\\left(\\prod_i x_i\\right)} = \\sum_i \\left(\\log{x_i}\\right) $\n",
    ">  * $ \\log x^n = n \\log x $\n",
    ">* 로그 함수의 성질2: 로그 함수를 적용해도 함수의 최고점, 최저점의 위치는 변하지 않는다 (최적화에 사용)\n",
    ">  * $ \\arg\\max_x f(x) = \\arg\\max_x \\log f(x) $\n",
    ">* 로그 함수의 성질3: 로그 함수는 0부터 1까지의 작은 값을 확대해서 보여준다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # 4.1. 함수의 미분"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 함수의 미분\n",
    "\n",
    "$$ f'(x) = \\lim_{dx \\to 0} \\frac{f(x+dx)-f(x)}{dx} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기본적인 미분 공식\n",
    "$$ \\dfrac{d}{dx}(c) = 0 $$\n",
    "\n",
    "$$ \\dfrac{d}{dx}(x^n) = n x^{n-1} $$\n",
    "\n",
    "$$ \\dfrac{d}{dx}(\\log x) = \\dfrac{1}{x} $$\n",
    "\n",
    "$$ \\dfrac{d}{dx}(e^x) = e^x $$\n",
    "\n",
    "$$ \\dfrac{d}{dx}\\left(c_1 f_1 + c_2 f_2 \\right) = c_1 \\dfrac{df_1}{dx} + c_2 \\dfrac{df_2}{dx}$$\n",
    "\n",
    "$$  \\dfrac{d}{dx}\\left( f  \\cdot g \\right) =  \\dfrac{df}{dx} \\cdot g + f \\cdot  \\dfrac{dg}{dx} $$\n",
    "\n",
    "$$ \\dfrac{d}{dx}h(g(x)) = \\dfrac{dh}{dg} \\cdot \\dfrac{dg}{dx} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2차 도함수 (2nd derivative)\n",
    "$$ f'' = \\dfrac{d^2y}{dx^2} $$\n",
    "* 2차 도함수가 양수이면 아래로 볼록(convex)\n",
    "* 2차 도함수가 음수이면 아래로 오목(concave)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 편미분 (partial derivative)\n",
    "$$ f_x(x,y) = \\dfrac{\\partial f}{\\partial x}$$\n",
    "$$ f_y(x,y) = \\dfrac{\\partial f}{\\partial y} $$\n",
    "* 특정 독립 변수로 편미분하는 경우, 다른 독립 변수는 상수로 취급한다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 편미분의 2차 도함수\n",
    "\n",
    "$$ f_{xx}(x,y) = \\dfrac{\\partial^2 f}{\\partial x^2} $$\n",
    "\n",
    "$$ f_{yy}(x,y) = \\dfrac{\\partial^2 f}{\\partial y^2} $$\n",
    "\n",
    "$$ f_{xy}(x,y) = \\dfrac{\\partial^2 f}{\\partial y \\partial x} $$\n",
    "\n",
    "$$ f_{yx}(x,y) = \\dfrac{\\partial^2 f}{\\partial x \\partial y} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 미분 - sympy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sympy\n",
    "\n",
    "# Juypter 노트북에서 수학식의 LaTeX 표현을 위해 필요함\n",
    "sympy.init_printing(use_latex='mathjax') \n",
    "\n",
    "# symbols 명령을 통해 x가 심볼임을 알려준다\n",
    "x = sympy.symbols('x')\n",
    "\n",
    "f = x * sympy.exp(x)\n",
    "\n",
    "# 함수의 미분\n",
    "sympy.diff(f)\n",
    "\n",
    "# 미분한 결과를 단순화\n",
    "sympy.simplify(sympy.diff(f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 편미분 - sympy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x, y = sympy.symbols('x y')\n",
    "f = x ** 2 + x * y + y ** 2\n",
    "\n",
    "# x와 y에 각각에 대해 편미분\n",
    "sympy.diff(f, x)\n",
    "sympy.diff(f, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x, mu, sigma = sympy.symbols('x mu sigma')\n",
    "f = sympy.exp((x - mu) ** 2 / sigma ** 2)\n",
    "sympy.simplify(sympy.diff(f,x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # 4.2. 함수의 적분"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 부정적분(indefinite integration)\n",
    "* $C$는 적분 상수를 의미\n",
    "$$ \\dfrac{dF(x)}{dx} = f(x) \\;\\;\\leftrightarrow\\;\\; F(x) = \\int_{}^{} f(x) dx + C $$\n",
    "$$$$\n",
    "$$ \n",
    "\\begin{matrix}\n",
    "\\dfrac{\\partial F_1(x)}{\\partial x} = f(x) & \\leftrightarrow & F_1(x, y) = \\int_{}^{} f(x, y) dx + C(y)\\\\\n",
    "\\dfrac{\\partial F_2(x)}{\\partial y} = f(x) & \\leftrightarrow & F_2(x, y) = \\int_{}^{} f(x, y) dy + C(x) \\\\ \n",
    "\\dfrac{\\partial^2 F_3(x)}{\\partial x \\partial y} = f(x) & \\leftrightarrow & F_3(x, y) = \\iint_{}^{} f(x, y) dxdy  + C\n",
    "\\end{matrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 부정적분 - sympy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sympy\n",
    "\n",
    "sympy.init_printing(use_latex='mathjax')  \n",
    "\n",
    "x = sympy.symbols('x')\n",
    "f = x * sympy.exp(x) + sympy.exp(x)\n",
    "\n",
    "sympy.integrate(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 정적분(definite integration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 독립변수 $x$가 $[a, b]$인 구간에서 함수 $f(x)$의 값과 $x$축이 이루는 면적\n",
    "\n",
    "$$\\int_{b}^{a} f(x) dx $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 미적분학의 기본 정리(Fundamental Theorem of Calculus)\n",
    "* 대부분의 경우 어느 함수의 정적분은 부정적분으로 구한 함수 $F(x)$를 이용하여 구할 수 있다\n",
    "\n",
    "$$ \\int_{b}^{a} f(x) dx = F(a) - F(b)  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 정적분 - sympy\n",
    "* 정적분 방법1: sympy로 부정적분을 한 후 미적분학의 기본 정리 사용\n",
    "* 장적분 방법2: 기존 함수의 면적을 잘게 쪼개어 면적을 근사적으로 구함 (numerical integration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 부정적분을 통해 계산하기\n",
    "x, y = sympy.symbols('x y')\n",
    "f = x ** 3 - 3 * x ** 2 + x + 6\n",
    "F = sympy.integrate(f)\n",
    "(F.subs(x, 2) - F.subs(x,0)).evalf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 바로 정적분 계산하기\n",
    "def f(x):\n",
    "    return x ** 3 - 3 * x ** 2 + x + 6\n",
    "\n",
    "sp.integrate.quad(f, 0, 2)\n",
    "# 두 번쨰 값은 오차의 상한값을 의미"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 다변수 정적분 (변수가 2개인 경우)\n",
    "* 방법1: 하나의 변수로 적분하고 나머지 변수를 정해지지 않은 상수로 취급\n",
    "* 방법2: 두 변수에 대해 모두 적분 (부피를 구하는 문제)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # 5. 행렬의 미분\n",
    "* 행렬 미분: 행렬을 입력이나 출력으로 가지는 함수를 미분하는 것\n",
    "* 엄밀하게는 편미분(partial derivative)에 해당\n",
    "* 분자 중심 표현법(Numerator-layout notation)과 분모 중심 표현법(Denominator-layout notation)이 있음\n",
    "* 데이터 분석에는 주로 분모 중심 표현법을 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) 스칼라를 벡터로 미분 - 그레디언트 벡터(gradient vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\nabla y = \n",
    "\\frac{\\partial y}{\\partial \\mathbf{x}} =\n",
    "\\begin{bmatrix}\n",
    "\\dfrac{\\partial y}{\\partial x_1}\\\\\n",
    "\\dfrac{\\partial y}{\\partial x_2}\\\\\n",
    "\\vdots\\\\\n",
    "\\dfrac{\\partial y}{\\partial x_N}\\\\\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 미분 규칙1: 선형 모형\n",
    "* 선형 모형을 미분하면 가중치 벡터가 된다\n",
    "* 증명은 부록-1. 참조\n",
    "$$\\frac{\\partial \\mathbf{w}^{T}\\mathbf{x}}{\\partial \\mathbf{x}} = \\frac{\\partial \\mathbf{x}^{T}\\mathbf{w}}{\\partial \\mathbf{x}} = \\mathbf{w}$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 미분 규칙2: 이차 형식\n",
    "* 이차 형식을 미분하면 행렬과 벡터의 곱으로 나타난다\n",
    "* 증명은 부록-2. 참조\n",
    "$$\\frac{\\partial \\mathbf{x}^{T}\\mathbf{A}\\mathbf{x}}{\\partial \\mathbf{x}} = (\\mathbf{A} + \\mathbf{A}^{T})\\mathbf{x}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 그레디언트 벡터의 표현1: surface plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f(x, y):\n",
    "    return 2 * x**2 + 6 * x * y + 7 * y**2 - 26 * x - 54 * y + 107\n",
    "\n",
    "xx = np.linspace(-5, 9, 100)\n",
    "yy = np.linspace(-4, 9, 100)\n",
    "X, Y = np.meshgrid(xx, yy)\n",
    "\n",
    "Z = f(X, Y)\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.gca(projection='3d').plot_surface(X, Y, Z)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 그레디언트 벡터의 표현2: quiver plot\n",
    "> * 그레디언트 벡터의 방향: 함수 곡면의 기울기가 가장 큰 방향\n",
    "> * 그레디언트 벡터의 크기: 기울기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gx(x, y):\n",
    "    return 4 * x + 6 * y - 26\n",
    "\n",
    "def gy(x, y):\n",
    "    return 6 * x + 14 * y - 54\n",
    "\n",
    "xx2 = np.linspace(-4, 8, 10)\n",
    "yy2 = np.linspace(-3, 9, 10)\n",
    "X2, Y2 = np.meshgrid(xx2, yy2)\n",
    "\n",
    "GX = gx(X2, Y2)\n",
    "GY = gy(X2, Y2)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.contour(X, Y, Z, levels=[0.05, 5, 50, 100, 150, 200, 250, 300], colors='k')\n",
    "plt.quiver(X2, Y2, GX, GY, color='blue', scale=400)\n",
    "plt.axis(\"equal\")\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) 벡터를 스칼라로 미분\n",
    "\n",
    "$$\n",
    "\\mathbf{y} =\n",
    "\\begin{bmatrix}\n",
    "y_1 \\\\\n",
    "y_2 \\\\\n",
    "\\vdots\\\\\n",
    "y_M \\\\\n",
    "\\end{bmatrix}\n",
    "= \\mathbf{f}(x)\n",
    "$$\n",
    "\n",
    "$$\\downarrow$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\mathbf{y}}{\\partial x} = \\left[\n",
    "\\frac{\\partial y_1}{\\partial x}\n",
    "\\frac{\\partial y_2}{\\partial x}\n",
    "\\cdots\n",
    "\\frac{\\partial y_M}{\\partial x}\n",
    "\\right].\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) 벡터를 벡터로 미분\n",
    "* 독립 변수 각각과 종속 변수 각각의 조합에 대해 모두 미분이 존재\n",
    "* **자코비안 행렬(Jacobian matrix)**: 이렇게 만들어진 도함수의 행렬\n",
    "* *행/열의 방향에 유의*\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "$$\n",
    "\\mathbf J = \\frac{d\\mathbf y}{d\\mathbf x} = \\begin{bmatrix}\n",
    "    \\dfrac{\\partial y_1}{\\partial \\mathbf x}^T \\\\ \\cdots \\\\ \\dfrac{\\partial y_M}{\\partial \\mathbf x}^T \\end{bmatrix}\n",
    "= \\begin{bmatrix}\n",
    "    \\dfrac{\\partial y_1}{\\partial x_1} & \\cdots & \\dfrac{\\partial y_1}{\\partial x_N}\\\\\n",
    "    \\vdots & \\ddots & \\vdots\\\\\n",
    "    \\dfrac{\\partial y_M}{\\partial x_1} & \\cdots & \\dfrac{\\partial y_M}{\\partial x_N} \\end{bmatrix}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) 스칼라를 행렬로 미분\n",
    "\n",
    "$$\n",
    "\\frac{\\partial y}{\\partial \\mathbf{X}} =\n",
    "\\begin{bmatrix}\n",
    "\\frac{\\partial y}{\\partial x_{1,1}} & \\frac{\\partial y}{\\partial x_{1,2}} & \\cdots & \\frac{\\partial y}{\\partial x_{1,N}}\\\\\n",
    "\\frac{\\partial y}{\\partial x_{2,1}} & \\frac{\\partial y}{\\partial x_{2,2}} & \\cdots & \\frac{\\partial y}{\\partial x_{2,N}}\\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
    "\\frac{\\partial y}{\\partial x_{M,1}} & \\frac{\\partial y}{\\partial x_{M,2}} & \\cdots & \\frac{\\partial y}{\\partial x_{M,N}}\\\\\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 스칼라를 행렬로 미분 - 2차 도함수\n",
    "* 이렇게 구해진 행렬을 **헤시안 행렬**(Hessian matrix)이라고 한다\n",
    "$$$$\n",
    "$$\n",
    "H =\n",
    "\\begin{bmatrix}\n",
    "  \\dfrac{\\partial^2 f}{\\partial x_1^2} & \\dfrac{\\partial^2 f}{\\partial x_1\\,\\partial x_2} & \\cdots & \\dfrac{\\partial^2 f}{\\partial x_1\\,\\partial x_N} \\\\\n",
    "  \\dfrac{\\partial^2 f}{\\partial x_2\\,\\partial x_1} & \\dfrac{\\partial^2 f}{\\partial x_2^2} & \\cdots & \\dfrac{\\partial^2 f}{\\partial x_2\\,\\partial x_N} \\\\\n",
    "  \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "  \\dfrac{\\partial^2 f}{\\partial x_N\\,\\partial x_1} & \\dfrac{\\partial^2 f}{\\partial x_N\\,\\partial x_2} & \\cdots & \\dfrac{\\partial^2 f}{\\partial x_N^2}\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 미분 규칙3: 행렬 곱의 대각성분\n",
    "$$ \\text{tr}(\\mathbf{B}\\mathbf{A}) = \\sum_{i=1}^N \\sum_{j=1}^N b_{ji} a_{ij} \\rightarrow \\dfrac{\\partial \\text{tr} (\\mathbf{B}\\mathbf{A})}{\\partial a_{ij}} = b_{ji} = \\mathbf{B}^T$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 미분 규칙4: 행렬식의 로그\n",
    "\n",
    "$$ \\dfrac{\\partial}{\\partial a_{i,j}} \\det \\mathbf{A} = C_{i,j} $$\n",
    "\n",
    "$$ \\dfrac{\\partial}{\\partial \\mathbf{A}} \\det \\mathbf{A} = C = (\\det \\mathbf{A}) (\\mathbf{A}^{-1})^T  $$\n",
    "\n",
    "$$ \\dfrac{d}{dx} \\log f(x) = \\dfrac{f'(x)}{f(x)} = \\dfrac{(\\det \\mathbf{A}) (\\mathbf{A}^{-1})^T}{\\det \\mathbf{A}} = (\\mathbf{A}^{-1})^T $$\n",
    "\n",
    "$$ \\dfrac{\\partial \\log \\det \\mathbf{A} }{\\partial \\mathbf{A}} = (\\mathbf{A}^{-1})^T $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # 6. 최적화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 최적화(optimization)란?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 특정한 제한 조건(constraint)을 만족시키면서 함수 $f$의 값을 최소화하는 변수 $x$의 값 $x^{\\ast}$를 찾는 것\n",
    "* 최대화 문제는 $f(x)$ 를 $-f(x)$ 로 바꾸면 풀 수 있으므로 보통 최소화의 경우만 고려\n",
    "\n",
    "$$ x^{\\ast} = \\underset{x}{\\operatorname{arg\\,min}} \\; f(x) $$\n",
    "\n",
    "* 이 때 최소화 혹은 최대화 하려는 함수를 **목적 함수(objective function)** 또는 **비용 함수(cost function)**, **손실 함수(loss function)**라고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 방법1: 그리드 서치(grid search)\n",
    "* $x$의 값을 여러 개 넣어보고 그 중 가장 작은 값은 선택\n",
    "* 간단하지만 많은 계산량 요구"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 방법2: 수치적 최적화(numerical optimization)\n",
    "* 다음과 같은 두 가지 알고리즘으로 구성됨\n",
    "* 1) 어떤 위치 $x_k$를 시도한 뒤, 다음 번에 시도할 위치 $x_{k+1}$을 찾는 알고리즘\n",
    "* 2) 현재 위치 $x_k$가 최적점인지 판단하는 알고리즘"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # 6.1. 수치적 최적화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기울기 필요 조건\n",
    "* 현재 위치가 최적점인지 판단하는 알고리즘\n",
    "* 아래의 조건은 **필요 조건**이다 (최적점을 보장하지는 않는다)\n",
    "* 단일 변수: $\\dfrac{df(x)}{dx} = 0 $\n",
    "* 다변수: $ \\nabla f = 0 $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 수치적 최적화 - SGD(Steepest Gradient Descent) 방법\n",
    "* 스텝 사이즈($\\mu$)를 잘 설정해야 함\n",
    "* 너무 작으면 maximum iteration 초과, 너무 크면 over-shooting\n",
    "$$$$\n",
    "$$ x_{k+1} = x_{k} - \\mu \\nabla f(x_k) = x_{k} - \\mu g(x_k)  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 수치적 최적화 - 그 외의 방법\n",
    "* CG(conjugated gradient) 방법\n",
    "* BFGS(Broyden–Fletcher–Goldfarb–Shanno) 방법\n",
    "* 매커니즘:\n",
    "> * 최적화하려는 영역을 2차 함수와 비슷한 모양으로 가정\n",
    "> * 1차 도함수인 그레디언트와 2차 도함수인 헤시안 행렬 정보를 모두 활용해서 최적점 탐색\n",
    "* 사용방법:\n",
    "> * sp.optimize.minimize 함수에서 `method='CG'` 또는 `method='BFGS'` 등을 통해 사용 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 수치적 최적화 - 전역 최적화 문제\n",
    "* 도달한 최적점이 국소 최적점(local minima)인지 전역 최적점(global minimum)인지 확신할 수 있는 방법이 없음\n",
    "* 초기 추정값 및 알고리즘, 파라미터를 잘 설정해야 함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 최적화 - scipy\n",
    "* 최적화 명령 'minimize'사용 / 세부적인 알고리즘은 'method'인수로 설정 / default 알고리즘은 BFGS 방법\n",
    "* 다변수 함수를 최적화하는 경우 목적 함수가 벡터 인수를 가짐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      fun: 1.2197702024999478e-11\n",
      " hess_inv: array([[ 0.50957143,  1.01994476],\n",
      "       [ 1.01994476,  2.04656074]])\n",
      "      jac: array([  9.66714798e-05,  -4.64005023e-05])\n",
      "  message: 'Desired error not necessarily achieved due to precision loss.'\n",
      "     nfev: 496\n",
      "      nit: 57\n",
      "     njev: 121\n",
      "   status: 2\n",
      "  success: False\n",
      "        x: array([ 0.99999746,  0.99999468])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.99999746,  0.99999468])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f2(x):\n",
    "    return (1 - x[0])**2 + 100.0 * (x[1] - x[0]**2)**2\n",
    "\n",
    "result = sp.optimize.minimize(f2, (-2, -2))\n",
    "print(result)\n",
    "x0 = result['x']\n",
    "x0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # 6.2. 제한 조건이 있는 최적화(contrained optimization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 등식 제한 조건 - 라그랑주 승수법(Lagrange multiplier)\n",
    "\n",
    "$$ x^{\\ast} = \\text{arg} \\min_x f(x) ,\\,\\,\\,\\ \\text{subject to } \\;\\; g(x)=0$$\n",
    "\n",
    "$$\\downarrow$$\n",
    "\n",
    "$$h(x, \\lambda) = f(x) + \\lambda g(x)$$\n",
    "\n",
    "$$\\downarrow$$\n",
    "\n",
    "$$ \\dfrac{\\partial (f + \\lambda g)}{\\partial x_1} = \\dfrac{\\partial f}{\\partial x_1} + \\lambda\\dfrac{\\partial g}{\\partial x_1} = 0 $$\n",
    "\n",
    "\n",
    "$$ \\dfrac{\\partial (f + \\lambda g)}{\\partial x_2} = \\dfrac{\\partial f}{\\partial x_2} + \\lambda\\dfrac{\\partial g}{\\partial x_2}= 0 $$\n",
    "$$ \\vdots $$\n",
    "$$ \\dfrac{\\partial (f + \\lambda g)}{\\partial x_N} = \\dfrac{\\partial f}{\\partial x_N} + \\lambda\\dfrac{\\partial g}{\\partial x_N}= 0 $$\n",
    "\n",
    "$$ \\dfrac{\\partial (f + \\lambda g)}{\\partial \\lambda} = g = 0 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 등식 제한 조건 - scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -1.3862943611198901\n",
      "            Iterations: 2\n",
      "            Function evaluations: 8\n",
      "            Gradient evaluations: 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.5,  0.5])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f2logs(x):\n",
    "    return np.log(x[0]) + np.log(x[1])\n",
    "\n",
    "def eq_constraint(x):\n",
    "    return x[0] + x[1] - 1\n",
    "\n",
    "sp.optimize.fmin_slsqp(f2logs, np.array([1, 1]), eqcons=[eq_constraint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 부등식 제한 조건 - KKT(Karush-Kuhn-Tucker) 조건\n",
    "* 부등식 제한 조건은 다음의 둘 중 하나에 해당된다\n",
    "  * 1) 최적화 결과에 전혀 영향을 주지 않는 조건\n",
    "  * 2) 최적화 결과에 영향을 주는 **등식** 조건\n",
    "* 따라서 등식 조건에 대한 라그랑주 승수법에 다음의 두 조건을 더하여 사용 가능\n",
    "  * 1) $  \\lambda g = 0 $ ($\\lambda$와 $g$중 적어도 하나는 0이어야 한다)\n",
    "  * 2) $  \\lambda \\geq 0 $ (실제로 부등식 제한 조건이 있는 문제와 같은 문제임을 보장 - strong duality)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 부등식 제한 조건 - scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return np.sqrt((x[0] - 3)**2 + (x[1] - 2)**2)\n",
    "\n",
    "def ieq_constraint(x):\n",
    "    return np.atleast_1d(1.5 - np.sum(np.abs(x)))\n",
    "\n",
    "sp.optimize.fmin_slsqp(f, np.array([0, 0]), ieqcons=[ieq_constraint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # 7. 확률"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 확률의 정의\n",
    "* **확률 표본**(sample, $\\omega$): 선택된 특정한 하나의 사실\n",
    "* **표본 공간**(sample space, $\\Omega$): 선택될 수 있는 모든 표본의 집합\n",
    "* **사건**(event, $A, B, C, ...$): 일부 표본의 집합\n",
    "* **확률**(probability, $P(A)$): 사건(부분 집합)을 입력하면 숫자(확률값)가 출력되는 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 콜모고로프의 공리(Kolmogorov's axioms)\n",
    "* 1) 모든 사건에 대해 확률은 실수이고 양수이다.\n",
    "$$P(A)\\in\\mathbb{R}, P(A)\\geq 0 $$\n",
    "\n",
    "* 2) 표본공간이라는 사건에 대한 확률은 1이다.\n",
    "\n",
    "$$P(\\Omega) = 1$$\n",
    "\n",
    "* 3) 공통 원소가 없는 두 사건의 합집합의 확률은 각각의 사건의 확률의 합이다.\n",
    "\n",
    "$$ A \\cap B = \\emptyset \\;\\;\\; \\rightarrow \\;\\;\\; P(A \\cup B) = P(A) + P(B) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 표본의 수가 무한한 경우\n",
    "\n",
    "\n",
    "* 표본의 수가 무한한 경우 특정한 하나의 표본(sample, 원소)이 나올 확률은 모든 표본에 대해서 0\n",
    "\n",
    "\n",
    "$$ P(\\{ \\theta = 0^{\\circ} \\}) = 0$$\n",
    "\n",
    "\n",
    "$$ P(\\{ \\theta = 30^{\\circ} \\}) = 0$$\n",
    "\n",
    "\n",
    "\n",
    "* 확률은 표본(sample, 원소)이 아닌 사건 (event, 집합)에 대해서만 정의\n",
    "\n",
    "\n",
    "$$ P(\\{  0^{\\circ} \\leq \\theta < 30^{\\circ} \\}) = \\frac{1}{12}$$\n",
    "\n",
    "\n",
    "$$ P(\\{  30^{\\circ} \\leq \\theta < 60^{\\circ} \\}) = \\frac{1}{12}$$\n",
    "\n",
    "\n",
    "$$ P(\\{  0^{\\circ} \\leq \\theta < 60^{\\circ} \\}) = \\frac{1}{6}$$\n",
    "\n",
    "\n",
    "$$ P(\\{  0^{\\circ} \\leq \\theta < 1^{\\circ} \\}) = \\frac{1}{360}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 확률의 성질\n",
    "* 1) 공집합의 확률: $ P(\\emptyset) = 0 $\n",
    "* 2) 여집합의 확률: $ P(A^C) = 1 - P(A) $\n",
    "* 3) 포함-배제 원리: $ P(A \\cup B) = P(A) + P(B) – P(A \\cap B) $\n",
    "* 4) 전체 확률의 법칙: \n",
    "$$ C_i \\cap C_j = \\emptyset \\text{  &  } C_1 \\cup C_2 \\cup \\cdots  = \\Omega $$\n",
    "$$$$\n",
    "$$ \\downarrow $$\n",
    "$$$$\n",
    "$$ P(A) = \\sum_i P(A \\cap C_i) $$\n",
    "* **모두 콜모고로프의 정리를 통해 증명 가능**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 확률의 의미\n",
    "* 1) **빈도주의적**(frequentist) 의미 - 반복된 샘플링을 통해 가능성을 정의\n",
    "* 2) **베이지안**(Bayesian) 의미 - 이미 발생한 일이 특정한 사건에 속할 가능성 / **주장의 신뢰도**\n",
    "  * 베이지안 관점에서의 사건: **\"진짜 표본이 포함되어 있을 가능성이 있는 후보의 집합\", \"진실에 대한 어떤 가설\"**\n",
    "  * 베이지안 관점에서의 확률: **\"진짜 표본이 그 후보 집합에 있을 가능성\", \"어떤 가설이 진실일 가능성\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # 7.1. 베이즈 정리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 결합 확률과 조건부 확률\n",
    "* 1) **결합 확률**(joint probability): 사건 A와 B가 동시에 발생할 확률, $ P(A \\cap B) = P(A, B) $\n",
    "* 2) **조건부 확률**(conditional probability): 사건 B가 사실일 경우 사건 A에 대한 확률, $ P(A | B) $\n",
    "\n",
    "$$ P(A|B) = \\dfrac{P(A,B)}{P(B)} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 독립적인 사건의 조건부 확률\n",
    "$$$$\n",
    "$$ P(A,B) = P(A)P(B) $$\n",
    "$$$$\n",
    "$$ P(A|B) = \\dfrac{P(A,B)}{P(B)} = \\dfrac{P(A)P(B)}{P(B)} = P(A) $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 베이즈 정리(Bayes' theorem)\n",
    "* 조건부 확률의 식이 $A$와 $B$에 대칭적임을 이용해 유도할 수 있다\n",
    "\n",
    "$$ P(A|B) = \\dfrac{P(B|A)P(A)}{P(B)} $$\n",
    "\n",
    "* $ P(A|B) $ : 사후 확률(posterior). 사건 B가 발생한 후 갱신된 사건 A의 확률\n",
    "* $ P(A) $ : 사전 확률(prior). 사건 B가 발생하기 전에 가지고 있던 사건 A의 확률\n",
    "* $ P(B|A) $ : likelihood. 사건 A가 발생한 경우 사건 B의 확률\n",
    "* $ P(B) $ : 정규화 상수(normalizing constant): 확률의 크기 조정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 베이즈 정리의 확장\n",
    "$$$$\n",
    "$$ P(A_1|B) = \\dfrac{P(B|A_1)P(A_1)}{P(B)} = \\dfrac{P(B|A_1)P(A_1)}{\\sum_i P(A_i, B)}= \\dfrac{P(B|A_1)P(A_1)}{\\sum_i P(B|A_i)P(A_i)}  $$\n",
    "$$$$\n",
    "* 조건1: $ A_i \\cap A_j = \\emptyset $\n",
    "* 조건2: $ A_1 \\cup A_2 \\cup \\cdots = \\Omega $\n",
    "\n",
    "#### 응용1: $A_1 = A$, $A_2 = A^C$ 인 경우:\n",
    "\n",
    "$$ \n",
    "\\begin{eqnarray}\n",
    "P(A|B) \n",
    "&=& \\dfrac{P(B|A)P(A)}{P(B)} \\\\\n",
    "&=& \\dfrac{P(B|A)P(A)}{P(B,A) + P(B,A^C)} \\\\\n",
    "&=& \\dfrac{P(B|A)P(A)}{P(B|A)P(A) + P(B|A^C)P(A^C)} \\\\\n",
    "&=& \\dfrac{P(B|A)P(A)}{P(B|A)P(A) + P(B|A^C)(1 - P(A))} \n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "#### 응용2: 추가적인 사건 $C$가 발생한 경우:\n",
    "\n",
    "$$ P(A,B,C) = P(A|B,C)P(B,C) = P(A|B,C)P(C|B)P(B)$$\n",
    "\n",
    "\n",
    "$$ P(A,B,C) = P(C|A,B)P(A,B) = P(C|A,B)P(A|B)P(B) $$\n",
    "\n",
    "\n",
    "$$ P(A|B,C)P(C|B)P(B) = P(C|A,B)P(A|B)P(B) $$\n",
    "\n",
    "\n",
    "$$ P(A|B,C) = \\dfrac{P(C|A,B)P(A|B)}{P(C|B)} $$\n",
    "\n",
    "$$ \\text{symmetrically,} $$\n",
    "\n",
    "$$ P(A|B,C) = \\dfrac{P(B|A,C)P(A|C)}{P(B|C)} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # 7.2. 확률 모형"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 확률 모형(probability model)\n",
    "* 확률 변수를 이용해 데이터 분포를 수학적으로 정의하는 방법\n",
    "* 확률 모형만 있으면 동일한 데이터 분포를 얻을 수 있음\n",
    "* 확률 모형론에서는 데이터 그 자체에는 의미가 없으며 데이터 분포 특성만이 중요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 확률 변수(random variable)\n",
    "* 표본 공간의 모든 표본에 대해 어떤 실수 값을 붙인 것 (추상적 개념 $\\rightarrow$ 계산 가능한 숫자)\n",
    ">* 이산 확률 변수(discrete random variable)\n",
    ">* 연속 확률 변수(continuous random variable)\n",
    "* 사건에 대해 할당되는 확률과 달리 확률 변수는 표본 하나 하나에 할당됨\n",
    "* 다음과 같이 표현 가능\n",
    "$$$$\n",
    "$$ A = \\{ \\omega ; a \\leq X(\\omega) < b \\} = \\{ a \\leq X < b \\} $$\n",
    "$$$$\n",
    "* 샘플링(sampling) 또는 실현(realization): 확률 변수를 통해 데이터를 생성하는 과정\n",
    "  * 샘플링은 많은 수의 데이터 집합에서 일부 데이터만 선택하는 과정을 의미하기도 하니 주의"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 분석에 적용\n",
    "1. 자료를 확보한다.\n",
    "2. 확보된 자료를 확률 변수의 표본으로 가정한다.\n",
    "3. 확률 변수가 특정한 확률 모형을 따른다고 가정한다.\n",
    "4. 표본에 대한 정보로부터 확률 모형의 종류나 모수를 추정한다.\n",
    "5. 구해진 확률 모형으로부터 다음에 생성될 데이터나 데이터 특성을 예측한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # 7.3. 확률 분포의 묘사"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 누적 분포 함수 (cdf, cumulative distribution function)\n",
    "* $\\{ -\\infty \\leq X < x \\} $ 에 할당된 확률\n",
    "$$$$\n",
    "$$ F(x) = P(\\{X < x\\}) = P(X < x)$$\n",
    "$$$$\n",
    "* $F(-\\infty) = 0$\n",
    "* $F(+\\infty) = 1$\n",
    "* $F(x) \\geq F(y) \\;\\; \\text{ if } \\;\\; x > y $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 확률 밀도 함수 (pdf, probability density function)\n",
    "* cdf를 미분한 결과 / pdf의 값 자체는 확률이 아님\n",
    "$$$$\n",
    "$$ \\dfrac{dF(x)}{dx} = f(x) \\Leftrightarrow F(x) = \\int_{-\\infty}^{x} f(u) du $$\n",
    "$$$$\n",
    "* $-\\infty$ 부터 $\\infty$ 까지 적분하면 그 값은 1이 된다\n",
    "* 확률 밀도 함수는 0보다 같거나 크다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 확률 질량 함수(pmf, probability mass function)\n",
    "* **이산 확률 변수**의 가능한 값 하나 하나에 대해 확률을 정의한 함수\n",
    "* 확률 변수에 대해 각 값을 누적하여 더하면 이산 확률 변수의 누적 분포 함수(cumulative distribution function)를 구할 수 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # 부록"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 미분 규칙1: 선형 모형 - 증명\n",
    "$$ \n",
    "\\dfrac{\\partial (\\mathbf{w}^T \\mathbf{x})}{\\partial \\mathbf{x}}=\n",
    "\\begin{bmatrix}\n",
    "\\dfrac{\\partial (\\mathbf{w}^T \\mathbf{x})}{\\partial x_1} \\\\\n",
    "\\dfrac{\\partial (\\mathbf{w}^T \\mathbf{x})}{\\partial x_2} \\\\\n",
    "\\vdots \\\\\n",
    "\\dfrac{\\partial (\\mathbf{w}^T \\mathbf{x})}{\\partial x_N} \\\\\n",
    "\\end{bmatrix} =\n",
    "\\begin{bmatrix}\n",
    "\\dfrac{\\partial (w_1 x_1 + \\cancel{w_2 x_2} + \\cdots + \\cancel{w_N x_N})}{\\partial x_1} \\\\\n",
    "\\dfrac{\\partial (\\cancel{w_1 x_1} + w_2 x_2 + \\cdots + \\cancel{w_N x_N})}{\\partial x_2} \\\\\n",
    "\\vdots \\\\\n",
    "\\dfrac{\\partial (\\cancel{w_1 x_1} + \\cancel{w_2 x_2} + \\cdots + w_N x_N)}{\\partial x_N} \\\\\n",
    "\\end{bmatrix} =\n",
    "\\begin{bmatrix}\n",
    "w_1 \\\\\n",
    "w_2 \\\\\n",
    "\\vdots \\\\\n",
    "w_N \\\\\n",
    "\\end{bmatrix}\n",
    "= \\mathbf{w} \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 미분 규칙2: 이차 형식 - 증명\n",
    "$$ \n",
    "\\begin{eqnarray}\n",
    "\\dfrac{\\partial (\\mathbf{x}^{T}\\mathbf{A}\\mathbf{x})}{\\partial \\mathbf{x}}\n",
    "&=&\n",
    "\\begin{bmatrix}\n",
    "\\dfrac{\\partial (\\mathbf{x}^{T}\\mathbf{A}\\mathbf{x})}{\\partial x_1} \\\\\n",
    "\\dfrac{\\partial (\\mathbf{x}^{T}\\mathbf{A}\\mathbf{x})}{\\partial x_2} \\\\\n",
    "\\vdots \\\\\n",
    "\\dfrac{\\partial (\\mathbf{x}^{T}\\mathbf{A}\\mathbf{x})}{\\partial x_N} \\\\\n",
    "\\end{bmatrix} \\\\\n",
    "&=&\n",
    "\\begin{bmatrix}\n",
    "\\dfrac{\\partial (\\sum_{i=1}^{N} \\sum_{j=1}^{N} a_{ij} x_i x_j)}{\\partial x_1} \\\\\n",
    "\\dfrac{\\partial (\\sum_{i=1}^{N} \\sum_{j=1}^{N} a_{ij} x_i x_j)}{\\partial x_2} \\\\\n",
    "\\vdots \\\\\n",
    "\\dfrac{\\partial (\\sum_{i=1}^{N} \\sum_{j=1}^{N} a_{ij} x_i x_j)}{\\partial x_N} \\\\\n",
    "\\end{bmatrix} \\\\\n",
    "&=&\n",
    "\\begin{bmatrix}\n",
    "\\dfrac{\\partial \n",
    "\\left(\n",
    "\\begin{matrix}\n",
    "a_{11}x_1x_1 + a_{12}x_1x_2 + \\cdots + a_{1N}x_1x_N + \\\\\n",
    "a_{21}x_2x_1 + \\cancel{a_{22}x_2x_2} + \\cdots + \\cancel{a_{2N}x_2x_N} + \\\\\n",
    "\\cdots  \\\\\n",
    "a_{N1}x_Nx_1 + \\cancel{a_{N2}x_Nx_2} + \\cdots + \\cancel{a_{NN}x_Nx_N} \n",
    "\\end{matrix}\n",
    "\\right)}{\\partial x_1} \\\\\n",
    "\\dfrac{\\partial \n",
    "\\left(\n",
    "\\begin{matrix}\n",
    "\\cancel{a_{11}x_1x_1} + a_{12}x_1x_2 + \\cdots + \\cancel{a_{1N}x_1x_N} + \\\\\n",
    "a_{21}x_2x_1 + a_{22}x_2x_2 + \\cdots + a_{2N}x_2x_N + \\\\\n",
    "\\cdots  \\\\\n",
    "\\cancel{a_{N1}x_Nx_1} + a_{N2}x_Nx_2 + \\cdots + \\cancel{a_{NN}x_Nx_N}\n",
    "\\end{matrix}\n",
    "\\right)}{\\partial x_2} \\\\\n",
    "\\vdots \\\\\n",
    "\\end{bmatrix} \n",
    "\\\\\n",
    "&=&\n",
    "\\begin{bmatrix}\n",
    "\\sum_{i=1}^{N} a_{1i} x_i + \\sum_{i=1}^{N} a_{i1} x_i\\\\\n",
    "\\sum_{i=1}^{N} a_{2i} x_i + \\sum_{i=1}^{N} a_{i2} x_i\\\\\n",
    "\\vdots \\\\\n",
    "\\sum_{i=1}^{N} a_{Ni} x_i + \\sum_{i=1}^{N} a_{iN} x_i\\\\\n",
    "\\end{bmatrix} \\\\\n",
    "&=&\n",
    "\\begin{bmatrix}\n",
    "\\sum_{i=1}^{N} a_{1i} x_i\\\\\n",
    "\\sum_{i=1}^{N} a_{2i} x_i\\\\\n",
    "\\vdots \\\\\n",
    "\\sum_{i=1}^{N} a_{Ni} x_i\\\\\n",
    "\\end{bmatrix}\n",
    "+\n",
    "\\begin{bmatrix}\n",
    "\\sum_{i=1}^{N} a_{i1} x_i \\\\\n",
    "\\sum_{i=1}^{N} a_{i2} x_i \\\\\n",
    "\\vdots \\\\\n",
    "\\sum_{i=1}^{N} a_{iN} x_i \\\\\n",
    "\\end{bmatrix} \\\\\n",
    "&=&\n",
    "\\mathbf{A} \\mathbf{x}  + \\mathbf{A}^T \\mathbf{x} \n",
    "=\n",
    "(\\mathbf{A} + \\mathbf{A}^T)\\mathbf{x} \n",
    "\\end{eqnarray}\n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
