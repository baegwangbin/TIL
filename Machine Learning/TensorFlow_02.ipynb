{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "># 2. FFNN - Fast Forward Neural Networks\n",
    "* Simplest NN model\n",
    "* Input - (hidden) - Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario\n",
    "1. Read Data\n",
    "1. Build Model\n",
    "1. Model Save & Restore\n",
    "1. Tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Input $\\rightarrow$ Output\n",
    "$$ y_0 = w_{00}x_0 + w_{01}x_1 + w_{02}x_2 + w_{03}x_3 ... w_{0n}x_n $$\n",
    "$$ y_1 = w_{10}x_0 + w_{11}x_1 + w_{12}x_2 + w_{13}x_3 ... w_{1n}x_n $$\n",
    "$$ y_2 = w_{20}w_0 + w_{21}x_1 + w_{22}x_2 + w_{23}x_3 ... w_{2n}x_n $$\n",
    "$$ y_3 = w_{30}w_0 + w_{31}x_1 + w_{32}x_2 + w_{33}x_3 ... w_{3n}x_n $$\n",
    "$$...$$\n",
    "$$ y_m = w_{m0}x_0 + w_{m1}x_1 + w_{m2}x_2 + w_{m3}x_3 ... w_{mn}x_n $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\begin{bmatrix} y_0\\\\y_1\\\\y_2\\\\y_3\\\\...\\\\y_m \\end{bmatrix} = \\begin{bmatrix} w_{00}&w_{01}&w_{02}&w_{03}&...&w_{0n} \\\\ w_{10}&w_{11}&w_{12}&w_{13}&...&w_{1n} \\\\ w_{20}&w_{21}&w_{22}&w_{23}&...&w_{2n} \\\\ w_{30}&w_{31}&w_{32}&w_{33}&...&w_{3n} \\\\ ...&...&...&...&...&... \\\\ w_{m0}&w_{m1}&w_{m2}&w_{m3}&...&w_{mn} \\end{bmatrix} \\begin{bmatrix} x_0\\\\x_1\\\\x_2\\\\x_3\\\\...\\\\x_n \\end{bmatrix} $$\n",
    "$$$$\n",
    "$$ Y = W^TX $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Output $\\rightarrow$ Input\n",
    "\n",
    "$$ h = \\sigma(W^TX) $$\n",
    "$$$$\n",
    "$$ \\sigma(x) = \\frac{1}{1 + e^{-(wx + b)}} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "># 2.1. Implementation - Binary Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data is written\n",
      "test data is written\n"
     ]
    }
   ],
   "source": [
    "samples = 1000\n",
    "test_samples = 100\n",
    "train_dataset = './dataset/train_dataset.csv'\n",
    "test_dataset = './dataset/test_dataset.csv'\n",
    "\n",
    "def write_dataset(samples, test_samples, train_dir, test_dir):\n",
    "    up = [i for i in range(10)]\n",
    "    down = [9-i for i in range(10)]\n",
    "\n",
    "    data = []\n",
    "    label = []\n",
    "    for i in range(samples):\n",
    "        data.append(up)\n",
    "        data.append(down)\n",
    "        label.append([1])\n",
    "        label.append([0])\n",
    "\n",
    "    with open(train_dataset, 'w') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        for i in range(samples-test_samples):\n",
    "            writer.writerow(label[i] + data[i])\n",
    "        print('train data is written')\n",
    "\n",
    "    with open(test_dataset, 'w') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        for i in range(test_samples):\n",
    "            writer.writerow(label[i] + data[i])\n",
    "        print('test data is written')\n",
    "        \n",
    "write_dataset(1000, 100, train_dataset, test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dataset\n",
    "* Put filepath / Set batch size / Shuffle with random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = tf.contrib.data.TextLineDataset(train_dataset)\n",
    "dataset = dataset.batch(32)\n",
    "dataset = dataset.shuffle(77)\n",
    "dataset = dataset.repeat(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "itr = dataset.make_one_shot_iterator()\n",
    "\n",
    "batch = itr.get_next()\n",
    "\n",
    "# record_defaults: in case of empty data, fill with record_defaults\n",
    "decoded_batch = tf.decode_csv(batch, record_defaults=[[0]]*11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape & Cast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reshape\n",
    "label = tf.reshape(decoded_batch[0], [-1, 1])\n",
    "label = tf.expand_dims(decoded_batch[0], axis=-1)\n",
    "feature = tf.stack(decoded_batch[1:], axis=1)\n",
    "\n",
    "# Cast\n",
    "label = tf.cast(label, tf.float32)\n",
    "feature = tf.cast(feature, tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Layers\n",
    "* units: no. of nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bin_model(x, activation=None, reuse=False):\n",
    "    layer1 = tf.layers.dense(x, units=9, activation=activation, reuse=reuse, name='layer1')\n",
    "    layer2 = tf.layers.dense(layer1, units=7, activation=activation, reuse=reuse, name='layer2')\n",
    "    layer3 = tf.layers.dense(layer2, units=5, activation=activation, reuse=reuse, name='layer3')\n",
    "    layer4 = tf.layers.dense(layer3, units=3, activation=activation, reuse=reuse, name='layer4')\n",
    "    out = tf.layers.dense(layer4, units=1, reuse=reuse, name='out')\n",
    "    return out\n",
    "        \n",
    "out = bin_model(feature, activation=tf.nn.relu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define loss & train_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:logits.dtype=<dtype: 'float32'>.\n",
      "INFO:tensorflow:multi_class_labels.dtype=<dtype: 'float32'>.\n",
      "INFO:tensorflow:losses.dtype=<dtype: 'float32'>.\n"
     ]
    }
   ],
   "source": [
    "loss = tf.losses.sigmoid_cross_entropy(label, out)\n",
    "train_op = tf.train.GradientDescentOptimizer(1e-2).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0, loss: 0.9482421278953552\n",
      "step: 10, loss: 0.7128403186798096\n",
      "step: 20, loss: 0.6632524132728577\n",
      "step: 30, loss: 0.6068441867828369\n",
      "step: 40, loss: 0.5468055009841919\n",
      "step: 50, loss: 0.4955664277076721\n",
      "step: 60, loss: 0.44572773575782776\n",
      "step: 70, loss: 0.35237836837768555\n",
      "step: 80, loss: 0.3364059031009674\n",
      "step: 90, loss: 0.33025437593460083\n",
      "step: 100, loss: 0.32187265157699585\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXMAAAD3CAYAAADv7LToAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fac05b2a630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    _loss_ = []\n",
    "    for i in range(101):\n",
    "        _, _loss = sess.run([train_op, loss])\n",
    "        _loss_.append(_loss)\n",
    "        if i%10 == 0:\n",
    "            print('step: {}, loss: {}'.format(i, _loss))\n",
    "        \n",
    "    plt.plot(_loss_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t_dataset = tf.contrib.data.TextLineDataset(test_dataset).batch(32).shuffle(77).repeat(100)\n",
    "\n",
    "t_itr = t_dataset.make_one_shot_iterator()\n",
    "\n",
    "t_batch = t_itr.get_next()\n",
    "\n",
    "t_decoded_batch = tf.decode_csv(t_batch, record_defaults=[[0]]*11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t_label = tf.reshape(t_decoded_batch[0], [-1, 1])\n",
    "t_feature = tf.stack(t_decoded_batch[1:], axis=1)\n",
    "\n",
    "t_label = tf.cast(t_label, tf.float32)\n",
    "t_feature = tf.cast(t_feature, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Cast_2:0\", shape=(?, 1), dtype=float32)\n",
      "Tensor(\"Cast_3:0\", shape=(?, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(t_label)\n",
    "print(t_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t_out = bin_model(t_feature, activation=tf.nn.relu, reuse=True)\n",
    "\n",
    "pred = tf.nn.sigmoid(t_out)\n",
    "\n",
    "accuracy = tf.metrics.accuracy(t_label, tf.round(pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.summary.scalar('loss', loss)\n",
    "\n",
    "merged = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0, loss: 0.95085209608078, accuracy: (0.0, 0.5)\n",
      "step: 10, loss: 0.39361414313316345, accuracy: (0.5, 0.5)\n",
      "step: 20, loss: 0.31506291031837463, accuracy: (0.69999999, 0.71804512)\n",
      "step: 30, loss: 0.2891136407852173, accuracy: (0.79619563, 0.8046875)\n",
      "step: 40, loss: 0.26506102085113525, accuracy: (0.85000002, 0.85465115)\n",
      "step: 50, loss: 0.24175995588302612, accuracy: (0.87864077, 0.8817035)\n",
      "step: 60, loss: 0.21771368384361267, accuracy: (0.89999998, 0.90208876)\n",
      "step: 70, loss: 0.1916748434305191, accuracy: (0.91496599, 0.91648108)\n",
      "step: 80, loss: 0.16408930718898773, accuracy: (0.92500001, 0.92618108)\n",
      "step: 90, loss: 0.1362316608428955, accuracy: (0.93374556, 0.93386245)\n",
      "step: 100, loss: 0.10992591083049774, accuracy: (0.94, 0.94075829)\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.local_variables_initializer()) # because of the accuracy\n",
    "    writer = tf.summary.FileWriter('./logs/', sess.graph)\n",
    "    for i in range(101):\n",
    "        _, _loss, _acc, _summary = sess.run([train_op, loss, accuracy, merged])\n",
    "        writer.add_summary(_summary, i)\n",
    "        if i%10 == 0:\n",
    "            print('step: {}, loss: {}, accuracy: {}'.format(i, _loss, _acc))\n",
    "            \n",
    "    saver.save(sess, './logs/ffnn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See in Tensorboard\n",
    "```\n",
    "$ tensorboard -logdir=./logs\n",
    "```\n",
    "Go to Chrome / 6006"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./logs/ffnn\n",
      "[[  7.09242880e-01]\n",
      " [  8.00312864e-06]\n",
      " [  7.09242880e-01]\n",
      " [  8.00312864e-06]\n",
      " [  7.09242880e-01]\n",
      " [  8.00312864e-06]\n",
      " [  7.09242880e-01]\n",
      " [  8.00312864e-06]\n",
      " [  7.09242880e-01]\n",
      " [  8.00312864e-06]\n",
      " [  7.09242880e-01]\n",
      " [  8.00312864e-06]\n",
      " [  7.09242880e-01]\n",
      " [  8.00312864e-06]\n",
      " [  7.09242880e-01]\n",
      " [  8.00312864e-06]\n",
      " [  7.09242880e-01]\n",
      " [  8.00312864e-06]\n",
      " [  7.09242880e-01]\n",
      " [  8.00312864e-06]\n",
      " [  7.09242880e-01]\n",
      " [  8.00312864e-06]\n",
      " [  7.09242880e-01]\n",
      " [  8.00312864e-06]\n",
      " [  7.09242880e-01]\n",
      " [  8.00312864e-06]\n",
      " [  7.09242880e-01]\n",
      " [  8.00312864e-06]\n",
      " [  7.09242880e-01]\n",
      " [  8.00312864e-06]\n",
      " [  7.09242880e-01]\n",
      " [  8.00312864e-06]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, './logs/ffnn')\n",
    "    _pred = sess.run(pred)\n",
    "    print(_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vanishing Gradient\n",
    "* When using sigmoid function, the gradient of the sigmoid is multiplied during the learning process\n",
    "* Since the gradient of the sigmoid function vanishes for large/small values, the learning becomes painfully slow\n",
    "* Solved by trying different activation functions (e.g. ReLU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "># 2.2. Multiple Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], label [0]\n",
      "data: [5, 5, 5, 5, 5, 5, 5, 5, 5, 5], label [1]\n",
      "data: [9, 8, 7, 6, 5, 4, 3, 2, 1, 0], label [2]\n",
      "data: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], label [0]\n",
      "data: [5, 5, 5, 5, 5, 5, 5, 5, 5, 5], label [1]\n",
      "data: [9, 8, 7, 6, 5, 4, 3, 2, 1, 0], label [2]\n",
      "data: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], label [0]\n",
      "data: [5, 5, 5, 5, 5, 5, 5, 5, 5, 5], label [1]\n",
      "data: [9, 8, 7, 6, 5, 4, 3, 2, 1, 0], label [2]\n",
      "data: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], label [0]\n",
      "train data is written\n",
      "test data is written\n"
     ]
    }
   ],
   "source": [
    "samples = 1000\n",
    "test_samples = 100\n",
    "train_dataset = './dataset/train_dataset.csv'\n",
    "test_dataset = './dataset/test_dataset.csv'\n",
    "\n",
    "up = [i for i in range(10)]\n",
    "down = [9-i for i in range(10)]\n",
    "flat = [5 for i in range(10)]\n",
    "\n",
    "data = []\n",
    "label = []\n",
    "for i in range(samples):\n",
    "    data.append(up)\n",
    "    data.append(flat)\n",
    "    data.append(down)\n",
    "    label.append([0])\n",
    "    label.append([1])\n",
    "    label.append([2])\n",
    "    \n",
    "for i in range(10):\n",
    "    print('data: {}, label {}'.format(data[i], label[i]))\n",
    "\n",
    "    \n",
    "    \n",
    "with open(train_dataset, 'w') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    for i in range(samples-test_samples):\n",
    "        writer.writerow(label[i] + data[i])\n",
    "    print('train data is written')\n",
    "        \n",
    "with open(test_dataset, 'w') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    for i in range(test_samples):\n",
    "        writer.writerow(label[i] + data[i])\n",
    "    print('test data is written')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Cast_1:0\", shape=(?, 10), dtype=float32)\n",
      "Tensor(\"Cast:0\", shape=(?, 10), dtype=float32)\n",
      "Tensor(\"one_hot:0\", shape=(?, 3), dtype=float32)\n",
      "Tensor(\"Reshape:0\", shape=(?, 1), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "trainset = tf.contrib.data.TextLineDataset(train_dataset).batch(10)\n",
    "testset = tf.contrib.data.TextLineDataset(test_dataset).batch(10)\n",
    "\n",
    "train_itr = trainset.make_one_shot_iterator()\n",
    "test_itr = testset.make_one_shot_iterator()\n",
    "\n",
    "train_batch = train_itr.get_next()\n",
    "test_batch = test_itr.get_next()\n",
    "\n",
    "decoded_train = tf.decode_csv(train_batch, [[0]]*11)\n",
    "decoded_test = tf.decode_csv(test_batch, [[0]]*11)\n",
    "\n",
    "train_label = tf.one_hot(decoded_train[0], depth=3, axis=-1, dtype=tf.float32)\n",
    "test_label = tf.reshape(decoded_test[0], [-1, 1])\n",
    "\n",
    "train_data = tf.stack(decoded_train[1:], axis=1)\n",
    "test_data = tf.stack(decoded_test[1:], axis=1)\n",
    "\n",
    "test_data = tf.cast(test_data, tf.float32)\n",
    "train_data = tf.cast(train_data, tf.float32)\n",
    "\n",
    "print(train_data)\n",
    "print(test_data)\n",
    "print(train_label)\n",
    "print(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'layer1/kernel:0' shape=(10, 10) dtype=float32_ref>\n",
      "<tf.Variable 'layer1/bias:0' shape=(10,) dtype=float32_ref>\n",
      "<tf.Variable 'layer2/kernel:0' shape=(10, 10) dtype=float32_ref>\n",
      "<tf.Variable 'layer2/bias:0' shape=(10,) dtype=float32_ref>\n",
      "<tf.Variable 'layer3/kernel:0' shape=(10, 10) dtype=float32_ref>\n",
      "<tf.Variable 'layer3/bias:0' shape=(10,) dtype=float32_ref>\n",
      "<tf.Variable 'layer4/kernel:0' shape=(10, 10) dtype=float32_ref>\n",
      "<tf.Variable 'layer4/bias:0' shape=(10,) dtype=float32_ref>\n",
      "<tf.Variable 'layer_out/kernel:0' shape=(10, 3) dtype=float32_ref>\n",
      "<tf.Variable 'layer_out/bias:0' shape=(3,) dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "def multi_class_model(x, activation, reuse=False):\n",
    "    layer1 = tf.layers.dense(x, 10, activation=activation, reuse=reuse, name='layer1')\n",
    "    layer2 = tf.layers.dense(layer1, 10, activation=activation, reuse=reuse, name='layer2')\n",
    "    layer3 = tf.layers.dense(layer2, 10, activation=activation, reuse=reuse, name='layer3')\n",
    "    layer4 = tf.layers.dense(layer3, 10, activation=activation, reuse=reuse, name='layer4')\n",
    "    return tf.layers.dense(layer4, 3, activation=activation, reuse=reuse, name='layer_out')\n",
    "\n",
    "train_out = multi_class_model(train_data, tf.nn.sigmoid)\n",
    "test_out = multi_class_model(test_data, tf.nn.sigmoid, True)\n",
    "\n",
    "for var in tf.trainable_variables():\n",
    "    print(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = tf.losses.softmax_cross_entropy(train_label, train_out)\n",
    "train_op = tf.train.GradientDescentOptimizer(1e-6).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = tf.nn.softmax(test_out)\n",
    "accuracy = tf.metrics.accuracy(test_label, tf.argmax(pred, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 1.1065032482147217, acc: 0.3333333432674408\n",
      "epoch: 1, loss: 1.0911767482757568, acc: 0.3333333432674408\n",
      "epoch: 2, loss: 1.1273247003555298, acc: 0.3333333432674408\n",
      "epoch: 3, loss: 1.1065032482147217, acc: 0.3333333432674408\n",
      "epoch: 4, loss: 1.0911767482757568, acc: 0.3333333432674408\n",
      "epoch: 5, loss: 1.1273247003555298, acc: 0.3333333432674408\n",
      "epoch: 6, loss: 1.1065032482147217, acc: 0.3333333432674408\n",
      "epoch: 7, loss: 1.0911767482757568, acc: 0.3333333432674408\n",
      "epoch: 8, loss: 1.1273247003555298, acc: 0.3333333432674408\n",
      "epoch: 9, loss: 1.1065032482147217, acc: 0.3333333432674408\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    for i in range(10):\n",
    "        while True:\n",
    "            try:\n",
    "                _, _loss = sess.run([train_op, loss])\n",
    "                _acc = sess.run(accuracy)\n",
    "            except tf.errors.OutOfRangeError:\n",
    "                break\n",
    "                \n",
    "        print('epoch: {}, loss: {}, acc: {}'.format(i, _loss, _acc[0]))\n",
    "        saver.save(sess, './logs/model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
